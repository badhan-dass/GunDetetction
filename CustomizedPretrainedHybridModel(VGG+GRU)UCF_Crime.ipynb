{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79628168-369c-462f-a874-ef1b3e1e7080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 23:00:45.025320: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-09 23:00:45.042560: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 23:00:45.059853: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 23:00:45.065201: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 23:00:45.079352: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 23:00:46.084754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import *\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Input, RepeatVector, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam, Adam\n",
    "from keras.layers import LSTM, GRU, Bidirectional, Attention\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe7e8fd-b73e-457d-bc9f-5d3d6e010c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3cd6a4-a4a6-4a78-8b5e-0d0b40abd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 23\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f69eee8d-a3d1-4bd6-b403-c410182a9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  \"UCF_crime_subset/\"\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH= 224,224\n",
    "\n",
    "SEQUENCE_LENGTH =50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b1901d2-fa71-4604-8fea-d17930c83387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_categories_list = [\"Gun\", \"NoGun\"]\n",
    "model_output_length = len(class_categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8d0353-8edc-48de-baf1-7da24a58a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pixel_value = 255\n",
    "def extract_frame(video_path):\n",
    "  # frames_list = []\n",
    "\n",
    "  # #print(\" the video file path is : {}\".format(video_path))\n",
    "  # videoObj = cv2.VideoCapture(video_path)\n",
    "  # #print(\"the video object is: {}\".format(videoObj))\n",
    "\n",
    "  # \"\"\" Iterating through Video Frames \"\"\"\n",
    "  # while True:\n",
    "\n",
    "  #   # Reading a frame from the video file\n",
    "  #   success, image = videoObj.read()\n",
    "  #   #print(\"the value of success is: {}\".format(success))\n",
    "\n",
    "  #   if not success:\n",
    "  #     break\n",
    "\n",
    "  #   resized_frame = cv2.resize(image, (image_height, image_width))\n",
    "\n",
    "  #   \"\"\"Normalize the resized frame by dividing it with 255 so that \n",
    "  #   each pixel value then lies between 0 and 1\"\"\"\n",
    "\n",
    "  #   normalized_frame = resized_frame / max_pixel_value\n",
    "  #   frames_list.append(normalized_frame)\n",
    "\n",
    "    \n",
    "  # videoObj.release()\n",
    "\n",
    "\n",
    "    frames_list = []\n",
    "    \n",
    "    # Read the Video File\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the total number of frames in the video.\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the the interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    "    \n",
    "    # Iterate through the Video Frames.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "    \n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "    \n",
    "        # Reading the frame from the video. \n",
    "        success, frame = video_reader.read() \n",
    "    \n",
    "        if not success:\n",
    "            break\n",
    "    \n",
    "        # Resize the Frame to fixed height and width.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Normalize the resized frame\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Append the normalized frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    \n",
    "    video_reader.release()\n",
    "\n",
    "\n",
    "    return frames_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "943a452f-3497-4bdb-8c45-51d27da91e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_creation():\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "    \n",
    "    # Iterating through all the classes.\n",
    "    for class_index, class_name in enumerate(class_categories_list):\n",
    "        \n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Get the list of video files present in the specific class name directory.\n",
    "        files_list = os.listdir(os.path.join(data_dir, class_name))\n",
    "        \n",
    "        # Iterate through all the files present in the files list.\n",
    "        for file_name in files_list:\n",
    "            \n",
    "            # Get the complete video path.\n",
    "            video_file_path = os.path.join(data_dir, class_name, file_name)\n",
    " \n",
    "            # Extract the frames of the video file.\n",
    "            frames = extract_frame(video_file_path)\n",
    " \n",
    "            # Check if the extracted frames are equal to the SEQUENCE_LENGTH specified.\n",
    "            # So ignore the videos having frames less than the SEQUENCE_LENGTH.\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    " \n",
    "                # Append the data to their repective lists.\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    " \n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8318f13-5f00-4ccf-bfde-5f469c9c19eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: Gun\n",
      "Extracting Data of Class: NoGun\n"
     ]
    }
   ],
   "source": [
    "features, labels = data_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e29e94-5e4b-466c-87c4-710328f43f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the feature = (100, 50, 224, 224, 3)\n",
      "the shape of the labels = (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the feature = {}\".format(features.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a591ab-de67-4797-bdf8-8e35f8d138a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27ff7c15-6485-437f-9c2e-a556d7ac3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, \n",
    "                                                                            test_size = 0.5, \n",
    "                                                                            shuffle = True, \n",
    "                                                                            random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d3bc01e-72fb-4b03-a98d-542d51bd7979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the feature = (50, 50, 224, 224, 3)\n",
      "the shape of the labels = (50, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the feature = {}\".format(features_train.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8935243-0edb-4d1a-a2fc-a5beeb6933b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the feature = (50, 50, 224, 224, 3)\n",
      "the shape of the labels = (50, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the feature = {}\".format(features_test.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ab9657e-4d72-4f4f-bd0d-7a70b8e3c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 23:02:28.488276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 28837 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:1a:00.0, compute capability: 8.0\n",
      "2024-09-09 23:02:28.490435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 35606 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:1b:00.0, compute capability: 8.0\n",
      "2024-09-09 23:02:28.492485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 35598 MB memory:  -> device: 2, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:3d:00.0, compute capability: 8.0\n",
      "2024-09-09 23:02:28.494888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38367 MB memory:  -> device: 3, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:3e:00.0, compute capability: 8.0\n",
      "2024-09-09 23:02:28.497533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 38367 MB memory:  -> device: 4, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:88:00.0, compute capability: 8.0\n",
      "2024-09-09 23:02:28.499700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 38367 MB memory:  -> device: 5, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:b2:00.0, compute capability: 8.0\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "no_of_channels = 3\n",
    "\n",
    "# Load the saved model\n",
    "VGG_model = load_model('VGG16_Date_Time_2024_08_17__16_23_00___Loss_0.13619327545166016___Accuracy_0.9503968358039856.h5')\n",
    "\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, no_of_channels)\n",
    "\n",
    "# Remove the classification head (last layer)\n",
    "VGG_model = Model(inputs=VGG_model.inputs, outputs=VGG_model.layers[-5].output)\n",
    "\n",
    "# Set the new input shape\n",
    "VGG_model.build(input_shape)\n",
    "\n",
    "# Print the updated model summary\n",
    "VGG_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7db383-fee1-431e-b2a1-44843a124825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37e3d45-9841-42fe-a1c6-a17c94829adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input = Input(shape=(SEQUENCE_LENGTH,\n",
    "                           IMAGE_HEIGHT,\n",
    "                            IMAGE_WIDTH,\n",
    "                            no_of_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db999892-7656-4766-9e1d-ebb3fb8d3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_encoded = TimeDistributed(VGG_model)(video_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "325d9785-25f2-4870-9736-0d4b6ad3ad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 50, 512), dtype=float32, sparse=False, name=keras_tensor_49>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_frames_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "133bd4c9-8327-4ec0-979e-c8521aa2fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1786e6c3-eb7d-4c43-94e1-87879d62da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_encoded_sequence = GRU(256)(video_frames_encoded)\n",
    "#video_frames_encoded_sequence = Dropout(0.5)(video_frames_encoded_sequence)\n",
    "\n",
    "\n",
    "# video_frames_encoded_sequence = LSTM(256, return_sequences=True)(video_frames_encoded)\n",
    "# attention_layer = Attention()([video_frames_encoded_sequence, video_frames_encoded_sequence])\n",
    "# video_frames_encoded_sequence = Flatten()(attention_layer)\n",
    "\n",
    "\n",
    "hidden_layer1 = Dense(1024, activation=\"relu\")(video_frames_encoded_sequence)\n",
    "#hidden_layer1 = Dropout(0.5)(hidden_layer1)\n",
    "\n",
    "hidden_layer2 = Dense(512, activation=\"relu\")(hidden_layer1)\n",
    "#hidden_layer2 = Dropout(0.5)(hidden_layer2)\n",
    "\n",
    "hidden_layer3 = Dense(256, activation=\"relu\")(hidden_layer2)\n",
    "#hidden_layer3 = Dropout(0.25)(hidden_layer3)\n",
    "\n",
    "hidden_layer4 =  Dense(128, activation=\"relu\")(hidden_layer3)\n",
    "#hidden_layer4 = Dropout(0.25)(hidden_layer4)\n",
    "\n",
    "hidden_layer5 =  Dense(64, activation=\"relu\")(hidden_layer4)\n",
    "#hidden_layer5 = Dropout(0.25)(hidden_layer5)\n",
    "\n",
    "outputs = Dense(no_of_classes, activation=\"softmax\")(hidden_layer5)\n",
    "model = Model([video_input], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4690bef4-3c70-4796-9219-7105a62eb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.000005)\n",
    "                  # beta_1=0.9,\n",
    "                  # beta_2=0.999,\n",
    "                  # epsilon=1e-08,\n",
    "                  # weight_decay=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13492e04-2f4f-4d39-896c-1a357a2757ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06e80d2e-e297-4476-a85d-10a01f46c867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">591,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m591,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,266,626</span> (62.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,266,626\u001b[0m (62.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,551,938</span> (5.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,551,938\u001b[0m (5.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b291f04b-07ce-453c-ae4e-4587efefa47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Early Stopping Callback\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\",\n",
    "                      mode=\"min\",\n",
    "                      restore_best_weights=True,\n",
    "                      patience=5)\n",
    "checkpoint = ModelCheckpoint('VGG+LSTM_best_weights(UCF_Crime).keras',\n",
    "                             monitor='val_accuracy',\n",
    "                            #  monitor='val_f1_score',\n",
    "                             verbose=1,\n",
    "                             mode='max',\n",
    "                             save_best_only=True)\n",
    "callbacks = [early_stopping_callback, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0237416-13bd-4356-8110-b860c3a7c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 50, 224, 224, 3), (50, 2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30f9ba48-922e-483a-a643-d40e16044ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 23:02:52.057163: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1725937372.138182  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.156309  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.186772  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.187484  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.188201  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.188953  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.192001  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.192772  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.195062  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.202301  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.203206  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.205164  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.229860  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.237194  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.239805  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.242040  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.244704  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.247114  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.265803  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.267291  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.270530  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.283676  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.375627  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.376865  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.378041  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.379304  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.380613  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.381990  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.383421  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.384876  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.386474  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.388176  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.389840  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.391495  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.393180  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.395161  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.397796  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.400551  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.403887  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.406922  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.409246  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.411572  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.415745  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.418688  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.423784  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.427564  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.438528  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.443116  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.448531  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.517104  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.517677  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.518188  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.518710  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.519244  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.519766  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.520327  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.520862  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.521407  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.522004  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.522611  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.523224  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.523887  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.524522  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.525196  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.525966  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.526753  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.527572  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.528455  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.529342  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.530409  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.532016  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.533336  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.534936  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.536673  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.540793  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.555998  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.564432  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.565148  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.565811  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.566453  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.567207  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.567888  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.568592  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.569282  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.570073  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.570779  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.571682  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.572501  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.573335  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.574167  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.575253  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.576415  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.577427  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.578629  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.579938  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.581500  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.583826  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.586380  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.589070  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.592223  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.597908  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.615124  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.633557  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.634032  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.634487  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.634961  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.635429  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.635931  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.636402  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.636886  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.637387  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.637925  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.638538  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.639088  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.639650  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.640210  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.640867  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.641575  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.642312  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.643062  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.643921  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.644799  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.646132  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.647736  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.649195  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.651078  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.654194  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.667126  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.672091  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.672708  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.673308  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.673927  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.674551  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.675225  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.675893  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.676564  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.677239  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.677956  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.678723  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.679486  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.680289  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.681056  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.682061  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.683060  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.684101  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.685264  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.686676  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.688041  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.691052  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.693450  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.711234  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.741666  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.742163  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.742641  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.743120  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.743586  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.744071  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.744567  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.745062  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.745553  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.746082  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.746638  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.747193  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.747755  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.748314  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.749008  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.749684  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.750394  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.751139  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.752133  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.753109  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.754958  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.756934  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.769129  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.771662  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.772253  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.772837  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.773431  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.774056  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.774691  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.775333  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.775978  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.776636  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.777289  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.777982  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.778719  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.779464  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.780232  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.781178  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.782149  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.783182  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.784343  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.785848  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.787369  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.791032  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.794030  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.814371  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.836343  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.836747  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.837151  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.837546  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.837939  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.838347  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.838756  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.839171  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.839597  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.840035  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.840483  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.840932  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.841413  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.841892  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.842388  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.842897  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.843409  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.843948  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.844542  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.845247  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.845953  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.847046  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937372.848464  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.4846 - loss: 0.7013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725937380.109167  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.109719  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.110070  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.110392  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.110732  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.111068  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.111396  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.111724  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.112083  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.112442  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.112837  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.113231  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.113620  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.114010  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.114434  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.114863  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.115288  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.115723  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.116258  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.116940  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.129038  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.129489  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.129897  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.130309  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.130734  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.131183  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.131620  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.132061  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.132521  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.133014  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.133510  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.133978  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.134450  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.134944  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.135477  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.136007  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.136607  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.137151  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.137731  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.138313  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.139158  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.139944  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.146758  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.147685  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.148684  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.160024  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.163208  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.163532  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.163861  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.164193  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.164528  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.164860  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.165187  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.165523  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.165861  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.166200  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.166558  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.166919  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.167275  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.167644  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.168034  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.168422  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.168817  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.169221  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.169635  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.170149  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.170734  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.171377  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.174864  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.175910  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.198497  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.198902  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.199281  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.199647  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.200022  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.200392  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.200769  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.201142  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.201520  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.201904  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.202316  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.202744  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.203148  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.203555  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.203967  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.204418  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.204894  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.205393  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.205890  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.206422  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.207184  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.208061  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.209070  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.210872  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.227445  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.227787  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.228099  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.228410  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.228734  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.229051  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.229356  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.229671  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.229994  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.230314  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.230649  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.230985  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.231317  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.231662  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.232011  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.232362  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.232730  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.233114  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.233503  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.233922  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.234350  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.234860  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.235465  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.236105  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.237368  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.238642  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.241026  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.263450  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.263835  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.264192  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.264544  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.264902  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.265251  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.265615  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.265972  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.266334  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.266700  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.267085  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.267481  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.267868  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.268262  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.268658  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.269098  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.269549  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.270012  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.270503  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.271011  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.271578  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.272759  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.273790  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.276163  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.292131  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.294331  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.294652  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.294963  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.295283  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.295614  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.295940  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.296267  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.296609  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.296941  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.297266  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.297603  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.297945  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.298299  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.298668  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.299028  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.299398  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.299786  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.300180  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.300583  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.301044  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.301672  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.302544  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.304162  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.326867  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.327293  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.327662  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.328017  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.328394  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.328758  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.329147  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.329511  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.329897  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.330276  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.330667  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.331118  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.331594  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.332007  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.332459  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.332865  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.333293  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.333781  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.334230  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.334757  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.335382  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.336369  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.337430  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.351318  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.355666  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.355994  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.356328  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.356651  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.356985  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.357311  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.357656  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.357993  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.358343  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.358695  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.359034  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.359389  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.359783  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.360176  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.360584  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.360998  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.361427  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.361875  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.362313  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.362808  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.363383  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.364529  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937380.371224  462301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to VGG+LSTM_best_weights(UCF_Crime).keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - accuracy: 0.4830 - loss: 0.7017 - val_accuracy: 0.5000 - val_loss: 0.6981\n",
      "Epoch 2/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.4846 - loss: 0.6979\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 463ms/step - accuracy: 0.4830 - loss: 0.6983 - val_accuracy: 0.5000 - val_loss: 0.6968\n",
      "Epoch 3/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.4846 - loss: 0.6958\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 469ms/step - accuracy: 0.4830 - loss: 0.6962 - val_accuracy: 0.5000 - val_loss: 0.6957\n",
      "Epoch 4/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.4846 - loss: 0.6939\n",
      "Epoch 4: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 952ms/step - accuracy: 0.4830 - loss: 0.6942 - val_accuracy: 0.5000 - val_loss: 0.6948\n",
      "Epoch 5/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.4846 - loss: 0.6920\n",
      "Epoch 5: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 444ms/step - accuracy: 0.4830 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
      "Epoch 6/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.4846 - loss: 0.6901\n",
      "Epoch 6: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 470ms/step - accuracy: 0.4830 - loss: 0.6904 - val_accuracy: 0.5000 - val_loss: 0.6926\n",
      "Epoch 7/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.4846 - loss: 0.6882\n",
      "Epoch 7: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 461ms/step - accuracy: 0.4830 - loss: 0.6885 - val_accuracy: 0.5000 - val_loss: 0.6913\n",
      "Epoch 8/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.4846 - loss: 0.6861\n",
      "Epoch 8: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 473ms/step - accuracy: 0.4830 - loss: 0.6864 - val_accuracy: 0.5000 - val_loss: 0.6898\n",
      "Epoch 9/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.5167 - loss: 0.6841\n",
      "Epoch 9: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 474ms/step - accuracy: 0.5139 - loss: 0.6844 - val_accuracy: 0.5000 - val_loss: 0.6889\n",
      "Epoch 10/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.5167 - loss: 0.6825\n",
      "Epoch 10: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 465ms/step - accuracy: 0.5139 - loss: 0.6828 - val_accuracy: 0.5000 - val_loss: 0.6884\n",
      "Epoch 11/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.5167 - loss: 0.6811\n",
      "Epoch 11: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 778ms/step - accuracy: 0.5139 - loss: 0.6814 - val_accuracy: 0.5000 - val_loss: 0.6878\n",
      "Epoch 12/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.5167 - loss: 0.6798\n",
      "Epoch 12: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 477ms/step - accuracy: 0.5139 - loss: 0.6800 - val_accuracy: 0.5000 - val_loss: 0.6872\n",
      "Epoch 13/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.5587 - loss: 0.6786\n",
      "Epoch 13: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 458ms/step - accuracy: 0.5615 - loss: 0.6789 - val_accuracy: 0.4000 - val_loss: 0.6864\n",
      "Epoch 14/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.7108 - loss: 0.6775\n",
      "Epoch 14: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.7090 - loss: 0.6778 - val_accuracy: 0.5000 - val_loss: 0.6858\n",
      "Epoch 15/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.7729 - loss: 0.6764\n",
      "Epoch 15: val_accuracy improved from 0.50000 to 0.60000, saving model to VGG+LSTM_best_weights(UCF_Crime).keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 560ms/step - accuracy: 0.7691 - loss: 0.6766 - val_accuracy: 0.6000 - val_loss: 0.6852\n",
      "Epoch 16/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.8413 - loss: 0.6753\n",
      "Epoch 16: val_accuracy did not improve from 0.60000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 477ms/step - accuracy: 0.8344 - loss: 0.6755 - val_accuracy: 0.6000 - val_loss: 0.6847\n",
      "Epoch 17/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 0.8733 - loss: 0.6740\n",
      "Epoch 17: val_accuracy improved from 0.60000 to 0.70000, saving model to VGG+LSTM_best_weights(UCF_Crime).keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 598ms/step - accuracy: 0.8653 - loss: 0.6743 - val_accuracy: 0.7000 - val_loss: 0.6842\n",
      "Epoch 18/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.8846 - loss: 0.6729\n",
      "Epoch 18: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 477ms/step - accuracy: 0.8788 - loss: 0.6731 - val_accuracy: 0.7000 - val_loss: 0.6837\n",
      "Epoch 19/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9154 - loss: 0.6718\n",
      "Epoch 19: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 482ms/step - accuracy: 0.9128 - loss: 0.6721 - val_accuracy: 0.7000 - val_loss: 0.6833\n",
      "Epoch 20/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.8583 - loss: 0.6710\n",
      "Epoch 20: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 470ms/step - accuracy: 0.8611 - loss: 0.6712 - val_accuracy: 0.7000 - val_loss: 0.6828\n",
      "Epoch 21/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.8583 - loss: 0.6701\n",
      "Epoch 21: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 476ms/step - accuracy: 0.8611 - loss: 0.6703 - val_accuracy: 0.6000 - val_loss: 0.6823\n",
      "Epoch 22/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.8375 - loss: 0.6693\n",
      "Epoch 22: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 469ms/step - accuracy: 0.8438 - loss: 0.6695 - val_accuracy: 0.6000 - val_loss: 0.6819\n",
      "Epoch 23/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.8325 - loss: 0.6684\n",
      "Epoch 23: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 481ms/step - accuracy: 0.8354 - loss: 0.6686 - val_accuracy: 0.7000 - val_loss: 0.6814\n",
      "Epoch 24/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8438 - loss: 0.6676\n",
      "Epoch 24: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 815ms/step - accuracy: 0.8490 - loss: 0.6678 - val_accuracy: 0.7000 - val_loss: 0.6808\n",
      "Epoch 25/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.8438 - loss: 0.6667\n",
      "Epoch 25: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 484ms/step - accuracy: 0.8490 - loss: 0.6669 - val_accuracy: 0.7000 - val_loss: 0.6802\n",
      "Epoch 26/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.8067 - loss: 0.6659\n",
      "Epoch 26: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 477ms/step - accuracy: 0.8097 - loss: 0.6661 - val_accuracy: 0.7000 - val_loss: 0.6798\n",
      "Epoch 27/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.8067 - loss: 0.6650\n",
      "Epoch 27: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 480ms/step - accuracy: 0.8097 - loss: 0.6652 - val_accuracy: 0.7000 - val_loss: 0.6792\n",
      "Epoch 28/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.8067 - loss: 0.6642\n",
      "Epoch 28: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 466ms/step - accuracy: 0.8097 - loss: 0.6644 - val_accuracy: 0.7000 - val_loss: 0.6787\n",
      "Epoch 29/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.8067 - loss: 0.6633\n",
      "Epoch 29: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 458ms/step - accuracy: 0.8097 - loss: 0.6635 - val_accuracy: 0.7000 - val_loss: 0.6781\n",
      "Epoch 30/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8637 - loss: 0.6624\n",
      "Epoch 30: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 466ms/step - accuracy: 0.8615 - loss: 0.6626 - val_accuracy: 0.7000 - val_loss: 0.6776\n",
      "Epoch 31/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.8637 - loss: 0.6615\n",
      "Epoch 31: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 692ms/step - accuracy: 0.8615 - loss: 0.6617 - val_accuracy: 0.7000 - val_loss: 0.6770\n",
      "Epoch 32/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8637 - loss: 0.6607\n",
      "Epoch 32: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 454ms/step - accuracy: 0.8615 - loss: 0.6609 - val_accuracy: 0.7000 - val_loss: 0.6765\n",
      "Epoch 33/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.8637 - loss: 0.6597\n",
      "Epoch 33: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 481ms/step - accuracy: 0.8615 - loss: 0.6599 - val_accuracy: 0.7000 - val_loss: 0.6759\n",
      "Epoch 34/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.8587 - loss: 0.6588\n",
      "Epoch 34: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 484ms/step - accuracy: 0.8531 - loss: 0.6590 - val_accuracy: 0.7000 - val_loss: 0.6754\n",
      "Epoch 35/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8587 - loss: 0.6579\n",
      "Epoch 35: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 0.8531 - loss: 0.6581 - val_accuracy: 0.7000 - val_loss: 0.6749\n",
      "Epoch 36/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8587 - loss: 0.6570\n",
      "Epoch 36: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 454ms/step - accuracy: 0.8531 - loss: 0.6572 - val_accuracy: 0.7000 - val_loss: 0.6745\n",
      "Epoch 37/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8637 - loss: 0.6561\n",
      "Epoch 37: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 0.8615 - loss: 0.6563 - val_accuracy: 0.7000 - val_loss: 0.6741\n",
      "Epoch 38/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8637 - loss: 0.6552\n",
      "Epoch 38: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 786ms/step - accuracy: 0.8615 - loss: 0.6554 - val_accuracy: 0.7000 - val_loss: 0.6736\n",
      "Epoch 39/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8637 - loss: 0.6544\n",
      "Epoch 39: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step - accuracy: 0.8615 - loss: 0.6546 - val_accuracy: 0.7000 - val_loss: 0.6732\n",
      "Epoch 40/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8637 - loss: 0.6535\n",
      "Epoch 40: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 454ms/step - accuracy: 0.8615 - loss: 0.6538 - val_accuracy: 0.7000 - val_loss: 0.6728\n",
      "Epoch 41/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.8637 - loss: 0.6527\n",
      "Epoch 41: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 463ms/step - accuracy: 0.8615 - loss: 0.6529 - val_accuracy: 0.7000 - val_loss: 0.6724\n",
      "Epoch 42/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8637 - loss: 0.6519\n",
      "Epoch 42: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 449ms/step - accuracy: 0.8615 - loss: 0.6521 - val_accuracy: 0.7000 - val_loss: 0.6722\n",
      "Epoch 43/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8587 - loss: 0.6510\n",
      "Epoch 43: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8531 - loss: 0.6512 - val_accuracy: 0.7000 - val_loss: 0.6718\n",
      "Epoch 44/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8587 - loss: 0.6502\n",
      "Epoch 44: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 444ms/step - accuracy: 0.8531 - loss: 0.6504 - val_accuracy: 0.7000 - val_loss: 0.6715\n",
      "Epoch 45/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8637 - loss: 0.6494\n",
      "Epoch 45: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 889ms/step - accuracy: 0.8615 - loss: 0.6496 - val_accuracy: 0.7000 - val_loss: 0.6712\n",
      "Epoch 46/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.8637 - loss: 0.6485\n",
      "Epoch 46: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 477ms/step - accuracy: 0.8615 - loss: 0.6487 - val_accuracy: 0.7000 - val_loss: 0.6708\n",
      "Epoch 47/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8637 - loss: 0.6477\n",
      "Epoch 47: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 451ms/step - accuracy: 0.8615 - loss: 0.6479 - val_accuracy: 0.7000 - val_loss: 0.6704\n",
      "Epoch 48/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8637 - loss: 0.6468\n",
      "Epoch 48: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 458ms/step - accuracy: 0.8615 - loss: 0.6470 - val_accuracy: 0.7000 - val_loss: 0.6700\n",
      "Epoch 49/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.8637 - loss: 0.6460\n",
      "Epoch 49: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 455ms/step - accuracy: 0.8615 - loss: 0.6462 - val_accuracy: 0.7000 - val_loss: 0.6697\n",
      "Epoch 50/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.8637 - loss: 0.6452\n",
      "Epoch 50: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 453ms/step - accuracy: 0.8615 - loss: 0.6454 - val_accuracy: 0.7000 - val_loss: 0.6693\n",
      "Epoch 51/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8637 - loss: 0.6443\n",
      "Epoch 51: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.8615 - loss: 0.6445 - val_accuracy: 0.7000 - val_loss: 0.6690\n",
      "Epoch 52/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8637 - loss: 0.6435\n",
      "Epoch 52: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 809ms/step - accuracy: 0.8615 - loss: 0.6437 - val_accuracy: 0.7000 - val_loss: 0.6686\n",
      "Epoch 53/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8637 - loss: 0.6427\n",
      "Epoch 53: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 455ms/step - accuracy: 0.8615 - loss: 0.6430 - val_accuracy: 0.7000 - val_loss: 0.6683\n",
      "Epoch 54/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8637 - loss: 0.6420\n",
      "Epoch 54: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 451ms/step - accuracy: 0.8615 - loss: 0.6422 - val_accuracy: 0.7000 - val_loss: 0.6679\n",
      "Epoch 55/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.8637 - loss: 0.6412\n",
      "Epoch 55: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 456ms/step - accuracy: 0.8615 - loss: 0.6414 - val_accuracy: 0.7000 - val_loss: 0.6675\n",
      "Epoch 56/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.8637 - loss: 0.6404\n",
      "Epoch 56: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 456ms/step - accuracy: 0.8615 - loss: 0.6406 - val_accuracy: 0.7000 - val_loss: 0.6670\n",
      "Epoch 57/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8637 - loss: 0.6396\n",
      "Epoch 57: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.8615 - loss: 0.6398 - val_accuracy: 0.7000 - val_loss: 0.6666\n",
      "Epoch 58/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8637 - loss: 0.6388\n",
      "Epoch 58: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 451ms/step - accuracy: 0.8615 - loss: 0.6390 - val_accuracy: 0.7000 - val_loss: 0.6661\n",
      "Epoch 59/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.8637 - loss: 0.6380\n",
      "Epoch 59: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 874ms/step - accuracy: 0.8615 - loss: 0.6383 - val_accuracy: 0.7000 - val_loss: 0.6656\n",
      "Epoch 60/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.8637 - loss: 0.6373\n",
      "Epoch 60: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 471ms/step - accuracy: 0.8615 - loss: 0.6375 - val_accuracy: 0.7000 - val_loss: 0.6651\n",
      "Epoch 61/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.8637 - loss: 0.6365\n",
      "Epoch 61: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 473ms/step - accuracy: 0.8615 - loss: 0.6367 - val_accuracy: 0.7000 - val_loss: 0.6646\n",
      "Epoch 62/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.8637 - loss: 0.6357\n",
      "Epoch 62: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 471ms/step - accuracy: 0.8615 - loss: 0.6359 - val_accuracy: 0.7000 - val_loss: 0.6642\n",
      "Epoch 63/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.8637 - loss: 0.6349\n",
      "Epoch 63: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 463ms/step - accuracy: 0.8615 - loss: 0.6351 - val_accuracy: 0.7000 - val_loss: 0.6638\n",
      "Epoch 64/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8637 - loss: 0.6341\n",
      "Epoch 64: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 451ms/step - accuracy: 0.8615 - loss: 0.6343 - val_accuracy: 0.7000 - val_loss: 0.6632\n",
      "Epoch 65/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.8637 - loss: 0.6333\n",
      "Epoch 65: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 481ms/step - accuracy: 0.8615 - loss: 0.6335 - val_accuracy: 0.7000 - val_loss: 0.6627\n",
      "Epoch 66/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.8637 - loss: 0.6325\n",
      "Epoch 66: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 752ms/step - accuracy: 0.8615 - loss: 0.6327 - val_accuracy: 0.6000 - val_loss: 0.6621\n",
      "Epoch 67/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.8637 - loss: 0.6317\n",
      "Epoch 67: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 457ms/step - accuracy: 0.8615 - loss: 0.6319 - val_accuracy: 0.6000 - val_loss: 0.6616\n",
      "Epoch 68/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.8637 - loss: 0.6308\n",
      "Epoch 68: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 483ms/step - accuracy: 0.8615 - loss: 0.6310 - val_accuracy: 0.6000 - val_loss: 0.6611\n",
      "Epoch 69/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 0.8637 - loss: 0.6300\n",
      "Epoch 69: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 491ms/step - accuracy: 0.8615 - loss: 0.6302 - val_accuracy: 0.6000 - val_loss: 0.6606\n",
      "Epoch 70/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.8637 - loss: 0.6291\n",
      "Epoch 70: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 465ms/step - accuracy: 0.8615 - loss: 0.6293 - val_accuracy: 0.6000 - val_loss: 0.6599\n",
      "Epoch 71/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8637 - loss: 0.6282\n",
      "Epoch 71: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.8615 - loss: 0.6285 - val_accuracy: 0.6000 - val_loss: 0.6593\n",
      "Epoch 72/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.8637 - loss: 0.6274\n",
      "Epoch 72: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.8615 - loss: 0.6276 - val_accuracy: 0.6000 - val_loss: 0.6588\n",
      "Epoch 73/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.8637 - loss: 0.6265\n",
      "Epoch 73: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 789ms/step - accuracy: 0.8615 - loss: 0.6267 - val_accuracy: 0.6000 - val_loss: 0.6583\n",
      "Epoch 74/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8637 - loss: 0.6256\n",
      "Epoch 74: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.8615 - loss: 0.6258 - val_accuracy: 0.6000 - val_loss: 0.6577\n",
      "Epoch 75/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8637 - loss: 0.6247\n",
      "Epoch 75: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 449ms/step - accuracy: 0.8615 - loss: 0.6250 - val_accuracy: 0.7000 - val_loss: 0.6572\n",
      "Epoch 76/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8637 - loss: 0.6238\n",
      "Epoch 76: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 457ms/step - accuracy: 0.8615 - loss: 0.6241 - val_accuracy: 0.7000 - val_loss: 0.6566\n",
      "Epoch 77/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8637 - loss: 0.6229\n",
      "Epoch 77: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 454ms/step - accuracy: 0.8615 - loss: 0.6232 - val_accuracy: 0.7000 - val_loss: 0.6560\n",
      "Epoch 78/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.8637 - loss: 0.6220\n",
      "Epoch 78: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 457ms/step - accuracy: 0.8615 - loss: 0.6222 - val_accuracy: 0.7000 - val_loss: 0.6554\n",
      "Epoch 79/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.8637 - loss: 0.6211\n",
      "Epoch 79: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.8615 - loss: 0.6213 - val_accuracy: 0.7000 - val_loss: 0.6548\n",
      "Epoch 80/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8637 - loss: 0.6202\n",
      "Epoch 80: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 865ms/step - accuracy: 0.8615 - loss: 0.6204 - val_accuracy: 0.7000 - val_loss: 0.6543\n",
      "Epoch 81/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.8637 - loss: 0.6192\n",
      "Epoch 81: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 467ms/step - accuracy: 0.8615 - loss: 0.6194 - val_accuracy: 0.7000 - val_loss: 0.6538\n",
      "Epoch 82/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8637 - loss: 0.6182\n",
      "Epoch 82: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 459ms/step - accuracy: 0.8615 - loss: 0.6184 - val_accuracy: 0.7000 - val_loss: 0.6531\n",
      "Epoch 83/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.8637 - loss: 0.6172\n",
      "Epoch 83: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 455ms/step - accuracy: 0.8615 - loss: 0.6174 - val_accuracy: 0.7000 - val_loss: 0.6525\n",
      "Epoch 84/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8637 - loss: 0.6162\n",
      "Epoch 84: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.8615 - loss: 0.6164 - val_accuracy: 0.6000 - val_loss: 0.6519\n",
      "Epoch 85/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8637 - loss: 0.6152\n",
      "Epoch 85: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 0.8615 - loss: 0.6154 - val_accuracy: 0.6000 - val_loss: 0.6513\n",
      "Epoch 86/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.8637 - loss: 0.6141\n",
      "Epoch 86: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 457ms/step - accuracy: 0.8615 - loss: 0.6144 - val_accuracy: 0.6000 - val_loss: 0.6505\n",
      "Epoch 87/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.8958 - loss: 0.6130\n",
      "Epoch 87: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 832ms/step - accuracy: 0.8924 - loss: 0.6133 - val_accuracy: 0.6000 - val_loss: 0.6498\n",
      "Epoch 88/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8958 - loss: 0.6119\n",
      "Epoch 88: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 466ms/step - accuracy: 0.8924 - loss: 0.6122 - val_accuracy: 0.6000 - val_loss: 0.6491\n",
      "Epoch 89/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.8388 - loss: 0.6108\n",
      "Epoch 89: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 473ms/step - accuracy: 0.8406 - loss: 0.6111 - val_accuracy: 0.6000 - val_loss: 0.6484\n",
      "Epoch 90/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.8388 - loss: 0.6098\n",
      "Epoch 90: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 458ms/step - accuracy: 0.8406 - loss: 0.6101 - val_accuracy: 0.6000 - val_loss: 0.6477\n",
      "Epoch 91/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.8388 - loss: 0.6087\n",
      "Epoch 91: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 483ms/step - accuracy: 0.8406 - loss: 0.6090 - val_accuracy: 0.6000 - val_loss: 0.6470\n",
      "Epoch 92/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.8388 - loss: 0.6078\n",
      "Epoch 92: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 456ms/step - accuracy: 0.8406 - loss: 0.6081 - val_accuracy: 0.6000 - val_loss: 0.6463\n",
      "Epoch 93/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8388 - loss: 0.6068\n",
      "Epoch 93: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 457ms/step - accuracy: 0.8406 - loss: 0.6071 - val_accuracy: 0.6000 - val_loss: 0.6458\n",
      "Epoch 94/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8388 - loss: 0.6058\n",
      "Epoch 94: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 736ms/step - accuracy: 0.8406 - loss: 0.6061 - val_accuracy: 0.6000 - val_loss: 0.6451\n",
      "Epoch 95/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.6048\n",
      "Epoch 95: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445ms/step - accuracy: 0.8406 - loss: 0.6051 - val_accuracy: 0.6000 - val_loss: 0.6445\n",
      "Epoch 96/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.6038\n",
      "Epoch 96: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 451ms/step - accuracy: 0.8406 - loss: 0.6041 - val_accuracy: 0.6000 - val_loss: 0.6439\n",
      "Epoch 97/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8388 - loss: 0.6028\n",
      "Epoch 97: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 451ms/step - accuracy: 0.8406 - loss: 0.6031 - val_accuracy: 0.6000 - val_loss: 0.6432\n",
      "Epoch 98/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8388 - loss: 0.6018\n",
      "Epoch 98: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.8406 - loss: 0.6021 - val_accuracy: 0.6000 - val_loss: 0.6427\n",
      "Epoch 99/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.8388 - loss: 0.6008\n",
      "Epoch 99: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 453ms/step - accuracy: 0.8406 - loss: 0.6012 - val_accuracy: 0.6000 - val_loss: 0.6421\n",
      "Epoch 100/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.8388 - loss: 0.5998\n",
      "Epoch 100: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 451ms/step - accuracy: 0.8406 - loss: 0.6002 - val_accuracy: 0.6000 - val_loss: 0.6416\n",
      "Epoch 101/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.8388 - loss: 0.5988\n",
      "Epoch 101: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 884ms/step - accuracy: 0.8406 - loss: 0.5992 - val_accuracy: 0.6000 - val_loss: 0.6411\n",
      "Epoch 102/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8388 - loss: 0.5978\n",
      "Epoch 102: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 0.8406 - loss: 0.5981 - val_accuracy: 0.6000 - val_loss: 0.6405\n",
      "Epoch 103/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8388 - loss: 0.5968\n",
      "Epoch 103: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step - accuracy: 0.8406 - loss: 0.5971 - val_accuracy: 0.6000 - val_loss: 0.6399\n",
      "Epoch 104/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8388 - loss: 0.5958\n",
      "Epoch 104: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 449ms/step - accuracy: 0.8406 - loss: 0.5961 - val_accuracy: 0.6000 - val_loss: 0.6393\n",
      "Epoch 105/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8388 - loss: 0.5947\n",
      "Epoch 105: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step - accuracy: 0.8406 - loss: 0.5951 - val_accuracy: 0.6000 - val_loss: 0.6388\n",
      "Epoch 106/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8388 - loss: 0.5937\n",
      "Epoch 106: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.8406 - loss: 0.5940 - val_accuracy: 0.6000 - val_loss: 0.6382\n",
      "Epoch 107/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.5926\n",
      "Epoch 107: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8406 - loss: 0.5930 - val_accuracy: 0.6000 - val_loss: 0.6377\n",
      "Epoch 108/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8388 - loss: 0.5916\n",
      "Epoch 108: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 896ms/step - accuracy: 0.8406 - loss: 0.5920 - val_accuracy: 0.6000 - val_loss: 0.6372\n",
      "Epoch 109/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8388 - loss: 0.5906\n",
      "Epoch 109: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step - accuracy: 0.8406 - loss: 0.5909 - val_accuracy: 0.6000 - val_loss: 0.6367\n",
      "Epoch 110/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.5895\n",
      "Epoch 110: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 0.8406 - loss: 0.5899 - val_accuracy: 0.6000 - val_loss: 0.6361\n",
      "Epoch 111/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.5884\n",
      "Epoch 111: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.8406 - loss: 0.5888 - val_accuracy: 0.6000 - val_loss: 0.6356\n",
      "Epoch 112/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.8388 - loss: 0.5873\n",
      "Epoch 112: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 463ms/step - accuracy: 0.8406 - loss: 0.5876 - val_accuracy: 0.6000 - val_loss: 0.6349\n",
      "Epoch 113/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.8388 - loss: 0.5862\n",
      "Epoch 113: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 459ms/step - accuracy: 0.8406 - loss: 0.5865 - val_accuracy: 0.6000 - val_loss: 0.6343\n",
      "Epoch 114/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8388 - loss: 0.5851\n",
      "Epoch 114: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.8406 - loss: 0.5854 - val_accuracy: 0.6000 - val_loss: 0.6337\n",
      "Epoch 115/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.8388 - loss: 0.5840\n",
      "Epoch 115: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 857ms/step - accuracy: 0.8406 - loss: 0.5843 - val_accuracy: 0.6000 - val_loss: 0.6332\n",
      "Epoch 116/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.5828\n",
      "Epoch 116: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step - accuracy: 0.8406 - loss: 0.5831 - val_accuracy: 0.6000 - val_loss: 0.6326\n",
      "Epoch 117/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.8388 - loss: 0.5816\n",
      "Epoch 117: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 468ms/step - accuracy: 0.8406 - loss: 0.5820 - val_accuracy: 0.6000 - val_loss: 0.6320\n",
      "Epoch 118/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.8388 - loss: 0.5805\n",
      "Epoch 118: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 476ms/step - accuracy: 0.8406 - loss: 0.5809 - val_accuracy: 0.6000 - val_loss: 0.6315\n",
      "Epoch 119/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.8388 - loss: 0.5793\n",
      "Epoch 119: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 459ms/step - accuracy: 0.8406 - loss: 0.5797 - val_accuracy: 0.6000 - val_loss: 0.6310\n",
      "Epoch 120/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.8388 - loss: 0.5782\n",
      "Epoch 120: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 466ms/step - accuracy: 0.8406 - loss: 0.5785 - val_accuracy: 0.6000 - val_loss: 0.6304\n",
      "Epoch 121/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.8388 - loss: 0.5771\n",
      "Epoch 121: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 453ms/step - accuracy: 0.8406 - loss: 0.5774 - val_accuracy: 0.6000 - val_loss: 0.6298\n",
      "Epoch 122/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8388 - loss: 0.5759\n",
      "Epoch 122: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 788ms/step - accuracy: 0.8406 - loss: 0.5763 - val_accuracy: 0.6000 - val_loss: 0.6291\n",
      "Epoch 123/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.5747\n",
      "Epoch 123: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8406 - loss: 0.5751 - val_accuracy: 0.6000 - val_loss: 0.6285\n",
      "Epoch 124/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.5735\n",
      "Epoch 124: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445ms/step - accuracy: 0.8406 - loss: 0.5739 - val_accuracy: 0.6000 - val_loss: 0.6278\n",
      "Epoch 125/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.5723\n",
      "Epoch 125: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8406 - loss: 0.5727 - val_accuracy: 0.6000 - val_loss: 0.6272\n",
      "Epoch 126/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.8388 - loss: 0.5711\n",
      "Epoch 126: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.8406 - loss: 0.5715 - val_accuracy: 0.6000 - val_loss: 0.6266\n",
      "Epoch 127/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8388 - loss: 0.5699\n",
      "Epoch 127: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 444ms/step - accuracy: 0.8406 - loss: 0.5703 - val_accuracy: 0.6000 - val_loss: 0.6259\n",
      "Epoch 128/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.5688\n",
      "Epoch 128: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8406 - loss: 0.5691 - val_accuracy: 0.6000 - val_loss: 0.6252\n",
      "Epoch 129/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8388 - loss: 0.5675\n",
      "Epoch 129: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 899ms/step - accuracy: 0.8406 - loss: 0.5679 - val_accuracy: 0.6000 - val_loss: 0.6246\n",
      "Epoch 130/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8388 - loss: 0.5663\n",
      "Epoch 130: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 442ms/step - accuracy: 0.8406 - loss: 0.5667 - val_accuracy: 0.6000 - val_loss: 0.6239\n",
      "Epoch 131/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8388 - loss: 0.5651\n",
      "Epoch 131: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 454ms/step - accuracy: 0.8406 - loss: 0.5655 - val_accuracy: 0.6000 - val_loss: 0.6233\n",
      "Epoch 132/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8388 - loss: 0.5638\n",
      "Epoch 132: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 458ms/step - accuracy: 0.8406 - loss: 0.5642 - val_accuracy: 0.6000 - val_loss: 0.6226\n",
      "Epoch 133/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.8708 - loss: 0.5626\n",
      "Epoch 133: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.8715 - loss: 0.5629 - val_accuracy: 0.6000 - val_loss: 0.6219\n",
      "Epoch 134/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8596 - loss: 0.5613\n",
      "Epoch 134: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step - accuracy: 0.8580 - loss: 0.5617 - val_accuracy: 0.6000 - val_loss: 0.6212\n",
      "Epoch 135/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8596 - loss: 0.5601\n",
      "Epoch 135: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8580 - loss: 0.5604 - val_accuracy: 0.6000 - val_loss: 0.6206\n",
      "Epoch 136/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8596 - loss: 0.5588\n",
      "Epoch 136: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 886ms/step - accuracy: 0.8580 - loss: 0.5592 - val_accuracy: 0.6000 - val_loss: 0.6199\n",
      "Epoch 137/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8596 - loss: 0.5576\n",
      "Epoch 137: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 443ms/step - accuracy: 0.8580 - loss: 0.5579 - val_accuracy: 0.6000 - val_loss: 0.6192\n",
      "Epoch 138/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8596 - loss: 0.5564\n",
      "Epoch 138: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 443ms/step - accuracy: 0.8580 - loss: 0.5567 - val_accuracy: 0.6000 - val_loss: 0.6185\n",
      "Epoch 139/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8596 - loss: 0.5551\n",
      "Epoch 139: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445ms/step - accuracy: 0.8580 - loss: 0.5554 - val_accuracy: 0.6000 - val_loss: 0.6177\n",
      "Epoch 140/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8596 - loss: 0.5538\n",
      "Epoch 140: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8580 - loss: 0.5541 - val_accuracy: 0.6000 - val_loss: 0.6170\n",
      "Epoch 141/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8596 - loss: 0.5525\n",
      "Epoch 141: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 0.8580 - loss: 0.5528 - val_accuracy: 0.7000 - val_loss: 0.6163\n",
      "Epoch 142/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8596 - loss: 0.5512\n",
      "Epoch 142: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.8580 - loss: 0.5514 - val_accuracy: 0.7000 - val_loss: 0.6155\n",
      "Epoch 143/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8596 - loss: 0.5499\n",
      "Epoch 143: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 910ms/step - accuracy: 0.8580 - loss: 0.5501 - val_accuracy: 0.7000 - val_loss: 0.6148\n",
      "Epoch 144/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8596 - loss: 0.5484\n",
      "Epoch 144: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8580 - loss: 0.5487 - val_accuracy: 0.7000 - val_loss: 0.6141\n",
      "Epoch 145/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8596 - loss: 0.5471\n",
      "Epoch 145: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8580 - loss: 0.5474 - val_accuracy: 0.7000 - val_loss: 0.6135\n",
      "Epoch 146/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8708 - loss: 0.5457\n",
      "Epoch 146: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445ms/step - accuracy: 0.8715 - loss: 0.5459 - val_accuracy: 0.7000 - val_loss: 0.6127\n",
      "Epoch 147/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8708 - loss: 0.5443\n",
      "Epoch 147: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8715 - loss: 0.5445 - val_accuracy: 0.7000 - val_loss: 0.6121\n",
      "Epoch 148/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8708 - loss: 0.5428\n",
      "Epoch 148: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 449ms/step - accuracy: 0.8715 - loss: 0.5429 - val_accuracy: 0.7000 - val_loss: 0.6114\n",
      "Epoch 149/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8708 - loss: 0.5412\n",
      "Epoch 149: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.8715 - loss: 0.5413 - val_accuracy: 0.7000 - val_loss: 0.6108\n",
      "Epoch 150/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.8708 - loss: 0.5396\n",
      "Epoch 150: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 886ms/step - accuracy: 0.8715 - loss: 0.5397 - val_accuracy: 0.7000 - val_loss: 0.6101\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "model_training_history = model.fit(x = features_train, \n",
    "                                   y = labels_train, \n",
    "                                   epochs = 150, \n",
    "                                   batch_size = 8,\n",
    "                                   shuffle = True, \n",
    "                                   callbacks=[callbacks],\n",
    "                                   validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2255e125-e7cd-405e-8c76-e0b65d4521a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 224, 224, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cf7356f-7d79-42cf-ae47-0377e61ad03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime as dt\n",
    "\n",
    "# model2_evaluation_history = model.evaluate(features_test, labels_test)\n",
    "\n",
    "# date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "# current_date_time_dt = dt.datetime.now()\n",
    "\n",
    "# current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "# model_evaluation_loss, model_evaluation_accuracy = model2_evaluation_history\n",
    "# model_name = f'Model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "# # Saving your Model\n",
    "# model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fb82a-1e5f-4c6d-9c47-3fb1cdfd8128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01c47a-eaf7-4edb-89a1-2f81191e9414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa7a3824-c046-4049-aecd-0f49026c4256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725937761.795690  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.797529  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.798992  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.799953  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.801169  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.802724  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.803935  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.805585  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.807409  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.809217  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.810867  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.812762  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.814428  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.816156  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.818122  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.821510  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.825007  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.827656  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.830351  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.833071  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.835314  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.837529  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.839794  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.842879  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.845594  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.849118  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.852817  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.856365  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.859867  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.862682  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.865320  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.869467  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.873694  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.880309  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.886700  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.893608  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.900456  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.907566  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.914643  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.926471  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.938725  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.942996  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937761.968143  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.036911  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.039109  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.041557  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.044058  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.046527  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.049351  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.051919  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.054548  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.057731  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.060605  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.063593  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.066967  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.069961  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.073258  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.076677  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.080193  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.084131  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.088225  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.092230  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.095653  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.099505  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.110939  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.114807  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.118706  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.122635  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.127159  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.131177  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.135757  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.140143  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.146007  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.150715  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.155507  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.161373  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.166824  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.171566  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.177067  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.186844  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.196725  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.202171  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.217096  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.226983  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.232589  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.241788  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.249969  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.256065  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.269271  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.277528  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.288373  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.301774  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.314707  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.337376  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.350291  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.366643  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.401614  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.418988  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.423701  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.429160  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.434797  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.440479  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.446238  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.452161  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.458179  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.464268  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.470513  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.476836  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.484936  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.489189  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.495812  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.505084  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.512157  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.522219  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.528988  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.536423  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.545763  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.584529  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.592375  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.601052  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.611133  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.619745  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.640901  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.656230  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.661428  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.662428  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.664544  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.665616  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.667517  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.668649  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.670647  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.671745  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.674033  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.675390  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.677383  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.678851  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.680837  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.682346  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.684191  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.685903  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.688242  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.689933  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.691957  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.693883  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.696761  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.698487  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.701284  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.702968  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.705890  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.707714  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.710441  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.712688  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.716702  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.719004  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.723122  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.725793  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.729258  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.731922  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.736401  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.739022  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.743786  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.748033  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.754045  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.757366  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.761609  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.770336  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.776028  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.779884  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.786361  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.796836  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.802990  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.815308  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.826891  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.849098  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.869238  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.908284  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.910924  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.913780  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.918683  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.948317  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.952537  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.959876  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.965639  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.972098  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.978073  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.983910  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.987863  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.993608  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937762.998105  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.002970  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.009663  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.014934  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.021719  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.027840  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.032582  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.039816  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.061128  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.066699  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.073793  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.081865  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.103278  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.105996  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.108784  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.111052  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.113410  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.123599  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.124470  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.126014  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.127041  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.128663  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.130033  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.131428  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.132674  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.134123  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.135574  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.137109  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.138605  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.140260  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.141555  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.143315  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.144830  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.146703  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.148518  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.150275  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.151498  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.153682  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.155343  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.157564  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.159835  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.161955  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.164101  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.166720  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.168856  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.172019  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.175254  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.178303  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.181079  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.184572  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.186521  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.190757  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.195174  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.199956  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.203687  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.209150  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.213992  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.220507  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.223555  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.235976  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.242999  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.262982  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.291560  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.294419  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.297655  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.299939  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.303005  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.306174  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.308691  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.311214  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.313775  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.317053  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.321192  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.324732  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.343115  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.347042  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.356504  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.362113  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.366497  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.372418  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.377679  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.383273  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.388848  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.404173  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.455689  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.459878  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.465355  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.472069  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.476506  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.483419  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.487816  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.492199  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.496698  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.501180  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.507511  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.517763  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.520079  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.522592  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.535653  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.538951  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.541948  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.545730  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.551034  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.556662  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.560872  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.574290  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.632785  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.637208  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.640356  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.650110  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.653163  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.656380  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.659623  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.662672  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.665679  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.668766  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.671834  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.674980  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.678138  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.681433  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.684848  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.688366  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.691886  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 8s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725937763.695584  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.699860  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.711347  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.717273  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937763.723114  462296 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.801107  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.803181  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.803857  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.804545  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.805528  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.806243  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.807062  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.807808  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.808538  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.809371  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.810071  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.810917  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.811932  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.812967  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.813891  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.814841  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.817240  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.818303  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.819469  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.820608  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.821704  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.823334  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.827215  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.827721  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.828306  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.829047  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.830259  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.831392  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.832319  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.833158  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.834338  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.835801  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.837204  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.838374  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.839800  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.842807  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.845272  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.900889  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.902393  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.903966  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.905783  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.907658  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.909259  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.911023  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.915320  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.928048  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.940520  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.952146  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.963426  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.973634  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937768.992927  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.225674  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.227112  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.228722  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.230543  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.232312  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.234168  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.236307  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.238475  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.240505  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.242569  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.244679  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.247182  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.249772  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.252855  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.255481  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.258412  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.261619  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.267381  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.272389  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.282781  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.288974  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.307312  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.402600  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.403380  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.404264  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.405053  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.405911  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.406681  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.407575  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.408408  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.409586  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.410640  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.411794  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.413921  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.417558  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.420899  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.427773  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.434573  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.438886  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.443097  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.561424  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.562181  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.563006  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.563826  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.564713  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.565541  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.566366  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.567299  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.568221  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.569190  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.570226  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.571238  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.572349  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.573631  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.574949  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.576309  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.577830  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.579350  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.581735  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.584769  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.588198  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.602636  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.636167  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.637358  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.638832  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.640126  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.641523  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.642716  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.643837  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.645142  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.647119  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.648837  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.650752  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.654003  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.660927  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.667500  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.681334  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.694401  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.702341  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.710071  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.943974  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.945233  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.946390  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.947517  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.948837  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.950025  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.951250  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.952629  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.953903  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.955535  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.956968  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.958438  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.959887  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.961881  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.964010  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.965837  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.968218  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.970783  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.975446  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.981094  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937769.987919  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.006443  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.056599  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.057368  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.058028  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.058670  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.059465  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.060159  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.060948  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.061642  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.062357  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.063043  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.063772  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.065500  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.068696  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.072477  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.075973  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.079915  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.083902  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.090824  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.209482  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.210165  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.210877  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.211526  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.212206  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.212968  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.213672  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.214389  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.215204  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.216124  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.216942  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.217796  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.218633  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.219655  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.220800  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.221999  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.223254  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.224730  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.227140  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.229940  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.232872  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.236234  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.251255  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.271784  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.272841  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.274068  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.275106  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.276427  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.277522  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.278522  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.279806  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.280888  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.282041  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.283222  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.286085  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.291766  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.298689  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.305445  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.312710  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.319829  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.333217  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.565954  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.566958  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.567998  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.568990  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.570034  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.571152  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.572210  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.573340  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.574511  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.575778  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.577047  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.578323  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.579698  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.581495  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.583247  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.585068  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.587246  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.589782  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.594860  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.612206  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.708257  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.709003  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.709723  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.710638  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.711450  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.712350  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.713118  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.713906  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.714694  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.715514  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.716298  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.720172  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.723661  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.727724  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.731689  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.735172  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.738623  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.745634  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.861708  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.862327  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.862985  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.866504  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.867175  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.867821  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.868538  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.869207  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.869918  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.870685  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.871449  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.872229  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.873067  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.874104  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.875148  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.876223  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.877439  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.879013  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.880720  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.883958  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.897213  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.911823  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.912792  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.913869  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.915035  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.916411  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.917767  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.924828  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.931062  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.938250  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.945710  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.952346  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.959038  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937770.972417  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725937771.200600  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.201541  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.202478  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.203460  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.204396  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.205378  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.206368  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.207430  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.208497  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.209529  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.210541  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.211619  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.212798  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.213978  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.215324  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.216959  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.218622  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.220579  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.222691  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.225497  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.228511  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.245270  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.323469  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.324100  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.324741  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.325377  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.325998  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.326637  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.327328  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.327954  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.328591  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.329248  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.329911  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.330594  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.331303  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.332086  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.332891  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.333740  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.334564  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.335490  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.336609  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.337836  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.340642  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.342078  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725937771.344679  462297 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    }
   ],
   "source": [
    "labels_pred = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d3fa9bf-b963-4ee2-998d-6f04d01b0768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred = np.argmax(labels_pred, axis = 1)\n",
    "labels_test = np.argmax(labels_test, axis = 1)\n",
    "labels_pred, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e0e471e-a0cb-47d4-89e3-633a26cc0442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.65        26\n",
      "           1       0.63      0.71      0.67        24\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.66      0.66      0.66        50\n",
      "weighted avg       0.66      0.66      0.66        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a534861-e555-4a08-9b66-ef9a7bb76362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_metric(measure_name_1, measure_name_2, plot_title):\n",
    "  \n",
    " \n",
    "  measure_value_1 = model_training_history.history[measure_name_1]\n",
    "  measure_value_2 = model_training_history.history[measure_name_2] \n",
    "  epochs = range(len(measure_value_1))\n",
    "\n",
    "  plt.plot(epochs, measure_value_1, 'blue', label = measure_name_1)\n",
    "  plt.plot(epochs, measure_value_2, 'red', label = measure_name_2)   \n",
    "\n",
    "  plt.title(str(plot_title))\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0ed272e-7af6-4ff1-8df1-b92c6139334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGzCAYAAAAMr0ziAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4MElEQVR4nO3dd1gUVxcG8HdpS5EmSFMUexcVlaBGTESxxhajCdYkGhUrxkSTWKMSe1fUxBZNbLF3xRJrVLAXbAg2sAJWUPZ+f9yPxVVQFsGB5f09zzyyM7Oz58LKHubee65KCCFARERElIMZKR0AERER0bswYSEiIqIcjwkLERER5XhMWIiIiCjHY8JCREREOR4TFiIiIsrxmLAQERFRjseEhYiIiHI8JixERESU4zFhIcXs2bMHKpUKe/bsUToUdO7cGR4eHpl67vDhw6FSqbI2IMqV6tati7p1637w103r/atSqTB8+PB3Pjc73r856f82GQ4mLHmMSqXK0JaRXzRjxozB2rVrc028hqhz587Ily+f0mEoJuXD9l1bRpKIgwcPYvjw4YiLi8u2eMPDw6FSqfDLL7+ke86lS5egUqkQFBSUbXFklVmzZmHhwoVKh6Gjbt26qFChgtJhUDYwUToA+rD+/PNPnceLFy/Gjh073thftmzZd15rzJgx+Pzzz9GiRYusDFFHVsb7NvPmzYNGo8nUc3/55RcMGjTovV6fMqdVq1YoUaKE9vHjx4/Ro0cPtGzZEq1atdLud3Z2fue1Dh48iBEjRqBz586ws7PLjnBRtWpVlClTBn///TdGjRqV5jl//fUXAKB9+/bv9VrPnj2DiUn2/oqfNWsWHB0d0blzZ539derUwbNnz2BmZpatr095CxOWPOb1X4KHDx/Gjh073vuXY3bJbLxPnz6FpaVlhl/H1NQ0U/EBgImJSbZ/MFDaKlWqhEqVKmkf37t3Dz169EClSpVy7Hs6ICAAQ4YMweHDh/HRRx+9cfzvv/9GmTJlULVq1fd6HXNz8/d6/vswMjJS9PXJMLFLiN7w5MkTDBgwAO7u7lCr1ShdujQmTJiAVxf2VqlUePLkCRYtWqS97Z7yV1ZUVBR69uyJ0qVLw8LCAg4ODmjTpg2uXbuWLfGm3AIOCwtDnTp1YGlpiZ9++gkAsG7dOjRp0gRubm5Qq9UoXrw4fv31VyQnJ+tc4/UxANeuXYNKpcKECRMwd+5cFC9eHGq1GtWrV8fRo0d1npvWGACVSoVevXph7dq1qFChAtRqNcqXL4+tW7e+Ef+ePXtQrVo1mJubo3jx4pgzZ06WjytYuXIlvLy8YGFhAUdHR7Rv3x43b97UOScmJgZdunRBoUKFoFar4erqiubNm+v83I4dOwZ/f384OjrCwsICRYsWxddff/3W127atCmKFSuW5jEfHx9Uq1ZN+3jHjh2oXbs27OzskC9fPpQuXVr7s3wfu3btwscffwwrKyvY2dmhefPmOH/+vPb48OHDMXDgQABA0aJFte/plLYvWLAAn376KZycnKBWq1GuXDnMnj07U7EEBAQASL2T8qqwsDBERERoz8no+zctaY1h2b9/P6pXr67zXktLRtrr4eGBs2fPYu/evW90vaU3hiUj78OUbs6bN2+iRYsWyJcvHwoUKIDvv/8+Q+3OqFmzZqF8+fJQq9Vwc3NDYGDgG92Bly5dQuvWreHi4gJzc3MUKlQI7dq1Q3x8vPac7HrP0pv4ZyHpEELgs88+w+7du/HNN9+gcuXK2LZtGwYOHIibN29i8uTJAGRXzbfffosaNWqgW7duAIDixYsDAI4ePYqDBw+iXbt2KFSoEK5du4bZs2ejbt26OHfunF53PjLq/v37aNSoEdq1a4f27dtruwAWLlyIfPnyISgoCPny5cOuXbswdOhQJCQkYPz48e+87l9//YVHjx7hu+++g0qlwrhx49CqVStcvXr1nXdl9u/fj9WrV6Nnz56wtrbGtGnT0Lp1a0RHR8PBwQEAcPz4cTRs2BCurq4YMWIEkpOTMXLkSBQoUOD9vyn/t3DhQnTp0gXVq1dHcHAwYmNjMXXqVBw4cADHjx/Xdn+0bt0aZ8+eRe/eveHh4YE7d+5gx44diI6O1j5u0KABChQogEGDBsHOzg7Xrl3D6tWr3/r6bdu2RceOHXH06FFUr15duz8qKgqHDx/W/hzOnj2Lpk2bolKlShg5ciTUajUuX76MAwcOvFf7d+7ciUaNGqFYsWIYPnw4nj17hunTp6NWrVoIDw+Hh4cHWrVqhYsXL+Lvv//G5MmT4ejoCADan8Ps2bNRvnx5fPbZZzAxMcGGDRvQs2dPaDQaBAYG6hVP0aJFUbNmTaxYsQKTJ0+GsbGx9lhKEvPVV18BeP/376tOnz6t/fkNHz4cL1++xLBhw9LsLstIe6dMmYLevXsjX758+PnnnwG8vesto+9DAEhOToa/vz+8vb0xYcIE7Ny5ExMnTkTx4sXRo0cPvdqdluHDh2PEiBHw8/NDjx49EBERgdmzZ+Po0aM4cOAATE1NkZSUBH9/fyQmJqJ3795wcXHBzZs3sXHjRsTFxcHW1jbb3rOUDkF5WmBgoHj1bbB27VoBQIwaNUrnvM8//1yoVCpx+fJl7T4rKyvRqVOnN6759OnTN/YdOnRIABCLFy/W7tu9e7cAIHbv3p3peIUQwtfXVwAQISEhGYrlu+++E5aWluL58+fafZ06dRJFihTRPo6MjBQAhIODg3jw4IF2/7p16wQAsWHDBu2+YcOGvRETAGFmZqbz/Tp58qQAIKZPn67d16xZM2FpaSlu3ryp3Xfp0iVhYmLyxjXT0qlTJ2FlZZXu8aSkJOHk5CQqVKggnj17pt2/ceNGAUAMHTpUCCHEw4cPBQAxfvz4dK+1Zs0aAUAcPXr0nXG9Kj4+XqjVajFgwACd/ePGjRMqlUpERUUJIYSYPHmyACDu3r2r1/VfdffuXQFADBs2TLuvcuXKwsnJSdy/f1+77+TJk8LIyEh07NhRu2/8+PECgIiMjHzjumm9j/z9/UWxYsV09vn6+gpfX993xjlz5kwBQGzbtk27Lzk5WRQsWFD4+Pi89XUz8v4VQrzxfWjRooUwNzfXfr+FEOLcuXPC2Nj4jfdaRttbvnz5NNv7+v/tjL4PU9oCQIwcOVLnmlWqVBFeXl5vvNbrfH19Rfny5dM9fufOHWFmZiYaNGggkpOTtftnzJghAIj58+cLIYQ4fvy4ACBWrlyZ7rWy4j1LGccuIdKxefNmGBsbo0+fPjr7BwwYACEEtmzZ8s5rWFhYaL9+8eIF7t+/jxIlSsDOzg7h4eFZHjMAqNVqdOnS5a2xPHr0CPfu3cPHH3+Mp0+f4sKFC++8btu2bWFvb699/PHHHwMArl69+s7n+vn5ae86AXK8hY2Njfa5ycnJ2LlzJ1q0aAE3NzfteSVKlECjRo3eef2MOHbsGO7cuYOePXvqjClo0qQJypQpg02bNgGQ3yczMzPs2bMHDx8+TPNaKX8Bb9y4ES9evMhwDDY2NmjUqBFWrFih0624fPlyfPTRRyhcuLDO9detW5fpAdCvu337Nk6cOIHOnTsjf/782v2VKlVC/fr1sXnz5gxd59X3UXx8PO7duwdfX19cvXpVp3sgo9q2bQtTU1OdbqG9e/fi5s2b2u6g1183M+/fFMnJydi2bRtatGih/X4DcrC6v7//G+dndXsz+j58Vffu3XUef/zxxxn6f/cuO3fuRFJSEvr16wcjo9SPwK5du8LGxkYbi62tLQBg27ZtePr0aZrXyo73LKWPCQvpiIqKgpubG6ytrXX2p8zCiYqKeuc1nj17hqFDh2rHwDg6OqJAgQKIi4vL1C+7jChYsGCaMxLOnj2Lli1bwtbWFjY2NihQoIB2MGZGYnn1lzsAbfKS3of6256b8vyU5965cwfPnj3TmeWSIq19mZHy8ypduvQbx8qUKaM9rlarMXbsWGzZsgXOzs6oU6cOxo0bh5iYGO35vr6+aN26NUaMGAFHR0c0b94cCxYsQGJi4jvjaNu2La5fv45Dhw4BAK5cuYKwsDC0bdtW55xatWrh22+/hbOzM9q1a4cVK1a81wfB29pftmxZ3Lt3D0+ePHnndQ4cOAA/Pz/tGJgCBQpoxylk5j3t4OAAf39/rFmzBs+fPwcgu4NMTEzwxRdfaM973/dvirt37+LZs2coWbLkG8fS+t5kdXsz+j5MYW5u/ka36Kv/d95HerGYmZmhWLFi2uNFixZFUFAQfv/9dzg6OsLf3x8zZ87UaX92vGcpfUxYKMv17t0bo0ePxhdffIEVK1Zg+/bt2LFjBxwcHLLtP/KrfxGmiIuLg6+vL06ePImRI0diw4YN2LFjB8aOHQsAGYrl1fEFr3r1TkF2PFcJ/fr1w8WLFxEcHAxzc3MMGTIEZcuWxfHjxwHIQZyrVq3CoUOH0KtXL9y8eRNff/01vLy88Pjx47deu1mzZrC0tMSKFSsAACtWrICRkRHatGmjPcfCwgL//vsvdu7ciQ4dOuDUqVNo27Yt6tevn6WDLfV15coV1KtXD/fu3cOkSZOwadMm7NixA/379weQsfdRWtq3b4+EhARs3LgRSUlJ+Oeff7RjTICsef9mRna1Vx/p/d/50CZOnIhTp07hp59+wrNnz9CnTx+UL18eN27cAJBz37OGigkL6ShSpAhu3bqFR48e6exPuf1cpEgR7b70ZrGsWrUKnTp1wsSJE/H555+jfv36qF27drYW5ErLnj17cP/+fSxcuBB9+/ZF06ZN4efnp9PFoyQnJyeYm5vj8uXLbxxLa19mpPy8IiIi3jgWERGh8/ME5MDpAQMGYPv27Thz5gySkpIwceJEnXM++ugjjB49GseOHcPSpUtx9uxZLFu27K1xWFlZoWnTpli5ciU0Gg2WL1+Ojz/+WKcrDJDTYevVq4dJkybh3LlzGD16NHbt2oXdu3dnpvlvbf+FCxfg6OgIKysrAOm/nzds2IDExESsX78e3333HRo3bgw/P780k2R9fPbZZ7C2tsZff/2FLVu24OHDhzrdQVn5/i1QoAAsLCxw6dKlN469/r3Rp70Zncmm7/swO6UXS1JSEiIjI9+IpWLFivjll1/w77//Yt++fbh58yZCQkK0x7P6PUvpY8JCOho3bozk5GTMmDFDZ//kyZOhUql0xlZYWVmlmYQYGxu/cRdh+vTpH/wvjpS/0l6NJSkpCbNmzfqgcaTH2NgYfn5+WLt2LW7duqXdf/ny5QyNFcqIatWqwcnJCSEhITpdN1u2bMH58+fRpEkTALJuTUrXRIrixYvD2tpa+7yHDx++8XOtXLkyAGS4W+jWrVv4/fffcfLkSZ3uIAB48ODBG8/R5/ppcXV1ReXKlbFo0SKd9+qZM2ewfft2NG7cWLsvJXF5/T2d1vsoPj4eCxYsyFRMKSwsLNCyZUts3rwZs2fPhpWVFZo3b/7W183s+9fY2Bj+/v5Yu3YtoqOjtfvPnz+Pbdu2vXHu66+bXnvT+x3wuoy+Dz8EPz8/mJmZYdq0aTpt/OOPPxAfH6+NJSEhAS9fvtR5bsWKFWFkZKRtQ3a8Zyl9nNZMOpo1a4ZPPvkEP//8M65duwZPT09s374d69atQ79+/XQGkXp5eWHnzp2YNGkS3NzcULRoUXh7e6Np06b4888/YWtri3LlyuHQoUPYuXOndirvh1KzZk3Y29ujU6dO6NOnD1QqFf78888c1SUzfPhwbN++HbVq1UKPHj20yWKFChVw4sSJDF3jxYsXaVZNzZ8/P3r27ImxY8eiS5cu8PX1xZdffqmdTurh4aG9zX/x4kXUq1cPX3zxBcqVKwcTExOsWbMGsbGxaNeuHQBg0aJFmDVrFlq2bInixYvj0aNHmDdvHmxsbHQ++NPTuHFjWFtb4/vvv4exsTFat26tc3zkyJH4999/0aRJExQpUgR37tzBrFmzUKhQIdSuXTtD34u0jB8/Ho0aNYKPjw+++eYb7bRmW1tbnTolXl5eAICff/4Z7dq1g6mpKZo1a4YGDRrAzMwMzZo1w3fffYfHjx9j3rx5cHJywu3btzMdFyC7hRYvXoxt27YhICBAmzQBWf/+HTFiBLZu3YqPP/4YPXv2xMuXLzF9+nSUL18ep06d0p6nT3u9vLwwe/ZsjBo1CiVKlICTkxM+/fTTN17b1NQ0Q+/DrHL37t00/08ULVoUAQEBGDx4MEaMGIGGDRvis88+Q0REBGbNmoXq1atrxwjt2rULvXr1Qps2bVCqVCm8fPkSf/75p857N7ves5QOReYmUY6R1jThR48eif79+ws3NzdhamoqSpYsKcaPHy80Go3OeRcuXBB16tQRFhYWAoB2ivPDhw9Fly5dhKOjo8iXL5/w9/cXFy5cEEWKFNGZBp2V05rTm8Z44MAB8dFHHwkLCwvh5uYmfvjhB7Ft27Y3Xje9ac1pTfPFa9NF05vWHBgY+MZzX/8eCCFEaGioqFKlijAzMxPFixcXv//+uxgwYIAwNzdP57uQKmUKaFpb8eLFtectX75cVKlSRajVapE/f34REBAgbty4oT1+7949ERgYKMqUKSOsrKyEra2t8Pb2FitWrNCeEx4eLr788ktRuHBhoVarhZOTk2jatKk4duzYO+NMERAQIAAIPz+/N46FhoaK5s2bCzc3N2FmZibc3NzEl19+KS5evJjh66c1rVkIIXbu3Clq1aolLCwshI2NjWjWrJk4d+7cG8//9ddfRcGCBYWRkZHOFOf169eLSpUqCXNzc+Hh4SHGjh0r5s+f/8Y06IxOa07x8uVL4erqKgCIzZs3v3E8s+9fId58nwohxN69e4WXl5cwMzMTxYoVEyEhIWm+fzPa3piYGNGkSRNhbW0tAGjbnt7/7Xe9D1PaktZU/bTiTEtKmYO0tnr16mnPmzFjhihTpowwNTUVzs7OokePHuLhw4fa41evXhVff/21KF68uDA3Nxf58+cXn3zyidi5c6f2nKx4z1LGqYTIQX9uEhEAoEWLFjh79myaYw6IiPIijmEhUtizZ890Hl+6dAmbN2/O0ArDRER5Be+wECnM1dUVnTt31taAmD17NhITE3H8+PE062YQEeVFHHRLpLCGDRvi77//RkxMDNRqNXx8fDBmzBgmK0REr+AdFiIiIsrxOIaFiIiIcjwmLERERJTjGcwYFo1Gg1u3bsHa2jrD5aKJiIhIWUIIPHr0CG5ubjoraL/OYBKWW7duwd3dXekwiIiIKBOuX7+OQoUKpXvcYBIWa2trALLBNjY2CkdDREREGZGQkAB3d3ft53h6DCZhSekGsrGxYcJCRESUy7xrOAcH3RIREVGOx4SFiIiIcjwmLERERJTjGcwYFiIiytuEEHj58iWSk5OVDoVeYWxsDBMTk/cuOcKEhYiIcr2kpCTcvn0bT58+VToUSoOlpSVcXV1hZmaW6WswYSEiolxNo9EgMjISxsbGcHNzg5mZGQuI5hBCCCQlJeHu3buIjIxEyZIl31oc7m2YsBARUa6WlJQEjUYDd3d3WFpaKh0OvcbCwgKmpqaIiopCUlISzM3NM3UdDrolIiKDkNm/3Cn7ZcXPhj9dIiIiyvGYsBAREVGOx4SFiIhIIXXr1kW/fv2UDiNXYMJCREREOR4TlrdITAQWLABatQI0GqWjISIiyruYsLxFYiLQrx+wZg2wZYvS0RARUUYJATx5oswmROZifvjwITp27Ah7e3tYWlqiUaNGuHTpkvZ4VFQUmjVrBnt7e1hZWaF8+fLYvHmz9rkBAQEoUKAALCwsULJkSSxYsCArvpU5BuuwvIWNDdC1KzBxIjBpEtCkidIRERFRRjx9CuTLp8xrP34MWFnp/7zOnTvj0qVLWL9+PWxsbPDjjz+icePGOHfuHExNTREYGIikpCT8+++/sLKywrlz55Dv/40cMmQIzp07hy1btsDR0RGXL1/Gs2fPsrhlymLC8g69ewNTpgC7dgEnTwKenkpHREREhiYlUTlw4ABq1qwJAFi6dCnc3d2xdu1atGnTBtHR0WjdujUqVqwIAChWrJj2+dHR0ahSpQqqVasGAPDw8PjgbchuTFjeoUgR4PPPgeXLgcmTgYULlY6IiIjexdJS3ulQ6rX1df78eZiYmMDb21u7z8HBAaVLl8b58+cBAH369EGPHj2wfft2+Pn5oXXr1qhUqRIAoEePHmjdujXCw8PRoEEDtGjRQpv4GIpMjWGZOXMmPDw8YG5uDm9vbxw5ciTdc+vWrQuVSvXG1uSV/hUhBIYOHQpXV1dYWFjAz89Pp99OaUFB8t+//gJu31Y2FiIiejeVSnbLKLFl1zJG3377La5evYoOHTrg9OnTqFatGqZPnw4AaNSoEaKiotC/f3/cunUL9erVw/fff589gShE74Rl+fLlCAoKwrBhwxAeHg5PT0/4+/vjzp07aZ6/evVq3L59W7udOXMGxsbGaNOmjfaccePGYdq0aQgJCcF///0HKysr+Pv74/nz55lvWRaqUQOoVQt48QKYOVPpaIiIyNCULVsWL1++xH///afdd//+fURERKBcuXLafe7u7ujevTtWr16NAQMGYN68edpjBQoUQKdOnbBkyRJMmTIFc+fO/aBtyG56JyyTJk1C165d0aVLF5QrVw4hISGwtLTE/Pnz0zw/f/78cHFx0W47duyApaWlNmERQmDKlCn45Zdf0Lx5c1SqVAmLFy/GrVu3sHbt2vdqXFZKucsye7YcBU5ERJRVSpYsiebNm6Nr167Yv38/Tp48ifbt26NgwYJo3rw5AKBfv37Ytm0bIiMjER4ejt27d6Ns2bIAgKFDh2LdunW4fPkyzp49i40bN2qPGQq9EpakpCSEhYXBz88v9QJGRvDz88OhQ4cydI0//vgD7dq1g9X/h1BHRkYiJiZG55q2trbw9vZ+6zUTExORkJCgs2Wn5s2B4sWBBw+AESOy9aWIiCgPWrBgAby8vNC0aVP4+PhACIHNmzfD1NQUAJCcnIzAwECULVsWDRs2RKlSpTBr1iwAgJmZGQYPHoxKlSqhTp06MDY2xrJly5RsTpbTa9DtvXv3kJycDGdnZ539zs7OuHDhwjuff+TIEZw5cwZ//PGHdl9MTIz2Gq9fM+VYWoKDgzHiA2YOxsZytlCzZnKK81dfAZUrf7CXJyIiA7Rnzx7t1/b29li8eHG656aMV0nLL7/8gl9++SUrQ8txPmjhuD/++AMVK1ZEjRo13vtagwcPRnx8vHa7fv16FkT4dk2bAm3aAMnJsj5LcnK2vyQRERFBz4TF0dERxsbGiI2N1dkfGxsLFxeXtz73yZMnWLZsGb755hud/SnP0/eaarUaNjY2Olu2uHBBp8zt1KmArS1w7BgH4BIREX0oeiUsZmZm8PLyQmhoqHafRqNBaGgofHx83vrclStXIjExEe3bt9fZX7RoUbi4uOhcMyEhAf/99987r5ntYmKABg1kP9D/b9O5ugJjx8rDP/0EREUpGB8REVEeoXeXUFBQEObNm4dFixbh/Pnz6NGjB548eYIuXboAADp27IjBgwe/8bw//vgDLVq0gIODg85+lUqFfv36YdSoUVi/fj1Onz6Njh07ws3NDS1atMhcq7KKgwNQt67s++nUCRg/HoDsDqpdW84W6tKFCyMSERFlN70r3bZt2xZ3797F0KFDERMTg8qVK2Pr1q3aQbPR0dEwMtLNgyIiIrB//35s3749zWv+8MMPePLkCbp164a4uDjUrl0bW7duhbm5eSaalIVMTWVpW2dnYMIE4IcfgJgYGI0bhwULjOHpCezeDcyYAfTpo2yoREREhkwlRGbXlcxZEhISYGtri/j4+OwZzzJhAjBwoPz644+BJUswa2NhBAYC5ubAiRNA6dJZ/7JERPR2z58/R2RkJIoWLar8H7qUprf9jDL6+f1BZwnlat9/DyxbBlhbA/v2AZ6e6FFgFerXB54/Bzp2BF6+VDpIIiIiw8SERR9t2wLHj8ta/XFxUH3RBmtNP0dp61s4coQF5YiIiLILExZ9FS8O7N8P/PwzYGwMy83/4NTLsuiBWRgzSoNXJjsRERFRFmHCkhmmpsCoUUB4OODtDbNnCZiFQGxHffz4ZTReKylDRESULTw8PDBlypQMnatSqXLUGn36YsLyPipVAg4cAKZPh7C0RD3sQujdiljitxCaZIMYy0xERJQjMGF5X8bGQK9eUJ08iSeVa8IWCRhwpgvO1egMPH2qdHREREQGgQlLVilRAlbH/sWRlmPwEsaoEL4YTyrXBK5eVToyIqK8RwhZ3VOJLYPVQubOnQs3NzdoXqs+2rx5c3z99de4cuUKmjdvDmdnZ+TLlw/Vq1fHzp07s+xbdPr0aXz66aewsLCAg4MDunXrhsePH2uP79mzBzVq1ICVlRXs7OxQq1YtRP2/vPvJkyfxySefwNraGjY2NvDy8sKxY8eyLLa0MGHJSsbGqP7PYIypuwN3UABWl05CU9UL+PdfpSMjIspbnj4F8uVTZsvg3fU2bdrg/v372L17t3bfgwcPsHXrVgQEBODx48do3LgxQkNDcfz4cTRs2BDNmjVDdHT0e397njx5An9/f9jb2+Po0aNYuXIldu7ciV69egEAXr58iRYtWsDX1xenTp3CoUOH0K1bN6hUKgBAQEAAChUqhKNHjyIsLAyDBg2Cqanpe8f1VsJAxMfHCwAiPj5e6VBEXJwQNQtfF4fgLQQgNObmQqxbp3RYREQG6dmzZ+LcuXPi2bNnqTsfPxZC3uv48NvjxxmOvXnz5uLrr7/WPp4zZ45wc3MTycnJaZ5fvnx5MX36dO3jIkWKiMmTJ2fotQCINWvWCCGEmDt3rrC3txePX4l106ZNwsjISMTExIj79+8LAGLPnj1pXsva2losXLgwQ68rRDo/o//L6Oc377BkA1tbYMqqQqhvvBvr0Qyq58+BVq1kmX8iIsp+lpbA48fKbJaWGQ4zICAA//zzDxITEwEAS5cuRbt27WBkZITHjx/j+++/R9myZWFnZ4d8+fLh/PnzWXKH5fz58/D09ISVlZV2X61ataDRaBAREYH8+fOjc+fO8Pf3R7NmzTB16lTcvn1be25QUBC+/fZb+Pn54bfffsOVK1feO6Z3YcKSTapXB0aMs0ArrMZio05yAcUuXYBZs5QOjYjI8KlUgJWVMtv/u00yolmzZhBCYNOmTbh+/Tr27duHgIAAAMD333+PNWvWYMyYMdi3bx9OnDiBihUrIikpKbu+azoWLFiAQ4cOoWbNmli+fDlKlSqFw4cPAwCGDx+Os2fPokmTJti1axfKlSuHNWvWZGs8TFiyUf/+QNPmJuismY8/bPrLnYGBwOzZygZGREQ5grm5OVq1aoWlS5fi77//RunSpVG1alUAwIEDB9C5c2e0bNkSFStWhIuLC65du5Ylr1u2bFmcPHkST5480e47cOAAjIyMUPqVhfGqVKmCwYMH4+DBg6hQoQL++usv7bFSpUqhf//+2L59O1q1aoUFCxZkSWzpYcKSjVQqYMECoIiHEb5NmIi1Jb6XB3r2BEJClA2OiIhyhICAAGzatAnz58/X3l0BgJIlS2L16tU4ceIETp48ia+++uqNGUXv85rm5ubo1KkTzpw5g927d6N3797o0KEDnJ2dERkZicGDB+PQoUOIiorC9u3bcenSJZQtWxbPnj1Dr169sGfPHkRFReHAgQM4evQoypYtmyWxpYcJSzaztwdWrgTMzFRoeXkcTtQbIA/06CHvtiQkKBsgEREp6tNPP0X+/PkRERGBr776Srt/0qRJsLe3R82aNdGsWTP4+/tr7768L0tLS2zbtg0PHjxA9erV8fnnn6NevXqYMWOG9viFCxfQunVrlCpVCt26dUNgYCC+++47GBsb4/79++jYsSNKlSqFL774Ao0aNcKIbF5QT/X/kcO5XkaXp1bK1KlAv36AhbnA9Q4/wWHeb/JAoUJyXEvTpnr1exIRkfT8+XNERkaiaNGiMDc3VzocSsPbfkYZ/fzmHZYPpHdvwM8PePZcBf/wYLzYGgoUKwbcuAF89hlQtCgQFCRL/RtGDklERJRlmLB8IEZGclazvT0QFgaM2PcpcPo0MHAgYGEBREUBkycDtWsDJUrIxRWvX1c6bCIiygWWLl2KfPnypbmVL19e6fCyBLuEPrAVK4C2bWUCs2cP8PHHkFURt28HVq8G1q4FHj2SJ6tUQOvWwI8/AtWqKRg1EVHOxS4h4NGjR4iNjU3zmKmpKYoUKfKBI9KVFV1CTFgU0LEj8OefgKsrcPw44Oz8ysEnT2TiMn++zGhSfPqpTFzq1+dYFyKiVzBhyfk4hiWXmjULKFsWuH0b+PJLWVNOy8oK6NAB2L0bOHVKfm1iAuzaBfj7A1WrAn//Dbx8qVj8REQ5kYH8/W2QsuJnw4RFAfnyAf/8I3OT3buBYcPSObFiRWDxYuDKFaBvX1nu+cQJ4KuvgFKlgJkzM7zIFhGRoUpZdO8pfx/mWCk/m/dZIJFdQgpatkzeYQGA5cuBL754xxPu35e3Z6ZNA+7dk/scHWXJ/y5d5G0bIqI86Pbt24iLi4OTkxMsLS21qwqTsoQQePr0Ke7cuQM7Ozu4urq+cQ7HsOQSffvK/MPUVI63bdw4A096+lSW0J04EYiMTN3/0Ufy7kvr1oCbW3aFTESU4wghEBMTg7i4OKVDoTTY2dnBxcUlzUSSCUsukZwMtG8v77aYmwNbtwK+vhl88suXwMaNMnnZtCl1MIxKJacftWkjk5c0MloiIkOUnJyMFy9eKB0GvcLU1BTGxsbpHmfCkou8eCHzig0b5PiW0FCgRg09LxITIwfjrlwJHDqUul+lAurUSU1eXFyyNHYiIqL3wYQll3n+HGjSRE4GsrcH9u6VY24zJToaWLVKJi//XwocgExefH3lYJlWrV6bT01ERPThMWHJhR4/lmVWDh+WucS+fUDJku950aio1OTlv/9S9xsZ6SYvTk7v+UJERET6Y8KSSz18CNStK0uwFC4M/PsvkGUFClOSlxUrgCNHUvcbGckXbd1armtUqFAWvSAREdHbMWHJxWJj5bCTixcBd3c5puW977S87tq11OTl6FHdY9WrAy1ayK1sWVbWJSKibMOEJZe7cUOu7hwRIcfJ7tgBVKiQTS8WGSkr2a1dCxw8qLtadMmSwOefAwEBgIEsoEVERDlHtpbmnzlzJjw8PGBubg5vb28cebV7IQ1xcXEIDAyEq6sr1Go1SpUqhc2bN2uPJycnY8iQIShatCgsLCxQvHhx/Prrr3m6zHKhQrI7qFIlOQHI11fmEtmiaFHg+++B/fvlegHz5skRwGZmwKVLQHCwzJY8PYGxY2XXEhER0Yck9LRs2TJhZmYm5s+fL86ePSu6du0q7OzsRGxsbJrnJyYmimrVqonGjRuL/fv3i8jISLFnzx5x4sQJ7TmjR48WDg4OYuPGjSIyMlKsXLlS5MuXT0ydOjXDccXHxwsAIj4+Xt8m5Wj37wtRo4YQgBCmpkLMmfMBXzwhQYhly4Ro3ly+uLz3IrfatYWYN0+Ix48/YEBERGRoMvr5rXeXkLe3N6pXr44ZM2YAADQaDdzd3dG7d28MGjTojfNDQkIwfvx4XLhwId01BJo2bQpnZ2f88ccf2n2tW7eGhYUFlixZkqG4DK1L6FWPH8vK+6tWycdduwLTpwNq9QcM4uFD2W30119yFemUt42trVx+ulMnuTAjx7sQEZEesqVLKCkpCWFhYfDz80u9gJER/Pz8cOjVYmWvWL9+PXx8fBAYGAhnZ2dUqFABY8aMQfIrSxTXrFkToaGhuHjxIgDg5MmT2L9/Pxo1apRuLImJiUhISNDZDFW+fHJs7JgxMh+YNw/45BPg1q0PGIS9PfDtt7JQzPXrwLhxQPHiQHy8zJ6qVQM8PORaAwcO6I6DISIiek96JSz37t1DcnIynF8rOObs7IyYmJg0n3P16lWsWrUKycnJ2Lx5M4YMGYKJEydi1KhR2nMGDRqEdu3aoUyZMjA1NUWVKlXQr18/BAQEpBtLcHAwbG1ttZu7u7s+Tcl1VCpg8GBZgd/OThaz9fLKxnEtb1OwIDBwoJzGtG2bHJRraSkL1k2bBtSuLVeTHjVK7iMiInpPmRp0qw+NRgMnJyfMnTsXXl5eaNu2LX7++WeEhIRoz1mxYgWWLl2Kv/76C+Hh4Vi0aBEmTJiARYsWpXvdwYMHIz4+Xrtdv349u5uSIzRqJGchly8vB+PWrQvMnatQMEZGQIMGsijdvXvAunWye8jKCrh8GRgyRN51qVcPWLwYePJEoUCJiCi30ythcXR0hLGxMWJjY3X2x8bGwiWdNWpcXV1RqlQpnYWPypYti5iYGCQlJQEABg4cqL3LUrFiRXTo0AH9+/dHcHBwurGo1WrY2NjobHlFiRKyGu7nn8t1iL77DujWDUhMVDAoCwtZdG7RIplJLVok+62EkN1InTrJ+dldush1BzQaBYMlIqLcRq+ExczMDF5eXggNDdXu02g0CA0NhY+PT5rPqVWrFi5fvgzNKx9QFy9ehKurK8zMzAAAT58+hZGRbijGxsY6zyFdOWJcS3ry5ZN3WnbtkjVeRo6U410ePwYWLpS3hYoXB4YPB65eVThYIiLKFfSdfrRs2TKhVqvFwoULxblz50S3bt2EnZ2diImJEUII0aFDBzFo0CDt+dHR0cLa2lr06tVLREREiI0bNwonJycxatQo7TmdOnUSBQsW1E5rXr16tXB0dBQ//PBDhuMy1GnNGbF5sxB2dnK2sYuLEPv3Kx1RGjQaGdi33wphY6M7RdrXV4ilS4V49kzpKImI6APL6Oe33gmLEEJMnz5dFC5cWJiZmYkaNWqIw4cPa4/5+vqKTp066Zx/8OBB4e3tLdRqtShWrJgYPXq0ePnypfZ4QkKC6Nu3ryhcuLAwNzcXxYoVEz///LNITEzMcEx5OWERQohLl4SoUCG1Xsvs2TJHyJGePJEJSoMGQqhUqYlL/vxC9OkjxOHDOTh4IiLKStlWhyWnMuQ6LBn1+DHw9ddyDCwAfPMNMGMGYG6ubFxvdeMGMH8+8Pvvcrp0imLFgK++klvZssrFR0RE2YprCeVRQgDjx8sp0BoNUKOGrPeW4xdgTk4Gtm4Fli6Vs42ePk095ukpE5d27eQS1kREZDCYsORx27fLz/eHDwEnJ3nXpU4dpaPKoCdPgPXrZVXdrVuBly9Tj338sUxePv8ccHRULkYiIsoSTFgIV68CrVoBJ08CJibApElAr165rHr+/fupSwL8+29qBV0TE1kDpk0buax1jr+FREREaWHCQgBkz8q33wJ//y0fd+wIhITIsim5zo0bwPLlMnkJD9c9VqaMTGBatJB3YUxMFAmRiIj0w4SFtIQApkyR1fSTk4GKFYFly4By5ZSO7D1ERMgsbMsW4Ngx3UJ0Dg5As2ZAy5ZA/fq5NDsjIsobmLDQG3btAr78ErhzR36GT50q777kqi6itMTFAbt3Axs2yLEv9++nHrOyAvz9gYYN5b8ctEtElKMwYaE0xcTIbqEdO+Tjpk3l1OciRZSNK8u8fAns2wesWQOsXas7VRqQXUf+/nLz9ZWLNhIRkWKYsFC6NBpgwgTgl1/kWkSWlrJ6ft++Bjb0QwggLAzYvFmuKn34sG7XkampnPddpw5QqxZQtSrg6qpcvEREeRATFnqnc+fkwon798vHlSsDc+bIz3CDFBcHhIbK5GXbNiA6+s1znJ1l4lKnjtyqVQP+v+YVERFlPSYslCEaDbBggRyQ+/ChHM/SsycwejRga6t0dNlICDnve98+uXr0kSPAhQtvriJtbi4L11WtCnh5ya18eXl3hoiI3hsTFtLLnTvA998Df/4pHzs7A+PGAR06GMCg3Ix6+hQ4fVp2Hf37r9zu3XvzPLVa3o6qW1fWgKlVizORiIgyiQkLZcquXUCPHsDFi/JxrVpyUG7lyoqGpQyNBrh8WdZ8CQuTW3g4EB+ve55aLb9R9erJzcvLwAYDERFlHyYslGlJScDkycCvv8oq+UZGMon59VfA3l7p6BSW0pV04IAcDxMaCty8qXuOra28+1KvnrwDU6ZMHrpNRUSkHyYs9N5u3AAGDABWrJCPCxQAfvsN6NxZJjEEmcBERKQmL7t3y8G9r3JzAz79VCYxvr5A8eJMYIiI/o8JC2WZ0FCgd2/g/Hn52NsbmDlT9nzQa5KTZbdRaCiwc6ecgpWYqHuOm5ucgeTrKzfegSGiPIwJC2WpFy+AadOA4cOBx4/l52u3bnI2kYOD0tHlYM+fAwcPysFBKbORkpJ0zylQQDeBqVCBt7CIKM9gwkLZ4tYtOQX6r7/k4/z5geBg4JtvAGNjZWPLFZ49S52FtHcvcOiQTGpeZW8vF3BMSWA8PTmIl4gMFhMWylZ79wK9egFnzsjH1arJ2UTe3srGleskJgJHj6YmMAcOyJHOr7KxkWNgGjWSayJxPSQiMiBMWCjbvXgBzJoFDB0KJCTIfd98I++4FCigbGy51osXcgxMSgKzb1/qNzdFuXIycWnUSHYlsRIvEeViTFjog4mJAX78EVi8WD62s5NjXXr2ZEHY95YyiHfrVrm9vh6SnR3w2WfA558D9evLyrxERLkIExb64A4ckN1EJ07Ix+XKAVOmyM9RyiIPHsiltrdulYs63rmTeszaWi6//fnn8g4MV6ImolyACQspIjkZ+OMP4KefgPv35b4WLYCJE4FixRQNzfAkJ8ss8Z9/5PZqATtLS6BxY6B1a5nE5MunXJxERG/BhIUU9fCh7BaaOVN+rqrVsgjd4MH87MwWGo2cMr1qlUxerl1LPWZuLse7tGkjkxdra8XCJCJ6HRMWyhHOngX69ZM11ACgYEFg7Fjgq69YKy3bCAEcPy6Tl1WrgEuXUo+p1anJS5MmBr4kNxHlBkxYKMcQAli3DggKAiIj5b5atWQhuqpVlY3N4AkBnDoFrFwpt5RVLQFZOKdWLZnANG4MVKzILJKIPjgmLJTjPH8OTJokq+M+fSo/G7/5Rj52clI6ujxACOD0abk41D//ABcu6B4vWFAmLy1bAg0asFgdEX0QTFgox7pxQ06DTqmWa2sLjBoFdO/Oz8gPKjIS2LJFzjbatUtW4U3h7Cz77Tp0ACpX5p0XIso2TFgoxztwAOjTR5YZAeTn4syZQM2aioaVNz1/LgvVbdwILF8O3L2beqxCBZm4BATIuzBERFmICQvlCsnJwNy5wM8/y5lFANC5sxyYy24ihbx4AWzbJisBrl+futq0SgXUqwd07Ci7jTjdi4iyABMWylXu3pVTnv/4Qz5mN1EOERcnB+suXgzs35+638oKaNVKJi+ffMKVL4ko0zL6+Z2pNexnzpwJDw8PmJubw9vbG0eOHHnr+XFxcQgMDISrqyvUajVKlSqFzZs365xz8+ZNtG/fHg4ODrCwsEDFihVx7NixzIRHuVCBAsDvv8vFi6tWBeLjgd695aKKBw4oHV0eZmcHdO0q1zS6cgUYMQIoUUIu0Pjnn7KMceHCclBSykqYRETZQO+EZfny5QgKCsKwYcMQHh4OT09P+Pv7486rJcJfkZSUhPr16+PatWtYtWoVIiIiMG/ePBR8pS/84cOHqFWrFkxNTbFlyxacO3cOEydOhL29feZbRrnSRx/J+mezZgH29sDJk0Dt2kCXLrrDKkgBxYrJlS4vXgQOHpS3v+ztgVu3gHHj5LToqlWByZPlAlNERFlI7y4hb29vVK9eHTNmzAAAaDQauLu7o3fv3hg0aNAb54eEhGD8+PG4cOECTNNZCW/QoEE4cOAA9u3bl4kmSOwSMjyvdxPZ28uVoLt2BYwydW+QslxiIrBpk+wy2rxZjn8BZBdR48ZycSk/P/7AiChd2dIllJSUhLCwMPj5+aVewMgIfn5+OHToUJrPWb9+PXx8fBAYGAhnZ2dUqFABY8aMQXJyss451apVQ5s2beDk5IQqVapg3rx5b40lMTERCQkJOhsZlle7iSpXloNyu3cHfHxSZxaRwtRqOZZl7Vp5p2XGDMDbW46m3rAB8PcHypYFpk8H+H+UiN6DXgnLvXv3kJycDGdnZ539zs7OiEnnFvDVq1exatUqJCcnY/PmzRgyZAgmTpyIUaNG6Zwze/ZslCxZEtu2bUOPHj3Qp08fLFq0KN1YgoODYWtrq93c3d31aQrlIh99BBw9Kivj2tjILqPq1eUYl7g4paMjLUdHIDAQOHwYOH9e/oCsrWUXUp8+ckp0r15yvQYiIj3p1SV069YtFCxYEAcPHoSPj492/w8//IC9e/fiv//+e+M5pUqVwvPnzxEZGQnj/88kmDRpEsaPH4/bt28DAMzMzFCtWjUcPHhQ+7w+ffrg6NGj6d65SUxMRGLKdEvIW0ru7u7sEjJwt28D33+fWnTO2VmuBM21iXKoR4/k4NwZM2QSk8LLC+jUCWjXTt5KI6I8K1u6hBwdHWFsbIzY2Fid/bGxsXBxcUnzOa6urihVqpQ2WQGAsmXLIiYmBklJSdpzypUrp/O8smXLIjo6Ot1Y1Go1bGxsdDYyfK6uwNKlcjHF0qWB2FigfXvg0091Pw8ph7C2Bnr2lHdVdu4EWrSQ89TDwuRdFzc3oHlzuVTAK3+AEBG9Tq+ExczMDF5eXggNDdXu02g0CA0N1bnj8qpatWrh8uXL0Gg02n0XL16Eq6srzMzMtOdEREToPO/ixYsoUqSIPuFRHlKvnpxBNHo0YG4O7NkDeHrKQbpPnyodHb0hpejcmjVyrMu0aXLO+suXsjjd55/LbLRHDzloyTDKQxFRVhJ6WrZsmVCr1WLhwoXi3Llzolu3bsLOzk7ExMQIIYTo0KGDGDRokPb86OhoYW1tLXr16iUiIiLExo0bhZOTkxg1apT2nCNHjggTExMxevRocenSJbF06VJhaWkplixZkuG44uPjBQARHx+vb5Mol7t6VYimTYWQn3JCFCkixLp1SkdFGXL2rBCDBglRqFDqDxAQokQJIUaOlD9cIjJoGf381jthEUKI6dOni8KFCwszMzNRo0YNcfjwYe0xX19f0alTJ53zDx48KLy9vYVarRbFihUTo0ePFi9fvtQ5Z8OGDaJChQpCrVaLMmXKiLlz5+oVExMWWrdOiMKFUz/zmjUTIjJS6agoQ16+FCI0VIhOnYSwstJNXurUEeL334WIi1M6SiLKBhn9/GZpfjIoT57Ikv4TJsjeBgsLuU7RgAGy64hygSdPZNfR4sVy3EvKryhzczmFOjBQzm3nKGsig8C1hChPO3dOfq7t2SMfFy0KjB8vP+/4OZeL3LghR1kvXix/qCmqVpWDdtu2ZSZKlMtl61pCRDlduXLArl3AkiWy/EdkpBzX+cknwIkTSkdHGVaoUOo6RUePAt98IxOU8HC5rLe7u7yFduOG0pESUTZjwkIGS6UCAgKAiAhgyBD5Obd3r/zjvGtXOSWacgmVSs4q+v134Pp1uUaDuztw7x4wZgxQpIhciHHRIlbUJTJQ7BKiPCM6Wv6xvmyZfGxtLROZPn1khXnKZV6+BNatk2X/9+5N3W9uLmu7tG8vlwZIZw0zIsoZOIaFKB0HDgB9+8raZQBQvLgcpNu8Oce35FpXr8ryx0uWyFtqKRwc5DiX9u3lGg/8ARPlOExYiN5Co5EV4wcPluX+AVktd8oUoGJFRUOj9yGEHN+yZAnw99+6/X4lSshMtUsXwMpKuRiJSAcTFqIMePxYDoeYOFFWhjcyArp1A379Va7lR7nYy5epI69Xr5bTpQEgf365XMB338lBvUSkKCYsRHqIjJTjW1aulI/t7IARI2SleA6BMABPnsip0RMmyO4jQGanTZrIDLVRI+CV9c6I6MPhtGYiPRQtCqxYIcduenoCcXGy96ByZVm7jHI5KyuZfV68KLNSX1/ZL7hhA9CsGeDhITPU69eVjpSI0sGEhegVderIwbizZ8vxmufOydmyLVum/mFOuZixsSzIs2cPcOECEBQkf9A3bgDDh8vMtX17WfeFiHIUJixErzE2Brp3By5dAnr3lo/XrpXF6H75RY57IQNQurQcvHTjhpxh5OsLJCfLyroVK8ppY4cPKx0lEf0fExaidNjbA9Omycq49erJQbmjRwNlysjPNMMY/UUwNwe+/FLedTl2TN6BUamA9evlmkWffgrs2MEfOJHCmLAQvUOFCvLzavVqOdTh5k3Za/Dxx3IGLRkQLy85xuX8eTn92cQE2L0baNBA1nHZuJGJC5FCmLAQZYBKJcexnD8vV4O2tJQF6KpVk2X+U2q5kIEoXRqYPx+4ckWWQrawAI4ckQN0vbzkatIajdJREuUpTFiI9GBuLtfai4gAvvpK/rH9+++yJtnQoVzGxuAULgxMnSrnvQ8cKGcbHT8ul/329ASWL5fjXogo2zFhIcqEQoXkOJZ9+wBvb+DpU1lsrkQJYM4cfoYZHGdnYNw44No1mbHa2MiZRO3ayT7DJUtkoToiyjZMWIjeQ+3awKFDwKpVQKlSwN27coZRtWoymSED4+go+wSvXZPToO3s5PToDh3kaOz584EXLxQOksgwMWEhek8qFdC6tfyDe+pU+Rl24oSs6dKunVwlmgyMvT0wbBgQFQWMGSMTmStXgG++kZnrnDlyWhkRZRkmLERZxNRUjs+8eFHeZTEykkMcypSRRVRTlrIhA2JjI1fQvHZNlv13dpZfd+8u+wenTweePVM6SiKDwISFKIsVKCAr5YaFybssz57J3oOSJYG5cznUwSBZWQEDBsjBuVOnAm5usiBdnz5AsWKyG+nOHaWjJMrVmLAQZZPKlWUtsuXLZcX327flAsEVKshZsSznYYAsLGSScuUKMGuWnGUUEwMMGQK4u8uxLv/+yx8+USYwYSHKRioV8MUXsn7L1KlyqENEhJwVW7MmB+YaLHNzudjipUvAn3/KqWRJSXI2ka8vULy47Ce8cUPpSIlyDZUQhpHqZ3R5aiIlJSTIoQ4TJ8qp0ADQtCkQHCzvvJABO3oUCAmRlXQfPZL7jI3liO2+feUyACqVsjESKSCjn9+8w0L0AdnYACNHyh6DHj3k59XGjbIG2ddfA9evKx0hZZvq1YE//pBdRCl3WpKTgRUrgFq15PHFizm7iCgdTFiIFODiIoc4nDsn19rTaIAFC+TA3B9+AB48UDpCyjaWlkBAgBzgdOKEnAptbi5HaXfqJMe9DBsmExsi0mLCQqSgUqVkD8Hhw/IP7sREYPx4OcRh3DjOiDV4np5ybYfr12U9l4IF5WyikSNl4tK+vexKIiImLEQ5gbe3XBR482agYkUgLg748UeZ0CxYwFL/Bs/RUdZziYyU08pq1ZIVc5cuBWrUkONb/v5bDtwlyqOYsBDlECoV0KiRXFtv0SL5B/aNG3Jsi6cnsGEDZ8MaPFNTOa1s/37g2DGgY0fAzEzegvvqK3kHpl8/2ZVElMdwlhBRDvX8uRznMnp06piW2rWBsWPllGjKI2JjZcXBkBDg1q3U/Z6eQOfOcjxMgQKKhUf0vjL6+c2EhSiHi4uTScqUKTKJAYAWLeRU6DJlFAyMPqyXL4EdO4CFC4G1a1O7h0xM5Nz4zp2Bxo3lXRqiXIQJC5GBuXlTlvifP1/OKjIykhNMhg+XleApD3nwQI51WbgQOHIkdX+BAvKOS+fO8g4MUS6QrXVYZs6cCQ8PD5ibm8Pb2xtHXv0Pk4a4uDgEBgbC1dUVarUapUqVwubNm9M897fffoNKpUK/fv0yExqRwSpYEJg3T64K3aKFTFrmzZNr7P30k7wTQ3lE/vyykM9//8k3xMCBcq783bvyVlzlykCVKrK88t27SkdLlCX0TliWL1+OoKAgDBs2DOHh4fD09IS/vz/upLOwV1JSEurXr49r165h1apViIiIwLx581CwYME3zj169CjmzJmDSpUq6d8SojyibFm5FtGBA3IyybNnsnuoeHFg0iTWHctzypeXc+CvXwc2bQLatJEDdU+ckAN03dyAli2BdevkzCOi3EroqUaNGiIwMFD7ODk5Wbi5uYng4OA0z589e7YoVqyYSEpKeut1Hz16JEqWLCl27NghfH19Rd++ffWKKz4+XgAQ8fHxej2PKDfTaIRYt06IcuWEkHOIhChSRIhFi4R4+VLp6Egx9+4JMWOGENWqpb4xACEKFBCiXz8hTp9WOkIirYx+fut1hyUpKQlhYWHw8/PT7jMyMoKfnx8OHTqU5nPWr18PHx8fBAYGwtnZGRUqVMCYMWOQ/FphicDAQDRp0kTn2m+TmJiIhIQEnY0or1GpgM8+A06elFXfCxYEoqJkwVRPTzk20zBGqZFeHByAwEBZdO70aeD77wFn59Quo4oVgY8/lnVeeEuOcgm9EpZ79+4hOTkZzs7OOvudnZ0Rk04Z6atXr2LVqlVITk7G5s2bMWTIEEycOBGjRo3SnrNs2TKEh4cjODg4w7EEBwfD1tZWu7m7u+vTFCKDYmIi67VcuiRnFNnbA2fPyp4AHx9ZlI7yqAoVZPnkGzfkwlUtW8pFrPbvl5V0XV3leJhDh5jdUo6W7YXjNBoNnJycMHfuXHh5eaFt27b4+eefERISAgC4fv06+vbti6VLl8Lc3DzD1x08eDDi4+O123WuGkcECwu5FtHVq3IgrqWlHJf56aeAv79crobyKBMToEkTYPVqeRtuxAigUCHg4UNZ46VmTVlaeeRI+QYiymH0SlgcHR1hbGyM2NhYnf2xsbFwcXFJ8zmurq4oVaoUjI2NtfvKli2LmJgYbRfTnTt3ULVqVZiYmMDExAR79+7FtGnTYGJi8kbXUQq1Wg0bGxudjYgkOztZcO7KFaBXL1maY/t2oFo1WUg1IkLpCElRBQsCQ4cC167J2i4dOsjs9vJlufBi8eJAnTpyGhqnn1EOoVfCYmZmBi8vL4SGhmr3aTQahIaGwsfHJ83n1KpVC5cvX4ZGo9Huu3jxIlxdXWFmZoZ69erh9OnTOHHihHarVq0aAgICcOLECZ1Eh4j04+ICTJ8uE5QOHeSYl5Ur5cSSrl1lLwHlYcbGgJ8fsHixrKi7aJF8rFIB+/YB3brJN1HbtrI7ibOMSEn6juZdtmyZUKvVYuHCheLcuXOiW7duws7OTsTExAghhOjQoYMYNGiQ9vzo6GhhbW0tevXqJSIiIsTGjRuFk5OTGDVqVLqvwVlCRNnj1CkhmjVLnTSiVgsxYIAQd+8qHRnlKNevC/Hbb7rTz1JmGfXtK0RYmJyiRpQFsmWWEAC0bdsWEyZMwNChQ1G5cmWcOHECW7du1Q7EjY6Oxu3bt7Xnu7u7Y9u2bTh69CgqVaqEPn36oG/fvhg0aFBW5VxElEEVKwLr18saLnXqyAkiEycCxYrJoQuPHikdIeUIhQrJ5cLPnJEDn/r2lVV0796Vxei8vORg3rFjeZuOPhiW5ifKo4QAtm2Tg3OPH5f7ChQAhgwBvvtO1h4j0nrxQg6EWrxYFqFLmQ6tUslR3R07Aq1aAfnyKRsn5TpcS4iIMkSjkeNahgyR06IBWe4/OBho3Vp+HhHpiIsDVq2Sycu+fan7LS1l0tK5s0xi+OahDGDCQkR6efFCLqw4bJgcfwnIGi4TJsgZr0RpiowEliyRycvly6n7y5SRU9Q6dgSsrZWLj3I8JixElCmPHskkZcIE4OlTua9VK+C334CSJZWNjXIwIYDDh+VMo6VLgceP5X5ra3nHJTAQKF1a0RApZ8rW1ZqJyHBZW8uaYpcuAd9+CxgZyVpj5coBvXtz8V9Kh0olb8mFhAA3bwLTpslCdI8eybn1ZcrI6oXr1gEvXyodLeVCTFiIKE1ubrJu2MmTQOPG8jNmxgw5vuW334Dnz5WOkHIsGxuZ3Z4/L0d2N2smE5rt24EWLeS0tF9/BaKjlY6UchF2CRFRhuzaJdfQS5lRVLSo7DZq2ZJjKykDIiPl3Zc//gDu35f7VCqgXj2gSxeZyFhaKhoiKYNjWIgoy2k0cnzl4MHArVtyX926cgFgT08lI6Nc4/lzOS1t/nxgz57U/TY2sqJu586ya4lZcJ7BhIWIss3jx7Jm2IQJ8vPHyEiOdxk1StZyIcqQq1fl7KJFi+S6RilKlZKJS4cOsogdGTQmLESU7a5dk6tDr1wpH9vYyDX1evdm4TnSg0YD/PsvsGCBrO+SMj1NpQLq15fJS4sWcjlyMjhMWIjog/n3X6Bfv9TxLSVLypL/TZvyzj7p6dEjmbQsXCjfWClsbYF27WTy4u3NN5YBYcJCRB9UcrL8jPnpJ+DOHbmvfn1g8mS5OjSR3q5cSe0yiopK3V+mjExc2rcHChZULDzKGkxYiEgRCQnA6NFyIG5SEmBsDPToAQwfDjg4KB0d5UoajRygu3ChvPvy7Jncb2Qka7v07i3/NWKljtyIheOISBE2NnJA7rlzcthBcrKs31KypKwf9uKF0hFSrmNkJNcmWrwYiImRU6Nr15aJzJYtslBQ+fJy2nTK+BcyOExYiChbFC8OrFkDhIYCFSsCDx8CffrI6c/btikdHeVaNjbA11/LRRcvXgT695flmS9ckLfy3N1lv+TNm0pHSlmMCQsRZatPPwXCw4HZswFHR1n8tGFDOSA3IkLp6ChXK1kSmDQJuHFDDpYqWhR48EAuNe7hIce4HDumdJSURZiwEFG2MzEBuneX6xP17y8fb9oEVKgABAUBcXFKR0i5mo2NnKZ26ZJc+Orjj+VaEkuXAtWry8erV8v+Scq1mLAQ0QdjZyf/ID5zBmjSRH6mTJ4s/1CeM4efJ/SejI3lWhH//ivvrLRvL7Pj/fuB1q3lQliTJ8uR4ZTrMGEhog+udGlg40Zg61agbFng3j15B6ZmTdl9RPTevLyAP/+U06F/+gnIn19WOgwKktVz+/eX6xtRrsGEhYgU4+8vV4OeOlXe1T9yRN7B790biI9XOjoyCG5ucp799etyFlGZMrI43ZQp8o5Lq1ZyAK9hVPgwaExYiEhRpqZy9tCFC8CXX8qZqjNmyLswf/3FzxHKIpaWwHffAWfPyqnQDRrIN9uaNUCdOjJTXrpUFg+iHIkJCxHlCK6uMkHZuVOufRcbCwQEAH5+MpkhyhJGRnKa2rZtcjBV166AuTkQFibHvBQtCowZI+fhU47ChIWIcpR69YBTp+TKz+bmwK5dQKVKwM8/syYYZbHy5YG5c4HoaODXXwEXF+DWLflmK1IEGDQodZ0JUhwTFiLKcdRq+Zlx9qwsYvrihfyjt3x5OViXKEsVKAD88oscoLt4sZxv/+iRLNlcpEhqVxIpigkLEeVYxYrJBGX1ajmx49o1oFkzOXM1Olrp6MjgmJkBHTrIkeDr1gE1agDPn8u7MBUqyNU8N26UY1/og2PCQkQ5mkolE5Tz54GBA2VZjbVr5XToceO4NhFlAyMj4LPPgMOH5aKLLVvKfTt3yoy5dGlg2jTWc/nAuFozEeUqZ84APXvKmagAUK6cLPtfp46ycZGBu3ZNTl/7/ffUOffW1nJdo9695eJZlClcrZmIDFKFCsDevcDChXJtonPnAF9foFMnjo+kbOThAUyYINctmjlT3mV59EgWESpZUtZz+e8/paM0aExYiCjXUalkghIRIcdDqlRyrGTp0rI2GIcYULbJl0/e4jt3TtZzadhQFgtaswb46COgbl1g82YWEMoGTFiIKNfKn18mKIcOAVWqyEUUe/SQnxkXLyodHRm0lHouW7bIfsrOneUAq7175UJZnp7AkiUcZJWFmLAQUa7n7S3L+k+dClhZyfEtnp7A+PFygUWibFW+PLBggVybKChI3oU5fVrOOCpRQr4xnzxROspcL1MJy8yZM+Hh4QFzc3N4e3vjyJEjbz0/Li4OgYGBcHV1hVqtRqlSpbB582bt8eDgYFSvXh3W1tZwcnJCixYtEBERkZnQiCiPMjGRJf7PnJHVcZ8/B374QS6oeOaM0tFRnlCoEDBxopxzP3o04OQkv+7XDyhcGBgyRJZwpkzRO2FZvnw5goKCMGzYMISHh8PT0xP+/v64k85ot6SkJNSvXx/Xrl3DqlWrEBERgXnz5qFgwYLac/bu3YvAwEAcPnwYO3bswIsXL9CgQQM8YUZKRHry8AC2bwf++AOwtQWOHgWqVgVGjOAyMfSB2NvLFaKvXZN9lsWLAw8eyPLNhQsD33zDQnSZoPe0Zm9vb1SvXh0zZswAAGg0Gri7u6N3794YNGjQG+eHhIRg/PjxuHDhAkxNTTP0Gnfv3oWTkxP27t2LOhmcq8hpzUT0ulu35JiW9evl44oVgfnzgWrVlI2L8pjkZDkod+JEWdslRcOGwIABcj0KlUq5+BSWLdOak5KSEBYWBj8/v9QLGBnBz88Phw4dSvM569evh4+PDwIDA+Hs7IwKFSpgzJgxSE5OTvd14v8/xz1//vzpnpOYmIiEhASdjYjoVW5ussjc33/LKdCnT8vxLj/+KLuMiD4IY2Pg88/l6PADB+QUaJUK2LpVVs+tUUMO3uXMorfSK2G5d+8ekpOT4ezsrLPf2dkZMTExaT7n6tWrWLVqFZKTk7F582YMGTIEEydOxKhRo9I8X6PRoF+/fqhVqxYqVKiQbizBwcGwtbXVbu7u7vo0hYjyCJUKaNdOzkJt105OeR43Ts4qesfwO6KsV7Mm8M8/wKVLQK9egIUFcOyYXDSrdm1g0ybOy09Hts8S0mg0cHJywty5c+Hl5YW2bdvi559/RkhISJrnBwYG4syZM1i2bNlbrzt48GDEx8drt+vXr2dH+ERkIAoUkHda1q6Vi/JeuAD4+MihBomJSkdHeU7x4sD06XKcS1CQXJr84EGgaVOgVClg8mSW/n+NXgmLo6MjjI2NEfvaKOfY2Fi4uLik+RxXV1eUKlUKxsbG2n1ly5ZFTEwMkl4bAderVy9s3LgRu3fvRqFChd4ai1qtho2Njc5GRPQuzZvLWUNffSX/kA0OBry8gLAwpSOjPMnJSY5tuXpVJi62tsCVK/LrYsWAKVOYUf+fXgmLmZkZvLy8EBoaqt2n0WgQGhoKHx+fNJ9Tq1YtXL58GZpXbnFdvHgRrq6uMDMzAwAIIdCrVy+sWbMGu3btQtGiRTPTFiKiDHFwAJYulXfmCxSQEza8vYGhQzmTiBTi6ioTl5s35cyi0qWB+/eB/v2BMmXkWhR5vQid0NOyZcuEWq0WCxcuFOfOnRPdunUTdnZ2IiYmRgghRIcOHcSgQYO050dHRwtra2vRq1cvERERITZu3CicnJzEqFGjtOf06NFD2Nraij179ojbt29rt6dPn2Y4rvj4eAFAxMfH69skIsrD7twRok0bIeSIRyE8PYU4cULpqCjPe/FCiHnzhHBzS31zFi4sxLRpQjx5onR0WSqjn996JyxCCDF9+nRRuHBhYWZmJmrUqCEOHz6sPebr6ys6deqkc/7BgweFt7e3UKvVolixYmL06NHi5cuXqUEAaW4LFizIcExMWIjofSxfLoSDg/xcMDERYuRIIZKSlI6K8rwnT4QYN04IZ+fUxKVAASFGjxbi4UOlo8sSGf381rsOS07FOixE9L5iY4Hu3eXAXEAWnFu0SK4QTaSo589lt9C4cXIJAACwsZHlnb//Xo59yaWypQ4LEZEhc3YGVq+W41vs7YHwcDkgNziYaxKRwszNZTZ98aJcVLF8eTmLaNQoOeNo6lSDH5zLhIWI6BUqlZxBdPasnGGalCSnPtesCZw/r3R0lOeZmAABAcCpU3LUeJkycnBuv37y66VLDbaOCxMWIqI0uLrKkv4LF6auSVSlilwB+i2Fuok+DCMjWTH39Glg7lz5hr12DWjfXt4W3LDB4BIXJixEROlQqYBOnWTdloYN5R33H34AfH1lqQwixZmYAF27ApcvA2PGyHEtJ04An30GlC0LzJoFGMhCwkxYiIjeoVAhYPNmYN48wNpaLgfj6QnMmcPlXyiHsLQEBg+WBeh++EHeFrx4EQgMBNzdgUGDgBs3lI7yvTBhISLKAJUK+PZbOXTA11f+0dq9u1wC5tYtpaMj+j8HB2DsWOD6dWDaNDkg9+FDua9oUaBjx1x7e5AJCxGRHjw8gF27gEmTALVaLrhboQLwjuXPiD4sa2ugd28gIkLO0/f1lVPd/vxTDs797juZ1OQiTFiIiPRkZCQrpqdMe374EPjyS7ka9P37SkdH9ApjY7mA1p49cuR4o0YycZk7V65V9NVXuWbZciYsRESZVK4ccOgQMGyY/FxYvhyoWBHYskXpyIjSUK2aHIy1bx/wyScycfn7b7mQVs2awIoVObrgEBMWIqL3YGoKDB8uE5cyZYDbt+W4lu++Ax4/Vjo6ojTUri37NcPD5TQ4MzP5Bm7bVt51GTsWePBA6SjfwISFiCgLVK8uf//36ycfz50rZxLt369oWETpq1JFFhqKipK3CZ2c5LiWQYPk1LgePXJUtUQmLEREWcTCApg8Wf7xWriwnGFap44c72IgpTDIELm4yNuEUVHAggUy0372DAgJkf2ejRoB27YpPoefCQsRURb75BM5/blLF/k7fsoUOZNo+3alIyN6C3NzoHNn4PhxOUi3RQs5n3/rVlk5sVw54ORJxcJjwkJElA1sbYH58+UYx8KFZdV0f385ZIAziShHU6nkNOg1a2QF3X795DTp69eBIkUUC4sJCxFRNmrUSJb279NHfg4sXiwrpi9bpvgddqJ3K1ZM9nPeuCHXJ7KzUywUJixERNnM2hqYOlWW9C9XDrh7V9Ztad4cuHlT6eiIMsDGRvZ1KogJCxHRB+LjI4cHDB8up0Nv2ACULy+7jni3hejtmLAQEX1AZmZyBml4uJwKHR8PfPONHN8SFaV0dEQ5FxMWIiIFVKgAHDwIjB8vJ2fs2CH3zZoFaDRKR0eU8zBhISJSiIkJ8P33cqZo7dqyMm5goBwqcOmS0tER5SxMWIiIFFaqFLB3LzB9OmBlBfz7L1CpEjBxIpCcrHR0RDkDExYiohzAyAjo1Qs4fRqoVw94/lzefalVCzh3TunoiJTHhIWIKAcpWlSOZ5k3T84k/e8/ueTL6NHAixdKR0ekHCYsREQ5jEoFfPstcPasXPk5KQn45RegRg3gxAmloyNSBhMWIqIcqlAhYONG4M8/gfz5ZbJSvTowZAiQmKh0dEQfFhMWIqIcTKUC2reX41hatwZevgRGjQKqVQPCwpSOjujDYcJCRJQLODsDq1YBK1cCBQrI9Ym8vWURuqQkpaMjyn5MWIiIcpHPP5djW9q0kVOeR46UicvJk0pHRpS9mLAQEeUyBQoAK1YAy5cDDg6pY1tGjeJMIjJcTFiIiHKpL76Qd1tatJCJypAhcoHFs2eVjowo62UqYZk5cyY8PDxgbm4Ob29vHDly5K3nx8XFITAwEK6urlCr1ShVqhQ2b978XtckIiI5tmX1amDJEsDOTg7ErVoVGDuWVXLJsOidsCxfvhxBQUEYNmwYwsPD4enpCX9/f9y5cyfN85OSklC/fn1cu3YNq1atQkREBObNm4eCBQtm+ppERJRKpQICAnTrtgwaBHz8MXDlitLREWUNlRBC6PMEb29vVK9eHTNmzAAAaDQauLu7o3fv3hg0aNAb54eEhGD8+PG4cOECTE1Ns+SaaUlISICtrS3i4+NhY2OjT5OIiAyGEMCiRUDfvkBCApAvHzB1KtCli0xsiHKajH5+63WHJSkpCWFhYfDz80u9gJER/Pz8cOjQoTSfs379evj4+CAwMBDOzs6oUKECxowZg+T/36vMzDUBIDExEQkJCTobEVFep1IBnTsDp04BderIFaC/+QZo1Qq4d0/p6IgyT6+E5d69e0hOToazs7POfmdnZ8TExKT5nKtXr2LVqlVITk7G5s2bMWTIEEycOBGjRo3K9DUBIDg4GLa2ttrN3d1dn6YQERm0IkWAXbvkWBZTU2DtWqBiRWDLFqUjI8qcbJ8lpNFo4OTkhLlz58LLywtt27bFzz//jJCQkPe67uDBgxEfH6/drl+/nkURExEZBmNj4Icf5AKK5coBMTFyjEuvXsDTp0pHR6QfvRIWR0dHGBsbIzY2Vmd/bGwsXFxc0nyOq6srSpUqBWNjY+2+smXLIiYmBklJSZm6JgCo1WrY2NjobERE9KYqVYBjx4A+feTjmTMBLy+W9qfcRa+ExczMDF5eXggNDdXu02g0CA0NhY+PT5rPqVWrFi5fvgyNRqPdd/HiRbi6usLMzCxT1yQiIv1YWMjBt9u2Aa6uwIULwEcfAWPGcPoz5Q56dwkFBQVh3rx5WLRoEc6fP48ePXrgyZMn6NKlCwCgY8eOGDx4sPb8Hj164MGDB+jbty8uXryITZs2YcyYMQgMDMzwNYmIKGs0aACcPi1L/L98Cfz8M+DrC0RGKh0Z0duZ6PuEtm3b4u7duxg6dChiYmJQuXJlbN26VTtoNjo6GkZGqXmQu7s7tm3bhv79+6NSpUooWLAg+vbtix9//DHD1yQioqzj4CBL+//5pxzPcuAA4OkJTJ8OdOzI6c+UM+ldhyWnYh0WIiL9RUYCHTrIpAUAWrcG5syRSQ3Rh5AtdViIiMiwFC0K7N0rx7KYmAD//COnP2/frnRkRLqYsBAR5XHGxsDgwcDhw0CZMsDt24C/P9CvH/D8udLREUlMWIiICEDqVOeUORFTpwLVq8uquURKY8JCRERalpbAjBnApk2AkxNw5oxMWiZPBl6pTkH0wTFhISKiNzRuLKc/N20qV38OCpLdRLduKR0Z5VVMWIiIKE1OTsD69cDs2bLw3M6dckDu6tVKR0Z5ERMWIiJKl0oFdO8OhIcDVasCDx7Iqc/ffCNXgib6UJiwEBHRO5UpAxw6BAwaJJOY+fOBypWBo0eVjozyCiYsRESUIWZmQHAwsHs34O4OXLkC1KwJTJjAAbmU/ZiwEBGRXnx9gZMnZdfQy5fAwIFykG5srNKRkSFjwkJERHqztwdWrpRl/M3N5SrQlSrJf4myAxMWIiLKFJUK6NYNOHYMqFABuHMHaNgQ+OEH4MULpaMjQ8OEhYiI3kv58sCRI0DPnvLx+PHAp5+yZgtlLSYsRET03iwsgJkz5eKJNjbA/v1yGvSePUpHRoaCCQsREWWZVq1kF1HFinIQbr16wNixnEVE748JCxERZamSJeXKzx07ykRl0CCgZUsgLk7pyCg3Y8JCRERZztISWLhQziIyM5Ml/r28gBMnlI6McismLERElC1SZhEdPAh4eABXrwI+PsCiRUpHRrkRExYiIspWXl5AWJgsLvf8OdC5s1yfKDFR6cgoN2HCQkRE2S5/fmDDBmDECHnnZc4c4OOPgehopSOj3IIJCxERfRBGRsDQocDmzTKBOXpUTn3evl3pyCg3YMJCREQfVMOGsovIywu4f18+HjWKU5/p7ZiwEBHRB+fhIYvLde0KCAEMGQJ89hnw8KHSkVFOxYSFiIgUYW4OzJ0LzJ8PqNXApk1AtWqc+kxpY8JCRESK6tLlzanPCxcqHRXlNExYiIhIcVWr6k597tIF+O47+TURwISFiIhyiJSpzyNHyqnPc+fKqc9RUUpHRjkBExYiIsoxjIzkANwtW2QCc+yYvPuybZvSkZHSmLAQEVGO4+8PhIfLQbgPHgCNGgG//sqpz3kZExYiIsqRihQB9u2T6xEJIYvOcepz3pWphGXmzJnw8PCAubk5vL29ceTIkXTPXbhwIVQqlc5mbm6uc87jx4/Rq1cvFCpUCBYWFihXrhxCQkIyExoRERkQc3NZxn/+fPn1pk2y4Nzx40pHRh+a3gnL8uXLERQUhGHDhiE8PByenp7w9/fHnTt30n2OjY0Nbt++rd2iXhtBFRQUhK1bt2LJkiU4f/48+vXrh169emH9+vX6t4iIiAxOytTnokWByEg59XnBAqWjog9J74Rl0qRJ6Nq1K7p06aK9E2JpaYn58+en+xyVSgUXFxft5uzsrHP84MGD6NSpE+rWrQsPDw9069YNnp6eb71zQ0REeUuVKnLqc5MmcqXnr7+W3UWc+pw36JWwJCUlISwsDH5+fqkXMDKCn58fDh06lO7zHj9+jCJFisDd3R3NmzfH2bNndY7XrFkT69evx82bNyGEwO7du3Hx4kU0aNAg3WsmJiYiISFBZyMiIsNmbw+sXy8H4KpUwLx5QO3awLVrSkdG2U2vhOXevXtITk5+4w6Js7MzYmJi0nxO6dKlMX/+fKxbtw5LliyBRqNBzZo1cePGDe0506dPR7ly5VCoUCGYmZmhYcOGmDlzJurUqZNuLMHBwbC1tdVu7u7u+jSFiIhyKSMj4JdfgK1bAQeH1IUUt25VOjLKTtk+S8jHxwcdO3ZE5cqV4evri9WrV6NAgQKYM2eO9pzp06fj8OHDWL9+PcLCwjBx4kQEBgZi586d6V538ODBiI+P127Xr1/P7qYQEVEO0qCBTFZSpj43biyLznHqs2Ey0edkR0dHGBsbIzY2Vmd/bGwsXFxcMnQNU1NTVKlSBZcvXwYAPHv2DD/99BPWrFmDJk2aAAAqVaqEEydOYMKECTrdT69Sq9VQq9X6hE9ERAamSBG56nPfvnI20bBhwOHDwJIlsvAcGQ697rCYmZnBy8sLoaGh2n0ajQahoaHw8fHJ0DWSk5Nx+vRpuLq6AgBevHiBFy9ewMhINxRjY2NomCYTEdE7qNVASIicNWRuLqvkennJwnNkOPTuEgoKCsK8efOwaNEinD9/Hj169MCTJ0/QpUsXAEDHjh0xePBg7fkjR47E9u3bcfXqVYSHh6N9+/aIiorCt99+C0BOefb19cXAgQOxZ88eREZGYuHChVi8eDFatmyZRc0kIiJD17kzcOgQUKyYHIRbs6as30KGQa8uIQBo27Yt7t69i6FDhyImJgaVK1fG1q1btQNxo6Ojde6WPHz4EF27dkVMTAzs7e3h5eWFgwcPoly5ctpzli1bhsGDByMgIAAPHjxAkSJFMHr0aHTv3j0LmkhERHlF5cpy/aGOHYGNG4FvvpFJzPTp8u4L5V4qIYRQOoiskJCQAFtbW8THx8PGxkbpcIiISEEaDTBmjCznLwRQowawZg3g5qZ0ZPS6jH5+cy0hIiIyOK9Ofba3B44ckbOJDh9WOjLKLCYsRERksBo0AI4eBcqXB27fBnx9WdI/t2LCQkREBq14cTmOpWVLIClJlvTv2xd48ULpyEgfTFiIiMjgWVsDq1YBw4fLx9OmAf7+wL17ioZFemDCQkREeYKRkSwst2YNkC8fsHu3HNdy4oTSkVFGMGEhIqI8pUULOfi2eHEgKkrWa1m2TOmo6F2YsBARUZ5TvrwcjOvvDzx7Bnz5JfDjj0BystKRUXqYsBARUZ5kbw9s2iQTFQAYNw5o0kQupEg5DxMWIiLKs4yNgd9+A/7+G7CwALZtk0XmzpxROjJ6HRMWIiLK89q1Aw4eBDw8gCtXgI8+AlavVjoqehUTFiIiIsh1iI4eBT79FHjyBGjdGhgyRJb5J+UxYSEiIvo/R0fZLdS/v3w8apRMXJ48UTYuYsJCRESkw8QEmDQJWLwYMDMD1q4F6taVpf1JOUxYiIiI0tChAxAaCjg4AMeOAd7ewKlTSkeVdzFhISIiSkft2rLIXKlSwPXr8vHWrUpHlTcxYSEiInqLEiXk4ol16wKPHslaLbNnKx1V3sOEhYiI6B3y55eDcTt1krOGevYEgoJYGfdDYsJCRESUAWZmwIIFcuYQAEyeDLRqxRlEHwoTFiIiogxSqYCff5aVcdVqYP16oE4d4NYtpSMzfExYiIiI9NSuHbBrl6zbEh4uZxCdPKl0VIaNCQsREVEm1KwJ/PcfUKYMcOOGnEG0ebPSURkuJixERESZVKyYXIPo00+Bx4+BZs2AGTOUjsowMWEhIiJ6D/b2wJYtwNdfyxlEvXsDfftyBlFWY8JCRET0nszMgN9/B8aMkY+nTQNatJB3XShrMGEhIiLKAioVMHgwsHy5nEG0caOcQXTzptKRGQYmLERERFnoiy+APXuAAgWA48flDKITJ5SOKvdjwkJERJTFPvpIziAqW1beYaldG9i0SemocjcmLERERNmgaFE5g6hePVkNt3lzOc6FMocJCxERUTaxs5MziDp3lrOGunYFRowAhFA6styHCQsREVE2MjUF5s+XJf0BYPhwoFs34OVLRcPKdZiwEBERZTOVSi6aOHs2YGQku4ZatODCifrIVMIyc+ZMeHh4wNzcHN7e3jhy5Ei65y5cuBAqlUpnMzc3f+O88+fP47PPPoOtrS2srKxQvXp1REdHZyY8IiKiHKl7d2D1asDcXA7C/fRT4O5dpaPKHfROWJYvX46goCAMGzYM4eHh8PT0hL+/P+7cuZPuc2xsbHD79m3tFhUVpXP8ypUrqF27NsqUKYM9e/bg1KlTGDJkSJqJDRERUW7WvDkQGgrkzw8cOSLXJLpyRemocj6VEPoN/fH29kb16tUx4/+LJWg0Gri7u6N3794YNGjQG+cvXLgQ/fr1Q1xcXLrXbNeuHUxNTfHnn39mOI7ExEQkJiZqHyckJMDd3R3x8fGwsbHJeIOIiIgUEBEB+PsDUVGAk5O841KtmtJRfXgJCQmwtbV95+e3XndYkpKSEBYWBj8/v9QLGBnBz88Phw4dSvd5jx8/RpEiReDu7o7mzZvj7Nmz2mMajQabNm1CqVKl4O/vDycnJ3h7e2Pt2rVvjSU4OBi2trbazd3dXZ+mEBERKap0aeDQIaByZeDOHaBuXWDrVqWjyrn0Slju3buH5ORkODs76+x3dnZGTExMms8pXbo05s+fj3Xr1mHJkiXQaDSoWbMmbty4AQC4c+cOHj9+jN9++w0NGzbE9u3b0bJlS7Rq1Qp79+5NN5bBgwcjPj5eu12/fl2fphARESnO1RXYuxfw85MDcJs2BRYuVDqqnMkku1/Ax8cHPj4+2sc1a9ZE2bJlMWfOHPz666/QaDQAgObNm6N///4AgMqVK+PgwYMICQmBr69vmtdVq9VQq9XZHT4REVG2srGR3UHffAMsWQJ06SKr4/70k5xdRJJed1gcHR1hbGyM2NhYnf2xsbFwcXHJ0DVMTU1RpUoVXL58WXtNExMTlCtXTue8smXLcpYQERHlCWZmwKJFwI8/yse//AL07CmLzZGkV8JiZmYGLy8vhIaGavdpNBqEhobq3EV5m+TkZJw+fRqurq7aa1avXh0RERE65128eBFFihTRJzwiIqJcy8gI+O03YPp0eWclJARo3Rp4+lTpyHIGvbuEgoKC0KlTJ1SrVg01atTAlClT8OTJE3Tp0gUA0LFjRxQsWBDBwcEAgJEjR+Kjjz5CiRIlEBcXh/HjxyMqKgrffvut9poDBw5E27ZtUadOHXzyySfYunUrNmzYgD179mRNK4mIiHKJXr3k2JaAAGDdOjm+ZcMGwMFB6ciUpXfC0rZtW9y9exdDhw5FTEwMKleujK1bt2oH4kZHR8PIKPXGzcOHD9G1a1fExMTA3t4eXl5eOHjwoE4XUMuWLRESEoLg4GD06dMHpUuXxj///IPatWtnQROJiIhyl9at5VTnzz6TM4lq1wa2bwfy8oRYveuw5FQZncdNRESUW5w7J2u13Lghk5UdO+R0aEOSLXVYiIiI6MMpVw44cAAoVQq4fh34+GMgPFzpqJTBhIWIiCgHK1wY2L8fqFpVrjtUt66s3ZLXMGEhIiLK4QoUAHbvBnx9gUePZDfR+vVKR/VhMWEhIiLKBWxsgC1b5EDcxESgVStAjyX4cj0mLERERLmEhQXwzz9Ax46yqFzHjsCcOUpH9WEwYSEiIspFTEyABQuA3r3l4+7dgSlTFA3pg2DCQkRElMsYGQFTpwI//CAf9+8P/L9eq8FiwkJERJQLqVSylP+wYfLxTz8BQ4YAhlFd7U1MWIiIiHIplQoYPlwmLgAwahQwcKBhJi1MWIiIiHK5H38Epk2TX0+cKNcj0miUjSmrMWEhIiIyAL17A3Pnyrsus2YBXbvKmUSGggkLERGRgejaFVi8WA7KnT8f6NABePFC6aiyBhMWIiIiA9K+PbB8uZz+/PffQNu2QFKS0lG9PyYsREREBubzz4E1awAzM/lvy5bAs2dKR/V+mLAQEREZoKZNgY0bZXXczZvl4ydPlI4q85iwEBERGaj69YGtW4F8+YBdu4CGDXNv0sKEhYiIyIDVqQPs2AHY2gL79wPNmwPPnysdlf6YsBARERm4jz5KvdMSGirHuOS2gbhMWIiIiPKAjz6SY1rMzYFNm4CAAODlS6WjyjgmLERERHmEr6+cNWRqCqxaBXz9de6piMuEhYiIKA9p2BBYsQIwNgb+/BPo2TN3rD3EhIWIiCiPadFCJisqFTBnDjBgQM5PWpiwEBER5UFffgn8/rv8evJkYOhQZeN5FyYsREREedTXXwPTp8uvR40CgoOVjedtmLAQERHlYb16Ab/9Jr/+6Sdg6lRl40kPExYiIqI87scfgSFD5Nf9+snFE3MaJixERESEESOA3r3l1x07Avv2KRvP65iwEBEREVQqOfi2RQtZBbd5c+DCBaWjSsWEhYiIiADI2ixLlwLe3sDDh0CjRkBsrNJRSUxYiIiISMvSEtiwASheHLh2DWjaNGes8JyphGXmzJnw8PCAubk5vL29ceTIkXTPXbhwIVQqlc5mbm6e7vndu3eHSqXClClTMhMaERERvacCBYDNmwEHB+DYMaBdO+XXHdI7YVm+fDmCgoIwbNgwhIeHw9PTE/7+/rhz5066z7GxscHt27e1W1RUVJrnrVmzBocPH4abm5u+YREREVEWKlUKWL8eUKvlool9+ihbDVfvhGXSpEno2rUrunTpgnLlyiEkJASWlpaYP39+us9RqVRwcXHRbs7Ozm+cc/PmTfTu3RtLly6FqampvmERERFRFqtZU45pUamA2bOB7duVi0WvhCUpKQlhYWHw8/NLvYCREfz8/HDo0KF0n/f48WMUKVIE7u7uaN68Oc6ePatzXKPRoEOHDhg4cCDKly+foVgSExORkJCgsxEREVHWat0amDhRVsFt0EC5OPRKWO7du4fk5OQ37pA4OzsjJiYmzeeULl0a8+fPx7p167BkyRJoNBrUrFkTN27c0J4zduxYmJiYoE+fPhmOJTg4GLa2ttrN3d1dn6YQERFRBvXvDwwaJO+0KCXbZwn5+PigY8eOqFy5Mnx9fbF69WoUKFAAc+bMAQCEhYVh6tSp2sG5GTV48GDEx8drt+vXr2dXE4iIiEhheiUsjo6OMDY2Ruxrk7JjY2Ph4uKSoWuYmpqiSpUquHz5MgBg3759uHPnDgoXLgwTExOYmJggKioKAwYMgIeHR7rXUavVsLGx0dmIiIjIMOmVsJiZmcHLywuhoaHafRqNBqGhofDx8cnQNZKTk3H69Gm4uroCADp06IBTp07hxIkT2s3NzQ0DBw7Etm3b9AmPiIiIDJSJvk8ICgpCp06dUK1aNdSoUQNTpkzBkydP0KVLFwBAx44dUbBgQQT/f43qkSNH4qOPPkKJEiUQFxeH8ePHIyoqCt9++y0AwMHBAQ4ODjqvYWpqChcXF5QuXfp920dEREQGQO+EpW3btrh79y6GDh2KmJgYVK5cGVu3btUOxI2OjoaRUeqNm4cPH6Jr166IiYmBvb09vLy8cPDgQZQrVy7rWkFEREQGTSWEkmVgsk5CQgJsbW0RHx/P8SxERES5REY/v7mWEBEREeV4TFiIiIgox2PCQkRERDkeExYiIiLK8ZiwEBERUY7HhIWIiIhyPCYsRERElOPpXTgup0opJ5OQkKBwJERERJRRKZ/b7yoLZzAJy6NHjwAA7u7uCkdCRERE+nr06BFsbW3TPW4wlW41Gg1u3boFa2trqFSqLLtuQkIC3N3dcf369TxTQTevtTmvtRfIe23Oa+0F8l6b81p7AcNpsxACjx49gpubm87SPq8zmDssRkZGKFSoULZd38bGJle/ITIjr7U5r7UXyHttzmvtBfJem/NaewHDaPPb7qyk4KBbIiIiyvGYsBAREVGOx4TlHdRqNYYNGwa1Wq10KB9MXmtzXmsvkPfanNfaC+S9Nue19gJ5r80GM+iWiIiIDBfvsBAREVGOx4SFiIiIcjwmLERERJTjMWEhIiKiHI8JCxEREeV4TFjeYebMmfDw8IC5uTm8vb1x5MgRpUPKEsHBwahevTqsra3h5OSEFi1aICIiQuec58+fIzAwEA4ODsiXLx9at26N2NhYhSLOWr/99htUKhX69eun3WeI7b158ybat28PBwcHWFhYoGLFijh27Jj2uBACQ4cOhaurKywsLODn54dLly4pGHHmJScnY8iQIShatCgsLCxQvHhx/PrrrzoLquX29v77779o1qwZ3NzcoFKpsHbtWp3jGWnfgwcPEBAQABsbG9jZ2eGbb77B48ePP2Ar9PO2Nr948QI//vgjKlasCCsrK7i5uaFjx464deuWzjVyU5vf9TN+Vffu3aFSqTBlyhSd/bmpvfpgwvIWy5cvR1BQEIYNG4bw8HB4enrC398fd+7cUTq097Z3714EBgbi8OHD2LFjB168eIEGDRrgyZMn2nP69++PDRs2YOXKldi7dy9u3bqFVq1aKRh11jh69CjmzJmDSpUq6ew3tPY+fPgQtWrVgqmpKbZs2YJz585h4sSJsLe3154zbtw4TJs2DSEhIfjvv/9gZWUFf39/PH/+XMHIM2fs2LGYPXs2ZsyYgfPnz2Ps2LEYN24cpk+frj0nt7f3yZMn8PT0xMyZM9M8npH2BQQE4OzZs9ixYwc2btyIf//9F926dftQTdDb29r89OlThIeHY8iQIQgPD8fq1asRERGBzz77TOe83NTmd/2MU6xZswaHDx+Gm5vbG8dyU3v1IihdNWrUEIGBgdrHycnJws3NTQQHBysYVfa4c+eOACD27t0rhBAiLi5OmJqaipUrV2rPOX/+vAAgDh06pFSY7+3Ro0eiZMmSYseOHcLX11f07dtXCGGY7f3xxx9F7dq10z2u0WiEi4uLGD9+vHZfXFycUKvV4u+///4QIWapJk2aiK+//lpnX6tWrURAQIAQwvDaC0CsWbNG+zgj7Tt37pwAII4ePao9Z8uWLUKlUombN29+sNgz6/U2p+XIkSMCgIiKihJC5O42p9feGzduiIIFC4ozZ86IIkWKiMmTJ2uP5eb2vgvvsKQjKSkJYWFh8PPz0+4zMjKCn58fDh06pGBk2SM+Ph4AkD9/fgBAWFgYXrx4odP+MmXKoHDhwrm6/YGBgWjSpIlOuwDDbO/69etRrVo1tGnTBk5OTqhSpQrmzZunPR4ZGYmYmBidNtva2sLb2ztXtrlmzZoIDQ3FxYsXAQAnT57E/v370ahRIwCG197XZaR9hw4dgp2dHapVq6Y9x8/PD0ZGRvjvv/8+eMzZIT4+HiqVCnZ2dgAMr80ajQYdOnTAwIEDUb58+TeOG1p7X2UwqzVntXv37iE5ORnOzs46+52dnXHhwgWFosoeGo0G/fr1Q61atVChQgUAQExMDMzMzLT/6VM4OzsjJiZGgSjf37JlyxAeHo6jR4++ccwQ23v16lXMnj0bQUFB+Omnn3D06FH06dMHZmZm6NSpk7Zdab3Hc2ObBw0ahISEBJQpUwbGxsZITk7G6NGjERAQAAAG197XZaR9MTExcHJy0jluYmKC/PnzG8T34Pnz5/jxxx/x5ZdfalcvNrQ2jx07FiYmJujTp0+axw2tva9iwkIIDAzEmTNnsH//fqVDyTbXr19H3759sWPHDpibmysdzgeh0WhQrVo1jBkzBgBQpUoVnDlzBiEhIejUqZPC0WW9FStWYOnSpfjrr79Qvnx5nDhxAv369YObm5tBtpd0vXjxAl988QWEEJg9e7bS4WSLsLAwTJ06FeHh4VCpVEqH88GxSygdjo6OMDY2fmOWSGxsLFxcXBSKKuv16tULGzduxO7du1GoUCHtfhcXFyQlJSEuLk7n/Nza/rCwMNy5cwdVq1aFiYkJTExMsHfvXkybNg0mJiZwdnY2qPYCgKurK8qVK6ezr2zZsoiOjgYAbbsM5T0+cOBADBo0CO3atUPFihXRoUMH9O/fH8HBwQAMr72vy0j7XFxc3pg08PLlSzx48CBXfw9SkpWoqCjs2LFDe3cFMKw279u3D3fu3EHhwoW1v8eioqIwYMAAeHh4ADCs9r6OCUs6zMzM4OXlhdDQUO0+jUaD0NBQ+Pj4KBhZ1hBCoFevXlizZg127dqFokWL6hz38vKCqampTvsjIiIQHR2dK9tfr149nD59GidOnNBu1apVQ0BAgPZrQ2ovANSqVeuNqeoXL15EkSJFAABFixaFi4uLTpsTEhLw33//5co2P336FEZGur/SjI2NodFoABhee1+Xkfb5+PggLi4OYWFh2nN27doFjUYDb2/vDx5zVkhJVi5duoSdO3fCwcFB57ghtblDhw44deqUzu8xNzc3DBw4ENu2bQNgWO19g9KjfnOyZcuWCbVaLRYuXCjOnTsnunXrJuzs7ERMTIzSob23Hj16CFtbW7Fnzx5x+/Zt7fb06VPtOd27dxeFCxcWu3btEseOHRM+Pj7Cx8dHwaiz1quzhIQwvPYeOXJEmJiYiNGjR4tLly6JpUuXCktLS7FkyRLtOb/99puws7MT69atE6dOnRLNmzcXRYsWFc+ePVMw8szp1KmTKFiwoNi4caOIjIwUq1evFo6OjuKHH37QnpPb2/vo0SNx/Phxcfz4cQFATJo0SRw/flw7IyYj7WvYsKGoUqWK+O+//8T+/ftFyZIlxZdffqlUk97pbW1OSkoSn332mShUqJA4ceKEzu+yxMRE7TVyU5vf9TN+3euzhITIXe3VBxOWd5g+fbooXLiwMDMzEzVq1BCHDx9WOqQsASDNbcGCBdpznj17Jnr27Cns7e2FpaWlaNmypbh9+7ZyQWex1xMWQ2zvhg0bRIUKFYRarRZlypQRc+fO1Tmu0WjEkCFDhLOzs1Cr1aJevXoiIiJCoWjfT0JCgujbt68oXLiwMDc3F8WKFRM///yzzgdXbm/v7t270/x/26lTJyFExtp3//598eWXX4p8+fIJGxsb0aVLF/Ho0SMFWpMxb2tzZGRkur/Ldu/erb1Gbmrzu37Gr0srYclN7dWHSohXykASERER5UAcw0JEREQ5HhMWIiIiyvGYsBAREVGOx4SFiIiIcjwmLERERJTjMWEhIiKiHI8JCxEREeV4TFiIiIgox2PCQkRERDkeExYiIiLK8ZiwEBERUY73P9/As2eAlDQuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('loss', 'val_loss', 'Total Training Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8d88c8b-177e-4fab-a3f7-0be5ae9915dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9deef-e07c-486b-86b1-ba3e8f1124b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42a1c225-6070-4719-a440-3804bf2069d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49001873, 0.5099813 ],\n",
       "       [0.54206854, 0.45793143],\n",
       "       [0.5848616 , 0.41513842],\n",
       "       [0.42356133, 0.5764387 ],\n",
       "       [0.55776113, 0.44223887],\n",
       "       [0.45790023, 0.5420998 ],\n",
       "       [0.5843653 , 0.41563472],\n",
       "       [0.43243876, 0.56756127],\n",
       "       [0.35884964, 0.6411504 ],\n",
       "       [0.49701488, 0.5029851 ],\n",
       "       [0.6272271 , 0.3727729 ],\n",
       "       [0.33379427, 0.6662057 ],\n",
       "       [0.3790315 , 0.62096846],\n",
       "       [0.37653285, 0.62346715],\n",
       "       [0.48418686, 0.5158131 ],\n",
       "       [0.49239486, 0.5076052 ],\n",
       "       [0.5561893 , 0.44381076],\n",
       "       [0.6203892 , 0.3796108 ],\n",
       "       [0.474379  , 0.52562106],\n",
       "       [0.5459999 , 0.45400015],\n",
       "       [0.40298527, 0.5970147 ],\n",
       "       [0.434882  , 0.565118  ],\n",
       "       [0.6506277 , 0.3493723 ],\n",
       "       [0.4693686 , 0.5306314 ],\n",
       "       [0.5446251 , 0.45537493],\n",
       "       [0.5673814 , 0.43261865],\n",
       "       [0.6497023 , 0.35029766],\n",
       "       [0.38471863, 0.6152814 ],\n",
       "       [0.5140167 , 0.48598334],\n",
       "       [0.39479116, 0.6052089 ],\n",
       "       [0.33711958, 0.66288036],\n",
       "       [0.50013447, 0.49986556],\n",
       "       [0.4200347 , 0.5799653 ],\n",
       "       [0.5068797 , 0.49312034],\n",
       "       [0.38854578, 0.61145425],\n",
       "       [0.4749889 , 0.52501106],\n",
       "       [0.42652315, 0.57347685],\n",
       "       [0.4353373 , 0.56466275],\n",
       "       [0.40724868, 0.59275126],\n",
       "       [0.5360319 , 0.46396804],\n",
       "       [0.4960985 , 0.5039015 ],\n",
       "       [0.42362532, 0.5763747 ],\n",
       "       [0.56524366, 0.4347563 ],\n",
       "       [0.6442741 , 0.35572588],\n",
       "       [0.6535888 , 0.3464112 ],\n",
       "       [0.40087906, 0.5991209 ],\n",
       "       [0.668256  , 0.33174405],\n",
       "       [0.5282854 , 0.4717146 ],\n",
       "       [0.6259271 , 0.3740729 ],\n",
       "       [0.5322803 , 0.46771964]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred_prob = model.predict(features_test)\n",
    "labels_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7679e01-65a0-4e65-9752-3e07a5644de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782051282051282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, labels_pred_prob[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "auc_score = roc_auc_score(labels_test, labels_pred_prob[:, 1])\n",
    "print(auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e37e0fed-d033-4bc1-b123-7b7ba1ab0c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.03846154, 0.03846154,\n",
       "        0.11538462, 0.11538462, 0.15384615, 0.15384615, 0.38461538,\n",
       "        0.38461538, 0.46153846, 0.46153846, 0.57692308, 0.57692308,\n",
       "        0.80769231, 0.80769231, 1.        ]),\n",
       " array([0.        , 0.04166667, 0.125     , 0.125     , 0.29166667,\n",
       "        0.29166667, 0.45833333, 0.45833333, 0.66666667, 0.66666667,\n",
       "        0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.95833333,\n",
       "        0.95833333, 1.        , 1.        ]),\n",
       " array([       inf, 0.6662057 , 0.6411504 , 0.62346715, 0.6052089 ,\n",
       "        0.5970147 , 0.5763747 , 0.57347685, 0.5306314 , 0.5039015 ,\n",
       "        0.48598334, 0.46771964, 0.45793143, 0.44381076, 0.44223887,\n",
       "        0.3740729 , 0.3727729 , 0.33174405], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cc950c7-e9b5-4a47-8f51-fcc3dec0e350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81879f5c-cb19-4be1-bebb-776859eae031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a093cf6-9133-486a-9052-f83cf2800011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62594a8d-640c-4e38-82ae-516522137f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894cfcb-d034-4c97-a4db-7f4f74779a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016f105-c131-49f8-8f7d-4590472b37a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182ae4c-c033-4475-b39d-e4408f440a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7181d-172e-41fc-8b22-7d217135ed30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d13c1b-3795-4c8c-98ac-6eb0b0b42292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccfc07-5b38-4922-9c71-c67a80e0118c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08245b91-c4bf-4d47-bf13-a4c610bcd48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002e0ce-833b-4d84-89fc-62e3f15db34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vid_Trans",
   "language": "python",
   "name": "vid_trans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
