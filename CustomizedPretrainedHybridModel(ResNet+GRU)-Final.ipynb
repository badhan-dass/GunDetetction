{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79628168-369c-462f-a874-ef1b3e1e7080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 17:58:41.974590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 17:58:41.988024: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 17:58:41.992156: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 17:58:42.001524: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 17:58:42.592463: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import *\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Input, RepeatVector, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam, Adam\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe7e8fd-b73e-457d-bc9f-5d3d6e010c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3cd6a4-a4a6-4a78-8b5e-0d0b40abd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 23\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69eee8d-a3d1-4bd6-b403-c410182a9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  \"Gun_NoGun_Dataset_augmented/\"\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH= 224,224\n",
    "\n",
    "SEQUENCE_LENGTH =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1901d2-fa71-4604-8fea-d17930c83387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_categories_list = [\"Gun\", \"NoGun\"]\n",
    "model_output_length = len(class_categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8d0353-8edc-48de-baf1-7da24a58a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pixel_value = 255\n",
    "def extract_frame(video_path):\n",
    "  # frames_list = []\n",
    "\n",
    "  # #print(\" the video file path is : {}\".format(video_path))\n",
    "  # videoObj = cv2.VideoCapture(video_path)\n",
    "  # #print(\"the video object is: {}\".format(videoObj))\n",
    "\n",
    "  # \"\"\" Iterating through Video Frames \"\"\"\n",
    "  # while True:\n",
    "\n",
    "  #   # Reading a frame from the video file\n",
    "  #   success, image = videoObj.read()\n",
    "  #   #print(\"the value of success is: {}\".format(success))\n",
    "\n",
    "  #   if not success:\n",
    "  #     break\n",
    "\n",
    "  #   resized_frame = cv2.resize(image, (image_height, image_width))\n",
    "\n",
    "  #   \"\"\"Normalize the resized frame by dividing it with 255 so that \n",
    "  #   each pixel value then lies between 0 and 1\"\"\"\n",
    "\n",
    "  #   normalized_frame = resized_frame / max_pixel_value\n",
    "  #   frames_list.append(normalized_frame)\n",
    "\n",
    "    \n",
    "  # videoObj.release()\n",
    "\n",
    "\n",
    "    frames_list = []\n",
    "    \n",
    "    # Read the Video File\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the total number of frames in the video.\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the the interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    "    \n",
    "    # Iterate through the Video Frames.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "    \n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "    \n",
    "        # Reading the frame from the video. \n",
    "        success, frame = video_reader.read() \n",
    "    \n",
    "        if not success:\n",
    "            break\n",
    "    \n",
    "        # Resize the Frame to fixed height and width.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Normalize the resized frame\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Append the normalized frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    \n",
    "    video_reader.release()\n",
    "\n",
    "\n",
    "    return frames_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943a452f-3497-4bdb-8c45-51d27da91e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_creation():\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "    \n",
    "    # Iterating through all the classes.\n",
    "    for class_index, class_name in enumerate(class_categories_list):\n",
    "        \n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Get the list of video files present in the specific class name directory.\n",
    "        files_list = os.listdir(os.path.join(data_dir, class_name))\n",
    "        \n",
    "        # Iterate through all the files present in the files list.\n",
    "        for file_name in files_list:\n",
    "            \n",
    "            # Get the complete video path.\n",
    "            video_file_path = os.path.join(data_dir, class_name, file_name)\n",
    " \n",
    "            # Extract the frames of the video file.\n",
    "            frames = extract_frame(video_file_path)\n",
    " \n",
    "            # Check if the extracted frames are equal to the SEQUENCE_LENGTH specified.\n",
    "            # So ignore the videos having frames less than the SEQUENCE_LENGTH.\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    " \n",
    "                # Append the data to their repective lists.\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    " \n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8318f13-5f00-4ccf-bfde-5f469c9c19eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: Gun\n",
      "Extracting Data of Class: NoGun\n"
     ]
    }
   ],
   "source": [
    "features, labels = data_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e29e94-5e4b-466c-87c4-710328f43f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the feature = (516, 30, 224, 224, 3)\n",
      "the shape of the labels = (516,)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the feature = {}\".format(features.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a591ab-de67-4797-bdf8-8e35f8d138a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27ff7c15-6485-437f-9c2e-a556d7ac3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, \n",
    "                                                                            test_size = 0.2, \n",
    "                                                                            shuffle = True, \n",
    "                                                                            random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3bc01e-72fb-4b03-a98d-542d51bd7979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the feature = (412, 30, 224, 224, 3)\n",
      "the shape of the labels = (412, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the feature = {}\".format(features_train.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8935243-0edb-4d1a-a2fc-a5beeb6933b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the feature = (104, 30, 224, 224, 3)\n",
      "the shape of the labels = (104, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the feature = {}\".format(features_test.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab9657e-4d72-4f4f-bd0d-7a70b8e3c12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725919259.386307 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.389458 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.406877 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.409746 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.412510 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.415218 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.686024 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.687148 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.688204 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.689226 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.690258 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.691276 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.700701 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.701848 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.702896 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.703916 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725919259.704954 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-09 18:00:59.705958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44968 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1725919259.706306 2608150 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-09 18:00:59.707330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46497 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:4d:00.0, compute capability: 8.6\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1_pad           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ conv1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1_pad           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1_pool          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pool1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block1_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ conv2_block1_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block1_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_0_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block1_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_0_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ conv2_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block2_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ conv2_block2_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block2_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block2_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ conv2_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block3_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ conv2_block3_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block3_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block3_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │ conv3_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block1_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block1_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block1_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_0_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ conv3_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block1_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_0_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv3_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ conv3_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block2_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block2_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block2_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block2_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv3_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ conv3_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block3_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block3_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block3_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block3_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv3_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ conv3_block4_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block4_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block4_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block4_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block4_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv3_block4_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block4_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │ conv4_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block1_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block1_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block1_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_0_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ conv4_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block1_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_0_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block2_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block2_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block2_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block2_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block3_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block3_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block3_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block3_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block4_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block4_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block4_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block4_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block4_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block4_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block4_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block5_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block5_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block5_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block5_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block5_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block5_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block5_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block6_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block6_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block6_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block6_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block6_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block6_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block6_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block7_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block7_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block7_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block7_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block7_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block7_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block7_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block8_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block8_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block8_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block8_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block8_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block8_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block8_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block9_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block9_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block9_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block9_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block9_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block9_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block9_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block10_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block10_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block10_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block10_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block10_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block10_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block10_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block11_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block11_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block11_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block11_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block11_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block11_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block11_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block12_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block12_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block12_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block12_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block12_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block12_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block12_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block13_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block13_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block13_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block13_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block13_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block13_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block13_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block14_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block14_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block14_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block14_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block14_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block14_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block14_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block15_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block15_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block15_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block15_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block15_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block15_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block15_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block16_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block16_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block16_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block16_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block16_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block16_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block16_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block17_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block17_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block17_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block17_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block17_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block17_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block17_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block18_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block18_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block18_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block18_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block18_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block18_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block18_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block19_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block19_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block19_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block19_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block19_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block19_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block19_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block20_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block20_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block20_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block20_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block20_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block20_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block20_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block21_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block21_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block21_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block21_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block21_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block21_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block21_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block22_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block22_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block22_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block22_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block22_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block22_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block22_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block23_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block23_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block23_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block23_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block23_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block23_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block23_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block23_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block23_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block23_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block23_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │ conv5_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block1_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │ conv5_block1_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block1_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_0_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ conv5_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block1_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_0_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │ conv5_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span> │ conv5_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block2_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │ conv5_block2_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block2_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block2_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │ conv5_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span> │ conv5_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block3_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │ conv5_block3_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block3_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block3_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │ conv5_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ post_bn             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ post_relu           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ post_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ post_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1_pad           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m230\u001b[0m, \u001b[38;5;34m230\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1_conv (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │      \u001b[38;5;34m9,472\u001b[0m │ conv1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1_pad           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv1_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1_pool          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ pool1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv2_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block1_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,864\u001b[0m │ conv2_block1_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block1_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_0_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,640\u001b[0m │ conv2_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,640\u001b[0m │ conv2_block1_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_0_c… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2_block1_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,384\u001b[0m │ conv2_block2_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block2_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,864\u001b[0m │ conv2_block2_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block2_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,640\u001b[0m │ conv2_block2_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2_block2_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block3_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,384\u001b[0m │ conv2_block3_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block3_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block3_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block3_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m36,864\u001b[0m │ conv2_block3_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block3_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block3_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_out… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m16,640\u001b[0m │ conv2_block3_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2_block3_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m32,768\u001b[0m │ conv3_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block1_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m147,456\u001b[0m │ conv3_block1_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block1_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_0_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m131,584\u001b[0m │ conv3_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m66,048\u001b[0m │ conv3_block1_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_0_c… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m512\u001b[0m)              │            │ conv3_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv3_block1_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m65,536\u001b[0m │ conv3_block2_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block2_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m147,456\u001b[0m │ conv3_block2_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block2_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m66,048\u001b[0m │ conv3_block2_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m512\u001b[0m)              │            │ conv3_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv3_block2_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m65,536\u001b[0m │ conv3_block3_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block3_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m147,456\u001b[0m │ conv3_block3_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block3_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m66,048\u001b[0m │ conv3_block3_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m512\u001b[0m)              │            │ conv3_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv3_block3_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block4_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m65,536\u001b[0m │ conv3_block4_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block4_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block4_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block4_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m147,456\u001b[0m │ conv3_block4_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block4_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block4_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_out… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m66,048\u001b[0m │ conv3_block4_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m512\u001b[0m)              │            │ conv3_block4_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv3_block4_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m131,072\u001b[0m │ conv4_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block1_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block1_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block1_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_0_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m525,312\u001b[0m │ conv4_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block1_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_0_c… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block1_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block2_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block2_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block2_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block2_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block2_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block2_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block3_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block3_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block3_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block3_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block3_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block3_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block4_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block4_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block4_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block4_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block4_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block4_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block4_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block5_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block5_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block5_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block5_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block5_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block5_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block5_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block6_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block6_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block6_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block6_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block6_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block6_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block6_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block7_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block7_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block7_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block7_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block7_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block7_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block7_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block8_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block8_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block8_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block8_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block8_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block8_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block8_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block9_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block9_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block9_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block9_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block9_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block9_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block9_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block10_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block10_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block10_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block10_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block10_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block10_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block10_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block11_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block11_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block11_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block11_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block11_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block11_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block11_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block12_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block12_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block12_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block12_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block12_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block12_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block12_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block13_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block13_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block13_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block13_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block13_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block13_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block13_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block14_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block14_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block14_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block14_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block14_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block14_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block14_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block15_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block15_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block15_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block15_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block15_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block15_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block15_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block16_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block16_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block16_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block16_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block16_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block16_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block16_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block17_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block17_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block17_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block17_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block17_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block17_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block17_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block18_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block18_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block18_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block18_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block18_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block18_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block18_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block19_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block19_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block19_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block19_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block19_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block19_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block19_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block20_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block20_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block20_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block20_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block20_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block20_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block20_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block21_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block21_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block21_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block21_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block21_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block21_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block21_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block22_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block22_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block22_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block22_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block22_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block22_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block22_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block23_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block23_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block23_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block23_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block23_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block23_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block23_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv4_block23_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_ou… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block23_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block23_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block23_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │    \u001b[38;5;34m524,288\u001b[0m │ conv5_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block1_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,296\u001b[0m │ conv5_block1_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block1_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_0_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m2,099,200\u001b[0m │ conv5_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block1_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_0_c… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m2048\u001b[0m)             │            │ conv5_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │      \u001b[38;5;34m8,192\u001b[0m │ conv5_block1_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m1,048,576\u001b[0m │ conv5_block2_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block2_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,296\u001b[0m │ conv5_block2_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block2_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block2_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m2048\u001b[0m)             │            │ conv5_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │      \u001b[38;5;34m8,192\u001b[0m │ conv5_block2_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block3_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m1,048,576\u001b[0m │ conv5_block3_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block3_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block3_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block3_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,296\u001b[0m │ conv5_block3_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block3_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block3_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block3_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m2048\u001b[0m)             │            │ conv5_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ post_bn             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │      \u001b[38;5;34m8,192\u001b[0m │ conv5_block3_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ post_relu           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ post_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ post_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> (162.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,626,560\u001b[0m (162.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,868,416</span> (30.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,868,416\u001b[0m (30.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,758,144</span> (132.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,758,144\u001b[0m (132.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "no_of_channels = 3\n",
    "\n",
    "# Load the saved model\n",
    "ResNet_model = load_model('ResNet_Date_Time_2024_08_20__21_12_43___Loss_0.050666701048612595___Accuracy_0.9838435649871826.h5')\n",
    "\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, no_of_channels)\n",
    "\n",
    "# Remove the classification head (last layer)\n",
    "ResNet_model = Model(inputs=ResNet_model.inputs, outputs=ResNet_model.layers[-5].output)\n",
    "\n",
    "# Set the new input shape\n",
    "ResNet_model.build(input_shape)\n",
    "\n",
    "# Print the updated model summary\n",
    "ResNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7db383-fee1-431e-b2a1-44843a124825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a37e3d45-9841-42fe-a1c6-a17c94829adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input = Input(shape=(SEQUENCE_LENGTH,\n",
    "                           IMAGE_HEIGHT,\n",
    "                            IMAGE_WIDTH,\n",
    "                            no_of_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db999892-7656-4766-9e1d-ebb3fb8d3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_encoded = TimeDistributed(ResNet_model)(video_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "325d9785-25f2-4870-9736-0d4b6ad3ad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 30, 2048), dtype=float32, sparse=False, name=keras_tensor_798>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_frames_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "133bd4c9-8327-4ec0-979e-c8521aa2fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1786e6c3-eb7d-4c43-94e1-87879d62da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_encoded_sequence = GRU(256)(video_frames_encoded)\n",
    "#video_frames_encoded_sequence = Dropout(0.5)(video_frames_encoded_sequence)\n",
    "\n",
    "hidden_layer1 = Dense(1024, activation=\"relu\")(video_frames_encoded_sequence)\n",
    "#hidden_layer1 = Dropout(0.5)(hidden_layer1)\n",
    "\n",
    "hidden_layer2 = Dense(512, activation=\"relu\")(hidden_layer1)\n",
    "#hidden_layer2 = Dropout(0.5)(hidden_layer2)\n",
    "\n",
    "hidden_layer3 = Dense(256, activation=\"relu\")(hidden_layer2)\n",
    "#hidden_layer3 = Dropout(0.25)(hidden_layer3)\n",
    "\n",
    "hidden_layer4 =  Dense(128, activation=\"relu\")(hidden_layer3)\n",
    "#hidden_layer4 = Dropout(0.25)(hidden_layer4)\n",
    "\n",
    "hidden_layer5 =  Dense(64, activation=\"relu\")(hidden_layer4)\n",
    "#hidden_layer5 = Dropout(0.25)(hidden_layer5)\n",
    "\n",
    "outputs = Dense(no_of_classes, activation=\"softmax\")(hidden_layer5)\n",
    "model = Model([video_input], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4690bef4-3c70-4796-9219-7105a62eb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.00001)\n",
    "                  # beta_1=0.9,\n",
    "                  # beta_2=0.999,\n",
    "                  # epsilon=1e-08,\n",
    "                  # weight_decay=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13492e04-2f4f-4d39-896c-1a357a2757ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06e80d2e-e297-4476-a85d-10a01f46c867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,771,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2048\u001b[0m)       │    \u001b[38;5;34m42,626,560\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,771,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,358,146</span> (173.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,358,146\u001b[0m (173.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,600,002</span> (40.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,600,002\u001b[0m (40.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,758,144</span> (132.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,758,144\u001b[0m (132.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b291f04b-07ce-453c-ae4e-4587efefa47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Early Stopping Callback\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\",\n",
    "                      mode=\"min\",\n",
    "                      restore_best_weights=True,\n",
    "                      patience=15)\n",
    "checkpoint = ModelCheckpoint('ResNet+GRU_best_weights.keras',\n",
    "                             monitor='val_accuracy',\n",
    "                            #  monitor='val_f1_score',\n",
    "                             verbose=1,\n",
    "                             mode='max',\n",
    "                             save_best_only=True)\n",
    "callbacks = [early_stopping_callback, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0237416-13bd-4356-8110-b860c3a7c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((412, 30, 224, 224, 3), (412, 2))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30f9ba48-922e-483a-a643-d40e16044ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 18:03:26.415082: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "W0000 00:00:1725919406.477083 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.500902 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.501473 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.502099 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.502659 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.508702 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.509950 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.517216 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.518485 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.519682 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.520360 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.521115 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.523103 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.523954 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.524851 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.525674 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.527652 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.528839 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.530081 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.531259 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.532483 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.533761 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.548060 2623659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.865113 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.865639 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.866037 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.866447 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.867322 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.868296 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.870427 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.871531 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.871988 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.873045 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.874085 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.874537 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.875637 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.876108 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.876579 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.878321 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.878802 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.879299 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.879790 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.880268 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.880784 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.881860 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.882384 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.882911 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.883415 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.884029 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.884644 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.886672 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.889007 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.889614 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.890216 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.890825 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.891448 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.892054 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.892669 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.893272 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.893896 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.894502 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.895130 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.896234 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.907970 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.908346 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.908688 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.909031 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.909383 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.909736 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.910096 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.910458 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.910821 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.911190 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.911560 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.911919 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.912289 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.912669 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.913061 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.913451 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.913844 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.914228 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.914616 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.915004 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.915402 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.915792 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.916184 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.916585 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.916983 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.917416 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.917837 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.918264 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.918689 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.919120 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.919547 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.919980 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.920407 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.920841 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.921259 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.921685 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.922113 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.922540 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.922962 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.923392 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.938314 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.938816 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.939274 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.939727 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.941147 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.941613 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.942088 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.942581 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.943051 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.943563 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.944076 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.944591 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.945074 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.945548 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.946057 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.946568 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.947063 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.947570 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.948089 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.948595 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.949119 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.949652 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.950170 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.951236 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.951753 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.952278 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.952804 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.954858 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.955382 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.955932 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.956502 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.957084 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.957720 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.958331 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.959003 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.959617 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.960253 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.960900 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.961544 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919406.964233 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.012112 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.012554 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.012945 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.013337 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.013745 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.014161 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.014607 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.015064 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.015540 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.016024 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.016488 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.017005 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.017502 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.018024 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.018573 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.019126 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.019679 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.020234 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.020792 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.021346 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.021902 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.022465 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.023030 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.023612 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.024197 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.024760 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.025346 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.025928 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.026515 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.027102 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.027693 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.028275 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.028879 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.029474 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.030066 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.030664 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.031289 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.031895 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.032529 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.033124 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.048868 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.091722 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.092111 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.092492 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.092887 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.093281 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.093667 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.094054 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.094457 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.094856 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.095260 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.095636 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.096018 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.096416 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.096785 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.097170 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.097564 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.097939 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.098327 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.098719 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.099120 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.099512 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.099899 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.100295 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.100682 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.101098 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.101485 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.101876 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.102271 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.102662 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.103038 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.103457 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.103838 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.104257 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.104687 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.105108 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.116512 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.116865 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.117183 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.117501 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.117839 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.118174 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.118514 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.118852 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.119197 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.119536 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.119883 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.120221 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.120558 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.120897 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.121236 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.121580 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.121927 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.122270 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.122625 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.122977 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.123327 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.123680 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.124037 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.124379 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.124728 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.125106 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.125481 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.125861 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.126245 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.126624 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.127003 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.127387 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.127765 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.128148 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.128525 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.128905 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.129273 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.129653 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.130027 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.130411 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.143388 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.143813 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.144195 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.144581 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.144996 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.145416 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.145831 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.146270 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.146707 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.147138 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.147578 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.148025 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.148501 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.148961 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.149447 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.149955 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.150455 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.150947 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.151429 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.151924 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.152423 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.152925 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.153448 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.153972 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.154505 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.155042 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.155565 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.156089 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.156592 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.157132 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.157663 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.158202 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.158740 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.159289 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.159827 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.160388 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.160910 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.161489 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.161990 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.162575 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.173913 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.174282 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.174601 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.174925 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.175288 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.175654 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.176018 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.176387 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.176751 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.177132 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.177499 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.177865 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.178241 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.178614 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.178989 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.179362 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.179751 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.180141 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.180528 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.180910 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.181297 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.181688 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.182076 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.182465 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.182869 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.183264 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.183657 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.184052 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.184445 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.184844 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.185234 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.185602 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.186017 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.186430 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.186794 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.187215 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.187632 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.188038 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.188403 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.188822 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.203078 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.203529 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.203941 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.204352 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.204771 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.205182 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.205606 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.206018 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.206439 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.206852 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.207265 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.207681 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.208113 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.208542 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.208954 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.209380 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.209814 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.210245 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.210686 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.211123 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.211546 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.211999 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.212459 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.212919 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.213389 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.213838 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.214292 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.214771 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.215248 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.215711 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.216210 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.216675 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.217166 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.217644 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.218146 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.218657 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.219189 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.219695 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.220256 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.220836 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.232955 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.233346 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.233704 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.234052 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.234432 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.234808 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.235190 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.235581 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.235974 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.236368 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.236757 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.237154 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.237544 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.237936 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.238348 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.238749 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.239165 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.239583 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.240016 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.240461 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.240918 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.241376 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.241834 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.242290 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.242748 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.243206 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.243644 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.244106 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.244553 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.245015 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.245469 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.245940 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.246405 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.246880 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.247353 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.247827 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.248305 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.248781 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.249269 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.249764 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.262036 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.266700 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.267043 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.267390 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.267812 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.268238 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.268662 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.269089 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.269512 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.269937 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.270367 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.270809 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.271251 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.271685 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.272119 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.272577 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.273023 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.273468 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.273915 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.274367 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.274815 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.275271 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.275731 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.276195 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.276665 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.277110 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.277565 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.278032 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.278486 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.278913 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.279369 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.279847 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.280327 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.280786 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.281180 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.281591 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.282080 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.282554 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.283037 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.283463 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.305507 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.341757 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.342123 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.342478 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.342838 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.343206 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.343554 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.343903 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.344266 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.344629 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.345004 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.345376 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.345744 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.346116 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.346484 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.346876 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.347227 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.347601 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.347975 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.348342 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.348716 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.349100 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.349484 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.349862 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.350233 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.350608 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.350986 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.351356 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.351734 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.352139 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.352546 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.352978 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.353356 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.353728 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.354120 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.354538 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.354956 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.355368 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.355758 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.356152 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.367942 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.368288 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.368605 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.368915 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.369247 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.369576 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.369912 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.370255 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.370587 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.370918 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.371259 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.371593 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.371933 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.372276 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.372630 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.372963 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.373293 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.373622 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.373950 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.374294 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.374639 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.374985 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.375335 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.375684 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.376032 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.376376 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.376731 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.377084 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.377429 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.377782 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.378135 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.378468 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.378808 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.379152 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.379503 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.379833 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.380186 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.380555 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.380883 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.381213 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.392655 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.393079 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.393477 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.393870 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.394293 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.394710 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.395132 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.395565 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.396002 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.396447 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.396898 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.397371 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.397816 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.398259 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.398726 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.399171 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.399633 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.400094 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.400549 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.401013 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.401496 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.401998 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.402489 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.402960 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.403413 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.403874 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.404395 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.404895 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.405399 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.405907 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.406401 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.406897 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.407381 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.407923 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.408421 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.408951 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.409484 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.409975 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.410542 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.411053 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.421530 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.421889 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.422216 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.422538 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.422891 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.423239 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.423599 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.423949 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.424310 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.424665 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.425023 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.425380 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.425746 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.426099 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.426456 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.426816 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.427185 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.427556 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.427915 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.428280 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.428651 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.429013 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.429370 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.429734 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.430101 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.430467 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.430834 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.431213 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.431589 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.431973 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.432352 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.432718 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.433083 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.433447 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.433835 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.434206 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.434577 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.434952 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.435331 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.435719 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.449105 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.449546 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.449951 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.450359 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.450771 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.451160 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.451579 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.451991 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.452403 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.452833 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.453231 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.453637 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.454044 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.454456 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.454863 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.455265 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.455704 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.456123 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.456546 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.456991 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.457475 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.457919 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.458357 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.458798 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.459282 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.459727 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.460204 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.460664 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.461136 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.461599 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.462050 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.462528 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.462994 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.463409 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.463887 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.464375 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.464927 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.465501 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.466094 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.466693 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.478623 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.479018 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.479374 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.479732 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.480102 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.480472 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.480840 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.481217 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.481595 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.481985 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.482367 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.482762 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.483147 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.483531 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.483946 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.484352 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.484759 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.485174 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.485582 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.485991 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.486386 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.486796 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.487222 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.487613 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.488024 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.488442 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.488860 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.489285 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.489705 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.490123 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.490549 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.490967 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.491384 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.491820 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.492243 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.492674 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.493146 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.493594 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.494036 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.494482 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.506937 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.507356 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.507712 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.508067 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.508459 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.508851 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.509254 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.509652 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.510049 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.510449 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.510849 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.511247 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.511650 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.512049 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.512450 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.512853 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.513284 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.513713 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.514127 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.514534 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.514941 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.515344 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.515740 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.516150 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.516557 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.516965 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.517376 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.517829 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.518264 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.518704 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.519146 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.519574 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.519996 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.520405 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.520865 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.521291 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.521717 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.522150 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.522608 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.523071 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.872168 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.891936 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.892287 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.892647 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.893010 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.893359 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.893722 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.894087 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.894460 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.894836 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.895200 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.895574 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.895945 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.896314 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.896682 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.897062 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.897447 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.897862 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.898248 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.898654 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.899052 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.899462 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.899866 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.900271 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.900679 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.901084 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.901496 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.901900 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.902341 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.902786 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.903231 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.903685 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.904163 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.904643 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.905130 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.905620 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.906114 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.906628 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.907133 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.923153 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.923530 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.923847 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.924166 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.924501 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.924837 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.925176 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.925512 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.925842 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.926175 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.926514 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.926852 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.927195 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.927560 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.927898 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.928236 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.928580 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.928919 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.929272 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.929606 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.929953 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.930294 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.930637 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.930976 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.931323 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.931665 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.932003 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.932337 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.932681 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.933039 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.933375 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.933712 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.934058 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.934398 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.934742 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.935099 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.935445 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.935791 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.946528 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.947011 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.947472 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.947929 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.948453 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.948959 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.949489 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.950002 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.950523 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.951055 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.951584 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.952065 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.952576 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.953121 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.953639 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.954143 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.954701 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.955227 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.955754 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.956266 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.956775 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.957304 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.957839 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.958363 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.958891 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.959426 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.959933 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.960459 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.961001 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.961552 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.962114 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.962698 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.963244 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.963795 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.964389 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.964965 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.965546 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.966108 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.966657 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.976631 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.977001 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.977339 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.977681 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.978048 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.978419 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.978787 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.979148 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.979515 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.979893 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.980268 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.980648 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.981040 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.981414 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.981795 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.982174 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.982548 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.982924 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.983301 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.983693 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.984076 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.984456 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.984839 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.985220 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.985604 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.985987 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.986369 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.986755 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.987133 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.987512 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.987902 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.988287 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.988679 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.989075 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.989474 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.989884 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.990300 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.990721 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919407.991143 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.003835 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.004301 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.004724 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.005140 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.005648 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.006080 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.006506 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.006923 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.007357 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.007779 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.008271 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.008693 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.009188 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.009689 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.010184 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.010682 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.011163 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.011630 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.012084 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.012582 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.013081 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.013581 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.014060 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.014712 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.015223 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.015732 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.016394 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.016899 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.017409 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.017965 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.018501 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.018999 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.019635 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.020267 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.020955 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.021639 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.022519 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.023300 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.039629 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.040040 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.040420 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.040798 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.041192 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.041607 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.042023 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.042436 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.042853 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.043266 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.043694 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.044105 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.044522 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.044948 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.045370 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.045799 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.046224 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.046654 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.047053 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.047481 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.047912 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.048334 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.048762 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.049204 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.049638 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.050082 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.050522 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.050937 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.051339 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.051784 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.052221 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.052647 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.053091 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.053528 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.053971 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.054417 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.054865 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.055292 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.055761 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.056208 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.067111 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.067523 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.067907 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.068292 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.068715 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.069145 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.069571 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.069993 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.070415 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.070848 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.071285 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.071732 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.072172 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.072630 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.073086 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.073540 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.073985 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.074427 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.074872 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.075331 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.075788 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.076240 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.076701 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.077157 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.077616 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.078078 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.078542 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.079004 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.079457 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.079921 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.080390 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.080856 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.081336 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.081824 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.082311 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.082827 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.083350 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.083887 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.084445 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.342727 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.343173 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.343560 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.343940 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.344385 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.349510 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.352194 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.352649 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.353075 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.353520 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.353969 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.354413 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.354856 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.355309 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.355769 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.356225 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.356695 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.357154 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.357727 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.360100 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.362169 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.362721 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.363254 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.363791 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.364721 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.370618 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.444612 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.445646 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.446019 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.446378 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.447218 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.448408 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.448789 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.449161 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.449979 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.450361 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.450739 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.451129 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.451513 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.451914 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.452317 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.452705 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.453104 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.454051 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.454462 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.459031 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.460383 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.460889 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.462785 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.466378 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.466889 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.467393 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.467928 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.468441 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.468972 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.469986 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.470535 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.471085 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.490557 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.491094 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.491616 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.492132 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.492584 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.493021 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.493534 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.493996 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.494452 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.494950 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.495447 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.495944 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.496448 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.496981 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.497477 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.498100 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.498982 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.499637 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.500297 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.501217 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.502101 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.502890 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.503468 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.504085 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.505013 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.506074 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.514480 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.514907 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.515320 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.515736 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.516146 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.516561 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.516982 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.517412 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.517858 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.518322 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.518784 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.519264 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.522486 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.523039 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.523637 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.524256 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.524833 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.525647 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.526462 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.527082 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.527901 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47:48\u001b[0m 143s/step - accuracy: 0.4375 - loss: 0.7194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725919408.556537 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.556958 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.557334 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.557710 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.558126 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.558536 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.558965 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.559402 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.559826 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.560255 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.560691 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.561127 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.561558 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.561994 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.562423 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.562849 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.563285 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.563733 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.564180 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.564627 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.565082 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.565531 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.566019 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.566513 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.567154 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.567844 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.569050 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.579085 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.579464 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.579828 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.580184 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.580547 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.580913 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.581275 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.581646 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.582022 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.582390 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.582765 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.583141 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.583532 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.583919 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.584295 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.584688 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.585089 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.585486 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.585890 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.586313 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.586764 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.587235 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.587725 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.588242 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.588795 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.589345 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.589897 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.590417 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.590935 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.591470 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.591975 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919408.592487 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - accuracy: 0.4621 - loss: 0.6972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725919424.168373 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.168891 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.169312 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.169755 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.170187 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.170725 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.171241 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.171763 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.172390 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.173063 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.173615 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.174243 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.174966 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.175691 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.176486 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.177196 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.178142 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.179165 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.180220 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.181238 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.182158 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.183167 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.185214 2623609 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.259489 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.259918 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.260270 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.260624 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.261005 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.261389 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.261767 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.262144 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.262531 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.262908 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.263296 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.263685 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.264066 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.264455 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.264850 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.265235 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.265626 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.266008 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.266437 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.266835 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.267233 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.267644 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.268047 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.268468 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.268934 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.269395 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.269867 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.270326 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.270789 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.271259 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.271724 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.272197 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.272671 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.273144 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.273612 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.274079 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.274548 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.275033 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.275509 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.275977 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.285995 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.286351 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.286672 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.286986 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.287303 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.287623 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.287941 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.288258 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.288590 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.288915 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.289245 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.289583 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.289922 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.290265 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.290615 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.290959 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.291306 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.291655 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.292005 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.292354 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.292710 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.293060 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.293415 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.293763 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.294115 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.294483 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.294849 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.295215 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.295585 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.295955 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.296325 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.296694 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.297066 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.297439 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.297802 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.298167 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.298534 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.298900 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.299268 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.299640 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.312972 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.313412 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.313796 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.314169 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.314561 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.314952 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.315346 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.315726 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.316122 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.316519 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.316934 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.317359 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.317761 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.318188 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.318601 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.319022 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.319451 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.319870 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.320286 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.320708 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.321114 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.321536 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.321946 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.322364 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.322789 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.323207 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.323627 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.324054 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.324484 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.324919 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.325343 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.325799 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.326234 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.326681 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.327137 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.327606 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.328071 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.328543 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.329067 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.329545 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.342267 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.353076 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.353425 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.353773 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.354130 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.354482 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.354841 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.355204 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.355592 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.355985 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.356375 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.356806 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.357220 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.357640 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.358072 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.358511 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.358959 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.359400 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.359847 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.360288 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.360736 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.361181 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.361635 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.362093 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.362555 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.363006 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.363460 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.363922 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.364382 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.364841 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.365297 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.365754 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.366215 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.366687 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.367141 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.367608 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.368085 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.368556 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.369033 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.369505 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.385004 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.403481 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.403824 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.404167 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.404510 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.404866 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.405225 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.405575 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.405932 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.406305 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.406659 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.407033 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.407386 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.407742 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.408096 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.408448 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.408803 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.409154 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.409506 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.409860 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.410215 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.410562 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.410919 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.411280 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.411637 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.412001 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.412362 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.412724 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.413082 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.413445 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.413842 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.414202 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.414561 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.414921 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.415268 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.415616 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.415997 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.416373 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.427262 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.427616 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.427924 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.428235 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.428558 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.428883 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.429203 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.429528 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.429854 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.430183 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.430507 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.430824 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.431140 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.431459 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.431787 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.432113 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.432443 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.432767 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.433099 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.433423 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.433745 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.434073 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.434395 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.434728 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.435055 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.435394 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.435736 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.436084 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.436436 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.436778 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.437121 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.437467 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.437808 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.438156 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.438507 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.438854 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.439200 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.439547 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.439891 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.440242 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.451420 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.451815 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.452167 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.452517 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.452895 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.453268 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.453645 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.454042 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.454432 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.454820 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.455203 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.455604 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.455996 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.456405 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.456806 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.457223 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.457637 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.458068 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.458487 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.458913 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.459340 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.459774 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.460197 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.460635 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.461063 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.461504 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.461944 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.462361 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.462802 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.463244 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.463682 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.464125 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.464565 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.464997 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.465447 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.465888 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.466342 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.466809 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.467283 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.467736 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.477711 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.478059 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.478374 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.478692 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.479023 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.479366 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.479707 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.480052 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.480387 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.480729 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.481064 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.481406 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.481754 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.482104 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.482452 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.482793 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.483138 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.483494 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.483841 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.484188 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.484533 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.484878 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.485222 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.485567 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.485923 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.486274 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.486629 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.486980 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.487332 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.487681 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.488028 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.488379 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.488733 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.489092 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.489444 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.489800 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.490162 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.490523 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.490888 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.491247 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.508795 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.509205 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.509575 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.509946 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.510313 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.510678 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.511051 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.511417 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.511790 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.512157 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.512528 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.512902 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.513269 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.513644 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.514026 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.514398 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.514782 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.515162 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.515556 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.515958 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.516343 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.516736 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.517127 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.517527 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.517926 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.518336 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.518727 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.519149 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.519542 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.519963 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.520360 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.520772 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.521179 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.521605 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.522032 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.522461 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.522879 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.523318 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.523778 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.524251 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.540184 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.540553 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.540887 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.541217 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.541568 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.541919 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.542269 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.542628 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.542983 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.543335 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.543696 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.544051 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.544418 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.544769 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.545136 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.545507 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.545867 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.546230 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.546611 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.547011 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.547401 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.547787 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.548187 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.548591 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.548986 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.549386 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.549788 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.550172 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.550573 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.550971 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.551372 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.551778 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.552157 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.552563 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.552957 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.553359 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.553746 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.554152 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.554562 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.554978 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.566284 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.566652 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.566984 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.567311 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.567672 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.568028 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.568411 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.568787 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.569168 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.569538 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.569917 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.570290 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.570668 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.571058 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.571439 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.571817 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.572202 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.572592 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.572971 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.573353 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.573732 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.574121 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.574503 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.574876 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.575257 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.575641 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.576025 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.576416 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.576796 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.577185 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.577580 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.577977 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.578375 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.578776 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.579173 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.579571 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.579959 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.580349 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.580750 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.581146 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.600940 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.616373 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.616716 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.617064 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.617407 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.617742 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.618092 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.618437 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.618784 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.619124 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.619485 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.619821 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.620165 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.620505 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.620857 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.621223 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.621566 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.621934 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.622302 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.622658 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.623026 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.623386 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.623729 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.624096 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.624458 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.624819 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.625177 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.625538 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.625891 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.626250 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.626617 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.626997 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.627378 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.627786 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.628185 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.628568 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.628974 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.629383 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.629789 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.630178 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.641709 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.642055 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.642362 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.642672 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.642991 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.643311 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.643633 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.643953 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.644278 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.644602 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.644922 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.645245 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.645580 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.645899 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.646227 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.646544 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.646870 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.647198 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.647515 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.647837 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.648166 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.648495 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.648825 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.649146 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.649474 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.649793 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.650125 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.650454 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.650782 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.651108 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.651431 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.651753 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.652079 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.652416 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.652755 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.653081 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.653407 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.653728 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.654056 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.654376 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.665779 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.666172 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.666519 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.666871 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.667258 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.667651 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.668040 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.668438 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.668826 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.669217 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.669621 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.670017 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.670443 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.670845 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.671244 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.671649 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.672061 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.672470 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.672862 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.673275 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.673689 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.674093 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.674504 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.674928 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.675349 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.675778 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.676206 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.676649 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.677076 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.677514 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.677921 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.678349 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.678779 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.679205 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.679627 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.680060 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.680483 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.680918 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.681370 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.681825 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.692736 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.693091 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.693402 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.693726 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.694065 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.694410 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.694760 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.695093 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.695426 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.695758 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.696103 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.696459 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.696804 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.697153 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.697498 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.697847 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.698189 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.698535 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.698880 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.699228 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.699574 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.699914 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.700255 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.700597 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.700948 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.701293 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.701634 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.701986 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.702334 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.702698 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.703045 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.703402 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.703749 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.704092 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.704441 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.704784 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.705129 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.705482 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.705842 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.706202 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.719196 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.719619 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.719989 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.720395 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.720780 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.721151 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.721532 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.721937 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.722312 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.722673 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.723029 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.723429 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.723827 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.724226 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.724628 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.724988 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.725387 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.725771 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.726159 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.726544 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.726954 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.727318 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.727746 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.728132 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.728535 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.728921 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.729315 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.729738 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.730139 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.730547 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.730953 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.731357 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.731778 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.732191 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.732678 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.733162 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.733713 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.734209 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.734734 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.746089 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.746465 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.746797 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.747130 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.747482 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.747837 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.748196 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.748549 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.748905 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.749261 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.749622 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.749981 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.750346 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.750701 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.751068 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.751425 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.751776 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.752159 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.752533 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.752918 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.753298 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.753674 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.754047 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.754415 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.754794 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.755160 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.755536 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.755913 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.756288 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.756668 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.757047 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.757419 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.757804 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.758186 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.758555 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.758933 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.759307 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.759687 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.760081 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.760463 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.772149 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.772534 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.772868 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.773203 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.773575 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.773953 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.774326 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.774691 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.775054 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.775420 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.775800 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.776185 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.776561 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.776946 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.777319 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.777702 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.778080 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.778462 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.778844 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.779228 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.779609 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.779995 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.780375 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.780755 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.781155 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.781537 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.781915 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.782304 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.782691 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.783101 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.783486 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.783874 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.784254 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.784638 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.785035 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.785415 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.785791 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.786177 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.786596 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919424.787023 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.006122 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.015840 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.016184 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.016531 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.016874 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.017224 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.017571 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.017922 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.018276 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.018630 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.018981 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.019349 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.019714 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.020076 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.020441 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.020807 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.021179 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.021557 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.021943 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.022343 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.022733 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.023143 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.023545 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.023942 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.024346 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.024750 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.025159 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.025565 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.025998 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.026444 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.026885 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.027320 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.027766 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.028238 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.028724 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.029212 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.029691 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.030206 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.030716 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.042155 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.042509 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.042822 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.043130 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.043455 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.043776 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.044101 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.044427 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.044768 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.045107 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.045440 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.045778 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.046115 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.046462 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.046798 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.047136 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.047476 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.047808 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.048139 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.048481 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.048824 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.049153 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.049490 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.049825 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.050163 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.050496 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.050835 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.051172 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.051524 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.051860 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.052195 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.052530 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.052881 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.053216 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.053551 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.053886 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.054247 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.054584 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.054931 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.055280 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.065998 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.066423 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.066817 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.067206 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.067621 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.068038 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.068473 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.068920 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.069369 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.069833 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.070310 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.070783 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.071253 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.071737 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.072226 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.072717 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.073196 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.073680 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.074164 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.074643 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.075114 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.075607 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.076092 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.076584 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.077070 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.077553 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.078062 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.078547 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.079047 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.079541 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.080054 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.080557 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.081071 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.081571 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.082100 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.082615 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.083119 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.083598 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.084126 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.084650 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.094116 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.094473 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.094794 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.095116 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.095503 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.095884 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.096262 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.096627 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.096983 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.097348 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.097730 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.098101 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.098476 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.098833 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.099220 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.099575 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.099936 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.100318 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.100669 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.101044 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.101418 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.101806 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.102191 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.102549 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.102907 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.103272 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.103679 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.104076 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.104440 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.104805 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.105170 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.105585 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.105946 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.106379 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.106755 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.107133 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.119340 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.119803 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.120224 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.120648 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.121036 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.121456 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.121838 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.122243 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.122676 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.123093 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.123534 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.123947 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.124405 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.124806 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.125208 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.125708 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.126204 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.126708 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.127202 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.127654 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.128148 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.128648 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.129149 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.129579 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.130060 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.130547 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.131032 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.131483 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.131976 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.132396 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.132951 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.133606 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.134268 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.134886 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.135481 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.135984 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.136684 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.137309 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.147805 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.148181 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.148526 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.148875 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.149237 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.149615 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.149973 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.150366 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.150759 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.151145 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.151525 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.151911 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.152283 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.152674 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.153067 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.153467 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.153864 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.154255 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.154654 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.155060 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.155462 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.155864 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.156270 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.156672 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.157091 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.157502 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.157922 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.158322 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.158739 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.159160 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.159580 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.159994 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.160393 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.160808 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.161214 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.161616 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.162014 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.162448 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.162879 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.175102 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.175484 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.175829 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.176172 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.176626 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.177076 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.177526 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.177944 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.178362 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.178772 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.179222 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.179670 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.180115 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.180523 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.180944 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.181360 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.181772 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.182223 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.182632 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.183081 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.183527 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.184004 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.184409 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.184812 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.185225 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.185750 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.186273 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.186699 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.187114 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.187549 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.187973 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.188529 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.188979 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.189430 2623657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step - accuracy: 0.4683 - loss: 0.6957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725919425.228548 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.228959 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.229304 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.229648 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.230065 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.230468 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.230884 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.231283 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.231689 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.232103 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.232534 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.232938 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.233384 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.233831 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.234327 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.234766 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.235216 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.235745 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.236197 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.236654 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.237130 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.237650 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.238065 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.238596 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.239135 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.251563 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.251924 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.252262 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.252606 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.252956 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.253299 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.253640 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.253983 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.254320 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.254674 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.255028 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.255383 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.255737 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.256100 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.256457 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.256812 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.257180 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.257561 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.257934 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.258311 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.258696 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.259098 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.259522 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.259941 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.260347 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.260766 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.261191 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.261615 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.262046 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.262490 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.262932 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.263377 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.271598 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.272061 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.272494 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.272915 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.273350 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.273763 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.274175 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.274594 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.275048 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.275542 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.276000 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.276491 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.276982 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.277475 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.277948 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.278573 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.279069 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.279600 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.280240 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.280892 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.281564 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.282269 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.282905 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.283700 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.287879 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.288272 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.288659 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.289053 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.289438 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.289830 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.290212 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.290603 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.291003 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.291410 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.291840 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.292274 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.292728 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.293204 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.293679 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.294246 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.294735 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.295213 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.295811 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.296415 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.297026 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.297732 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.298452 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.299666 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.309250 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.315672 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.316016 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.316365 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.316729 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.317105 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.317503 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.317901 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.318297 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.318703 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.319100 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.319502 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.319901 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.320285 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.320705 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.321110 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.321521 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.321931 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.322340 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.322775 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.323192 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.323604 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.324016 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.324437 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.324950 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.325474 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.333142 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.333502 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.333845 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.334189 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.334537 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.334886 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.335229 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.335576 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.335922 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.336276 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.336625 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.336980 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.337331 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.337687 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.338044 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.338399 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.338768 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.339155 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.339537 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.339907 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.340279 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.340723 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.341164 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.341610 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.342007 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.342428 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.342834 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.343252 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.343680 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.344105 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.344544 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919425.344969 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.864904 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.865518 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.866119 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.866768 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.867458 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.869454 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.870296 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.885752 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.886781 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.887807 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.889071 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.890339 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.891688 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.893071 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.894404 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.895735 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.897269 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.900208 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.966641 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.967143 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.967586 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.968009 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.968487 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.968959 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.969429 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.969909 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.970385 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.970877 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.971352 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.971845 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.972340 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.972816 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.973304 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.973797 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.974272 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.974769 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.975318 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.975824 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.976340 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.976902 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.977461 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.978085 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.978607 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.979160 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.979805 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.980337 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.980892 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.981496 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.982063 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.982593 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.983299 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.983891 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.984475 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.985029 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.985587 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.986285 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.987178 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919464.987988 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.005237 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.080140 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.080513 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.080894 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.081286 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.081682 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.082074 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.082469 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.082847 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.083229 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.083611 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.083998 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.084386 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.084772 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.085158 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.085544 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.085940 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.086326 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.086711 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.087111 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.087513 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.087916 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.088314 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.088725 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.089137 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.089532 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.089947 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.090334 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.090735 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.091149 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.091544 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.092009 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.092430 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.092860 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.093274 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.093705 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.094177 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.094658 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.108862 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.113909 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.114307 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.114703 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.115122 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.115535 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.115972 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.116403 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.116827 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.117256 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.117666 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.118077 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.118521 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.118938 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.119372 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.119806 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.120243 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.120682 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.121115 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.121560 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.122011 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.122445 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.122917 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.123364 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.123802 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.124315 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.124802 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.125326 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.125827 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.126312 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.126741 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.127171 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.127669 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.128343 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.128929 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.129706 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.130369 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.130858 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.131354 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.131951 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.169389 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.208282 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.208639 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.208990 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.209339 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.209709 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.210067 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.210452 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.210814 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.211176 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.211546 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.211915 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.212280 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.212652 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.213019 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.213382 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.213762 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.214130 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.214510 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.214892 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.215275 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.215646 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.216042 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.216406 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.216783 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.217169 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.217546 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.217929 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.218307 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.218689 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.219114 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.219529 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.219916 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.220337 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.220792 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.221224 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.221642 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.239798 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.240256 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.240698 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.241133 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.241525 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.241947 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.242343 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.242806 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.243234 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.243674 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.244161 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.244581 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.245052 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.245533 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.245942 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.246351 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.246841 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.247281 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.247714 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.248135 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.248535 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.248940 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.249354 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.249765 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.250204 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.250648 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.251052 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.251532 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.251932 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.252340 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.252784 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.253277 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.253772 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.254349 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.255145 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.255753 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.256688 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.257321 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.579800 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.599911 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.600262 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.600612 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.600956 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.601330 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.601686 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.602057 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.602415 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.602789 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.603148 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.603521 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.603897 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.604263 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.604629 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.605007 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.605426 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.605823 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.606207 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.606606 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.607013 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.607423 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.607818 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.608216 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.608627 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.609024 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.609421 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.609827 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.610257 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.610747 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.611242 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.611692 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.612162 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.612638 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.613139 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.613626 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.614262 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.627784 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.628236 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.628657 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.629081 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.629505 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.629926 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.630365 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.630796 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.631230 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.631676 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.632189 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.632646 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.633120 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.633586 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.634053 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.634548 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.635045 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.635542 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.636043 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.636543 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.637038 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.637547 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.638069 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.638577 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.639070 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.639580 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.640118 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.640619 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.641174 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.641861 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.642518 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.643188 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.643860 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.644547 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.645279 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.646042 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.646976 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919465.647944 2623630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.462382 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.462807 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.463158 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.463511 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.463866 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.464232 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.464593 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.464974 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.465362 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.465752 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.466188 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.466617 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.467060 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.467502 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.467938 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.468417 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.468848 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.542262 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.542660 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.542993 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.543320 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.543659 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.544003 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.544332 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.544671 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.545008 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.545345 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.545691 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.546029 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.546366 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.546700 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.547042 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.547396 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.547742 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.548080 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.548416 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.548754 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.549094 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.549436 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.549787 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.550140 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.550486 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.550849 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.551208 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.551561 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.551914 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.552253 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.552596 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.552952 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.565175 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.565558 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.565929 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.566304 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.566681 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.567066 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.567461 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.567825 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.585912 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.589067 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.589386 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.589707 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.590038 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.590374 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.590697 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.591020 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.591342 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.591682 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.592023 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.592347 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.592683 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.593011 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.593337 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.593666 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.593995 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.594331 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.594668 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.595006 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.595341 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.595678 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.596014 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.596337 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.596683 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.597024 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.597380 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.597711 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.598037 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.598374 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.598734 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.599082 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.599453 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.599784 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.600121 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.600484 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.600834 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.615921 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.616305 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.616648 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.616985 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.617321 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.617648 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.617987 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.618323 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.618665 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.618995 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.619332 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.619671 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.620024 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.620381 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.620736 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.621076 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.621424 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.621789 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.622154 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.622513 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.622872 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.623234 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.623588 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.623944 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.624288 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.624644 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.624994 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.625340 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.625698 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.626030 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.626377 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.626742 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.627093 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.627491 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.627871 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.628274 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.628662 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.629061 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.629447 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.629814 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.649287 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.649662 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.649998 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.650314 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.650638 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.650973 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.651299 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.651625 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.651947 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.652281 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.652606 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.652935 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.653271 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.653611 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.653950 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.654285 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.654618 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.654960 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.655306 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.655656 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.656008 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.656365 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.656711 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.657063 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.657419 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.657774 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.658131 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.658493 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.658836 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.659193 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.659561 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.659918 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.660275 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.660651 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.661023 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.661407 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.661792 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.662190 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.662598 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.662994 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.677163 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.677550 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.677890 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.678227 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.678571 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.678914 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.679267 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.679610 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.679961 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.680315 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.680669 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.681014 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.681372 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.681738 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.682089 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.682441 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.682782 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.683159 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.683531 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.683902 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.684277 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.684655 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.685033 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.685394 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.685757 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.686156 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.686556 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.686949 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.687341 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.687737 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.688135 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.688536 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.688939 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.689358 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.689805 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.690214 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.690698 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.691185 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.691654 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.796259 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.796651 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.796987 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.797327 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.797656 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.797986 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.798320 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.798662 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.799005 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.799361 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.799714 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.800067 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.800423 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.800782 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.801139 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.801500 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.801865 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.802267 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.802638 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.803018 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.803394 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.803764 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.804159 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.804561 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.804963 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.805337 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.805736 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.806136 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.806543 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.806947 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.807408 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.807822 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.808283 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.808732 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.809219 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.809705 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.810196 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.824197 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.824610 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.824970 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.825350 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.825715 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.826094 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.826474 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.826848 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.827256 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.827669 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.828083 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.828498 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.828871 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.829274 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.829697 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.830079 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.830498 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.830868 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.831329 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.831810 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.832287 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.832782 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.833275 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.833754 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.834246 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.834737 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.835228 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.835723 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.836164 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.836618 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.837163 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.837778 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.838341 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.838953 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.839608 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.840271 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725919468.840886 2623605 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.85542, saving model to ResNet+GRU_best_weights.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - accuracy: 0.4740 - loss: 0.6943 - val_accuracy: 0.8554 - val_loss: 0.5966\n",
      "Epoch 2/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811ms/step - accuracy: 0.8446 - loss: 0.5826\n",
      "Epoch 2: val_accuracy improved from 0.85542 to 0.92771, saving model to ResNet+GRU_best_weights.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.8457 - loss: 0.5815 - val_accuracy: 0.9277 - val_loss: 0.4932\n",
      "Epoch 3/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - accuracy: 0.8993 - loss: 0.4788\n",
      "Epoch 3: val_accuracy improved from 0.92771 to 0.96386, saving model to ResNet+GRU_best_weights.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.8989 - loss: 0.4778 - val_accuracy: 0.9639 - val_loss: 0.3906\n",
      "Epoch 4/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822ms/step - accuracy: 0.9211 - loss: 0.3873\n",
      "Epoch 4: val_accuracy improved from 0.96386 to 1.00000, saving model to ResNet+GRU_best_weights.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9211 - loss: 0.3863 - val_accuracy: 1.0000 - val_loss: 0.3049\n",
      "Epoch 5/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825ms/step - accuracy: 0.9649 - loss: 0.3057\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9648 - loss: 0.3047 - val_accuracy: 0.9880 - val_loss: 0.2375\n",
      "Epoch 6/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 0.9776 - loss: 0.2403\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9778 - loss: 0.2393 - val_accuracy: 0.9759 - val_loss: 0.1821\n",
      "Epoch 7/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 0.9804 - loss: 0.1888\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9805 - loss: 0.1879 - val_accuracy: 1.0000 - val_loss: 0.1350\n",
      "Epoch 8/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 0.9802 - loss: 0.1430\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9802 - loss: 0.1425 - val_accuracy: 1.0000 - val_loss: 0.1040\n",
      "Epoch 9/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 0.9892 - loss: 0.1008\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9891 - loss: 0.1005 - val_accuracy: 0.9880 - val_loss: 0.0904\n",
      "Epoch 10/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 0.9932 - loss: 0.0748\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9932 - loss: 0.0745 - val_accuracy: 0.9880 - val_loss: 0.0698\n",
      "Epoch 11/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0526\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0524 - val_accuracy: 0.9880 - val_loss: 0.0539\n",
      "Epoch 12/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0364\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0363 - val_accuracy: 1.0000 - val_loss: 0.0463\n",
      "Epoch 13/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0268\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.9880 - val_loss: 0.0397\n",
      "Epoch 14/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0204\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 1.0000 - val_loss: 0.0315\n",
      "Epoch 15/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0159\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0272\n",
      "Epoch 16/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0128\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
      "Epoch 17/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0104\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 0.0232\n",
      "Epoch 18/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0212\n",
      "Epoch 19/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0072\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0194\n",
      "Epoch 20/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0185\n",
      "Epoch 21/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0173\n",
      "Epoch 22/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0165\n",
      "Epoch 23/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0158\n",
      "Epoch 24/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
      "Epoch 25/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0147\n",
      "Epoch 26/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0141\n",
      "Epoch 27/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0139\n",
      "Epoch 28/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0134\n",
      "Epoch 29/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
      "Epoch 30/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0127\n",
      "Epoch 31/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 31: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0124\n",
      "Epoch 32/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 32: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0121\n",
      "Epoch 33/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 33: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 34: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0118\n",
      "Epoch 35/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 35: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
      "Epoch 36/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 36: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0114\n",
      "Epoch 37/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0010\n",
      "Epoch 37: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.9845e-04 - val_accuracy: 1.0000 - val_loss: 0.0112\n",
      "Epoch 38/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 9.2762e-04\n",
      "Epoch 38: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.2527e-04 - val_accuracy: 1.0000 - val_loss: 0.0110\n",
      "Epoch 39/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 8.6069e-04\n",
      "Epoch 39: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.5854e-04 - val_accuracy: 1.0000 - val_loss: 0.0110\n",
      "Epoch 40/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 7.9855e-04\n",
      "Epoch 40: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.9658e-04 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
      "Epoch 41/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 7.4212e-04\n",
      "Epoch 41: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.4031e-04 - val_accuracy: 1.0000 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 6.8977e-04\n",
      "Epoch 42: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.8810e-04 - val_accuracy: 1.0000 - val_loss: 0.0106\n",
      "Epoch 43/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 6.4129e-04\n",
      "Epoch 43: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.3976e-04 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
      "Epoch 44/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 5.9824e-04\n",
      "Epoch 44: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.9682e-04 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
      "Epoch 45/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 5.5904e-04\n",
      "Epoch 45: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.5774e-04 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 46/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 5.2354e-04\n",
      "Epoch 46: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.2234e-04 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 47/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 4.9095e-04\n",
      "Epoch 47: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.8983e-04 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
      "Epoch 48/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 4.6137e-04\n",
      "Epoch 48: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.6033e-04 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
      "Epoch 49/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 4.3395e-04\n",
      "Epoch 49: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.3297e-04 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "Epoch 50/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 4.0889e-04\n",
      "Epoch 50: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.0798e-04 - val_accuracy: 1.0000 - val_loss: 0.0099\n",
      "Epoch 51/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.8576e-04\n",
      "Epoch 51: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.8491e-04 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "Epoch 52/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.6421e-04\n",
      "Epoch 52: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.6341e-04 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "Epoch 53/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.4420e-04\n",
      "Epoch 53: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.4344e-04 - val_accuracy: 1.0000 - val_loss: 0.0099\n",
      "Epoch 54/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.2569e-04\n",
      "Epoch 54: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.2498e-04 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
      "Epoch 55/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.0851e-04\n",
      "Epoch 55: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.0784e-04 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
      "Epoch 56/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.9227e-04\n",
      "Epoch 56: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.9164e-04 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
      "Epoch 57/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.7696e-04\n",
      "Epoch 57: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.7635e-04 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 58/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.6253e-04\n",
      "Epoch 58: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6196e-04 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 59/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.4869e-04\n",
      "Epoch 59: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.4815e-04 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 60/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.3574e-04\n",
      "Epoch 60: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.3524e-04 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 61/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 2.2376e-04\n",
      "Epoch 61: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2329e-04 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 62/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.1256e-04\n",
      "Epoch 62: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1211e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 63/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.0215e-04\n",
      "Epoch 63: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0172e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 64/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.9234e-04\n",
      "Epoch 64: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9194e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 65/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.8308e-04\n",
      "Epoch 65: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8270e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 66/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.7430e-04\n",
      "Epoch 66: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7394e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 67/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.6601e-04\n",
      "Epoch 67: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6567e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 68/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.5824e-04\n",
      "Epoch 68: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5791e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.5091e-04\n",
      "Epoch 69: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5060e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 70/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.4389e-04\n",
      "Epoch 70: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4360e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 71/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.3733e-04\n",
      "Epoch 71: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3705e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 72/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.3114e-04\n",
      "Epoch 72: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3087e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 73/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.2527e-04\n",
      "Epoch 73: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2501e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 74/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.1969e-04\n",
      "Epoch 74: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1945e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 75/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.1440e-04\n",
      "Epoch 75: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1417e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 76/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 1.0943e-04\n",
      "Epoch 76: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0921e-04 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 77/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 1.0474e-04\n",
      "Epoch 77: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0453e-04 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 78/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.0028e-04\n",
      "Epoch 78: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0008e-04 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 79/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 9.6028e-05\n",
      "Epoch 79: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.5837e-05 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 80/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 9.1984e-05\n",
      "Epoch 80: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1803e-05 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 81/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 8.8181e-05\n",
      "Epoch 81: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.8008e-05 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 82/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 8.4548e-05\n",
      "Epoch 82: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.4385e-05 - val_accuracy: 1.0000 - val_loss: 0.0096\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "model_training_history = model.fit(x = features_train, \n",
    "                                   y = labels_train, \n",
    "                                   epochs = 100, \n",
    "                                   batch_size = 16,\n",
    "                                   shuffle = True, \n",
    "                                   callbacks=[callbacks],\n",
    "                                   validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2255e125-e7cd-405e-8c76-e0b65d4521a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 30, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf7356f-7d79-42cf-ae47-0377e61ad03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# import datetime as dt\n",
    "\n",
    "# model2_evaluation_history = model.evaluate(features_test, labels_test)\n",
    "\n",
    "# date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "# current_date_time_dt = dt.datetime.now()\n",
    "\n",
    "# current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "# model_evaluation_loss, model_evaluation_accuracy = model2_evaluation_history\n",
    "model_name = \"ResNet+GRU.h5\"\n",
    "# Saving your Model\n",
    "model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fb82a-1e5f-4c6d-9c47-3fb1cdfd8128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01c47a-eaf7-4edb-89a1-2f81191e9414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa7a3824-c046-4049-aecd-0f49026c4256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725921248.737118 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.742042 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.742916 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.743805 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.744869 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.746101 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.747343 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.748751 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.750327 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.751948 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.754101 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.756256 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.758452 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.760748 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.762997 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.765354 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.768168 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.772988 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.851576 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.861510 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.862071 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.862609 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.863243 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.863864 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.864480 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.865122 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.865759 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.866407 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.867028 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.867686 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.868347 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.868971 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.869631 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.870297 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.870918 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.871575 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.872362 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.873061 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.873761 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.874580 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.875381 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.876244 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.876972 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.877716 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.878591 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.879340 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.880091 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.880951 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.881756 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.882505 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.883569 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.884391 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.885213 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.885979 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.886763 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.887836 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.889254 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.890522 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921248.908108 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.066591 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.067033 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.067486 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.067958 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.068470 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.068940 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.069401 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.069854 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.070304 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.070780 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.071265 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.071727 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.072187 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.072640 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.073115 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.073618 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.074102 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.074582 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.075107 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.075639 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.076140 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.076624 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.077151 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.077651 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.078169 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.078734 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.079208 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.079759 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.080279 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.080769 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.081347 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.081889 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.082443 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.083022 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.083580 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.084162 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.084767 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.098391 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.119651 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.120132 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.120623 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.121104 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.121587 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.122101 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.122579 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.123057 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.123590 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.124193 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.124792 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.125364 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.125910 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.126449 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.127033 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.127626 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.128176 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.128741 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.129339 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.129919 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.130495 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.131074 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.131669 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.132342 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.133016 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.133723 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.134440 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.135132 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.136030 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.136924 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.137768 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.138530 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.139281 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.139957 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.140775 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.141807 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.142713 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.143661 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.144759 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.206849 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.288327 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.288737 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.289151 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.289557 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.289957 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.290358 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.290765 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.291163 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.291571 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.291979 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.292394 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.292814 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.293219 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.293631 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.294061 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.294488 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.294892 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.295305 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.295725 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.296156 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.296572 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.296991 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.297425 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.297858 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.298283 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.298730 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.299150 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.299642 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.300085 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.300583 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.301033 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.301493 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.301994 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.302582 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.303099 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.303717 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.304336 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.304893 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.305462 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.319602 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.327943 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.328446 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.328907 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.329407 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.329905 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.330368 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.330820 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.331335 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.331853 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.332369 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.332890 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.333408 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.333894 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.334425 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.334941 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.335450 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.335958 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.336453 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.336989 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.337512 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.338115 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.338659 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.339191 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.339735 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.340267 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.340825 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.341370 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.341994 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.342649 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.343296 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.343971 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.344620 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.345286 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.345935 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.346863 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.347731 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.348701 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 39s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725921249.934606 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.979671 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.980087 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.980500 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.980932 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.981361 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.981747 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.982153 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.982581 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.983005 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.983422 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.983849 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.984271 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.984685 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.985089 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.985494 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.985890 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.986311 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.986737 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.987122 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.987547 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.987981 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.988379 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.988762 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.989187 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.989620 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.990052 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.990503 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.990979 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.991497 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.992017 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.992537 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.993089 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.993747 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.994309 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.994989 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921249.995652 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.008703 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.012628 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.013139 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.013696 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.014219 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.014732 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.015249 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.015738 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.016305 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.016834 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.017413 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.017944 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.018522 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.019083 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.019636 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.020139 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.020660 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.021168 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.021686 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.022354 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.022969 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.023478 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.024082 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.024775 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.025371 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.025882 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.026571 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.027246 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.027846 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.028540 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.029228 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.030115 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.031440 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.032448 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.033722 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921250.035314 2623661 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725921291.167739 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.168225 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.168644 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.169056 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.169504 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.169978 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.170455 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.170992 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.171539 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.172056 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.172723 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.173399 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.174066 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.174727 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.175396 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.176152 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.176822 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.178541 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.246740 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.247182 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.247561 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.247946 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.248332 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.248728 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.249132 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.249530 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.249939 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.250348 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.250750 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.251152 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.251564 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.251965 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.252382 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.252792 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.253206 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.253625 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.254046 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.254473 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.254902 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.255335 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.255789 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.256238 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.256680 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.257109 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.257577 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.258034 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.258495 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.258934 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.259402 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.259853 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.260446 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.261142 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.261667 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.262198 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.262710 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.263227 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.263765 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.264335 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.280988 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.313166 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.313507 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.313847 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.314194 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.314539 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.314891 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.315234 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.315586 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.315933 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.316278 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.316628 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.316973 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.317318 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.317660 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.318016 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.318359 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.318715 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.319065 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.319417 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.319765 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.320118 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.320472 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.320833 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.321190 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.321569 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.321947 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.322315 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.322681 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.323050 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.323426 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.323805 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.324169 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.324551 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.324940 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.325341 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.339492 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.339890 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.340252 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.340610 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.340969 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.341327 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.341692 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.342060 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.342432 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.342787 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.343160 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.343529 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.343900 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.344280 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.344654 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.345030 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.345410 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.345792 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.346167 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.346545 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.346927 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.347303 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.347684 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.348066 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.348474 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.348890 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.349280 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.349701 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.350103 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.350506 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.350900 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.351294 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.351709 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.352120 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.352546 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.353004 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.353462 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.353943 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.354389 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.354935 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.380500 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.396644 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.396983 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.397321 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.397653 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.397993 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.398348 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.398696 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.399037 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.399390 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.399741 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.400095 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.400442 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.400792 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.401132 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.401491 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.401849 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.402182 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.402542 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.402875 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.403225 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.403585 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.403946 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.404307 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.404680 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.405053 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.405396 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.405739 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.406104 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.406466 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.406836 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.407243 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.407653 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.408028 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.408418 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.408815 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.409201 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.409658 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.410063 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.410452 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.423866 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.424274 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.424659 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.425062 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.425423 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.425800 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.426187 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.426595 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.427014 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.427423 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.427798 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.428169 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.428524 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.428885 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.429287 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.429650 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.430006 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.430423 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.430820 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.431219 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.431603 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.431992 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.432387 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.432788 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.433193 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.433588 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.433986 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.434391 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.434795 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.435203 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.435632 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.436157 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.436651 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.437173 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.437784 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.438396 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.438879 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.439363 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 14s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725921291.635710 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.643144 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.643483 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.643821 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.644158 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.644498 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.644833 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.645179 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.645532 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.645890 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.646242 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.646599 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.646951 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.647305 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.647675 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.648031 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.648422 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.648805 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.649201 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.649582 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.649971 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.650362 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.650764 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.651169 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.651567 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.651967 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.652372 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.652786 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.653213 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.653649 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.654093 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.654549 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.655017 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.655478 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.655973 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.656460 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.656948 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.671202 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.671679 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.672089 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.672479 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.672854 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.673274 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.673694 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.674112 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.674513 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.674937 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.675376 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.675817 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.676213 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.676616 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.677048 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.677495 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.677964 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.678405 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.678900 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.679395 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.679879 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.680376 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.680875 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.681360 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.681848 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.682344 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.682836 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.683259 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.683808 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.684329 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.684853 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.685518 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.686172 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.686786 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.687397 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.688030 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921291.688734 2623650 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    }
   ],
   "source": [
    "labels_pred_prob = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8666fda5-8890-489e-a7a9-c7849da11154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99819100e-01, 1.80979943e-04],\n",
       "       [3.80803458e-03, 9.96191978e-01],\n",
       "       [9.99668360e-01, 3.31624615e-04],\n",
       "       [2.59532622e-04, 9.99740422e-01],\n",
       "       [1.32374043e-04, 9.99867558e-01],\n",
       "       [1.61967022e-04, 9.99837995e-01],\n",
       "       [9.99878645e-01, 1.21335186e-04],\n",
       "       [9.99316692e-01, 6.83327205e-04],\n",
       "       [4.03066551e-05, 9.99959707e-01],\n",
       "       [3.92683893e-01, 6.07316077e-01],\n",
       "       [9.99755085e-01, 2.44867959e-04],\n",
       "       [1.24186743e-04, 9.99875784e-01],\n",
       "       [5.15814245e-05, 9.99948382e-01],\n",
       "       [3.34887372e-05, 9.99966502e-01],\n",
       "       [9.99806941e-01, 1.93094384e-04],\n",
       "       [9.99895453e-01, 1.04592043e-04],\n",
       "       [2.38690714e-04, 9.99761283e-01],\n",
       "       [1.14021866e-04, 9.99885917e-01],\n",
       "       [5.81352178e-05, 9.99941826e-01],\n",
       "       [9.99903202e-01, 9.67545348e-05],\n",
       "       [9.99148726e-01, 8.51232151e-04],\n",
       "       [9.67717290e-01, 3.22827250e-02],\n",
       "       [3.26038600e-04, 9.99673963e-01],\n",
       "       [4.95116219e-05, 9.99950528e-01],\n",
       "       [9.97563004e-01, 2.43697944e-03],\n",
       "       [9.99764621e-01, 2.35326908e-04],\n",
       "       [9.99902487e-01, 9.75380681e-05],\n",
       "       [3.21330481e-05, 9.99967813e-01],\n",
       "       [9.99926209e-01, 7.38225863e-05],\n",
       "       [1.32665431e-04, 9.99867320e-01],\n",
       "       [5.09201745e-05, 9.99949098e-01],\n",
       "       [9.99911547e-01, 8.84374094e-05],\n",
       "       [6.34689713e-05, 9.99936581e-01],\n",
       "       [9.99937534e-01, 6.25094690e-05],\n",
       "       [9.99795258e-01, 2.04809592e-04],\n",
       "       [1.31751702e-04, 9.99868274e-01],\n",
       "       [3.23266213e-05, 9.99967694e-01],\n",
       "       [3.52377647e-05, 9.99964714e-01],\n",
       "       [4.55354893e-05, 9.99954462e-01],\n",
       "       [7.80251939e-05, 9.99921918e-01],\n",
       "       [9.99884725e-01, 1.15219111e-04],\n",
       "       [3.69776390e-05, 9.99963045e-01],\n",
       "       [9.99908328e-01, 9.16040735e-05],\n",
       "       [3.38802376e-04, 9.99661207e-01],\n",
       "       [1.47821265e-04, 9.99852180e-01],\n",
       "       [9.99794304e-01, 2.05659628e-04],\n",
       "       [9.99779522e-01, 2.20502479e-04],\n",
       "       [1.90514489e-04, 9.99809563e-01],\n",
       "       [1.17421238e-04, 9.99882579e-01],\n",
       "       [3.28678470e-05, 9.99967098e-01],\n",
       "       [9.99745667e-01, 2.54294777e-04],\n",
       "       [9.95948911e-01, 4.05106228e-03],\n",
       "       [9.99814928e-01, 1.85119803e-04],\n",
       "       [9.99897480e-01, 1.02456637e-04],\n",
       "       [3.68324290e-05, 9.99963164e-01],\n",
       "       [9.99793231e-01, 2.06765224e-04],\n",
       "       [9.99913335e-01, 8.66398186e-05],\n",
       "       [9.99744952e-01, 2.55089370e-04],\n",
       "       [9.99776542e-01, 2.23525029e-04],\n",
       "       [9.99901772e-01, 9.81691192e-05],\n",
       "       [9.99862432e-01, 1.37510840e-04],\n",
       "       [9.99741614e-01, 2.58407206e-04],\n",
       "       [9.99909163e-01, 9.07945941e-05],\n",
       "       [1.83489639e-02, 9.81651068e-01],\n",
       "       [9.99363124e-01, 6.36835466e-04],\n",
       "       [9.99924302e-01, 7.57337039e-05],\n",
       "       [1.48131701e-04, 9.99851823e-01],\n",
       "       [9.99940038e-01, 5.99882405e-05],\n",
       "       [5.90233576e-05, 9.99940991e-01],\n",
       "       [3.57585406e-04, 9.99642372e-01],\n",
       "       [9.99809563e-01, 1.90419305e-04],\n",
       "       [9.65600729e-01, 3.43992524e-02],\n",
       "       [1.34071946e-04, 9.99865890e-01],\n",
       "       [1.61209420e-04, 9.99838710e-01],\n",
       "       [3.35732184e-05, 9.99966383e-01],\n",
       "       [9.99748886e-01, 2.51159945e-04],\n",
       "       [9.99920487e-01, 7.94511652e-05],\n",
       "       [3.45288536e-05, 9.99965429e-01],\n",
       "       [1.39661905e-04, 9.99860287e-01],\n",
       "       [9.99810517e-01, 1.89458005e-04],\n",
       "       [6.15282697e-05, 9.99938488e-01],\n",
       "       [9.99761999e-01, 2.38005334e-04],\n",
       "       [9.99917746e-01, 8.22478469e-05],\n",
       "       [3.55742995e-05, 9.99964476e-01],\n",
       "       [3.93668422e-04, 9.99606311e-01],\n",
       "       [9.99902487e-01, 9.75179719e-05],\n",
       "       [9.99865055e-01, 1.34924310e-04],\n",
       "       [1.02750848e-04, 9.99897242e-01],\n",
       "       [9.99917269e-01, 8.27526019e-05],\n",
       "       [3.85059757e-05, 9.99961495e-01],\n",
       "       [9.99937415e-01, 6.26286856e-05],\n",
       "       [1.96284993e-04, 9.99803722e-01],\n",
       "       [9.99718368e-01, 2.81586166e-04],\n",
       "       [5.20903741e-05, 9.99947906e-01],\n",
       "       [9.99750912e-01, 2.49061035e-04],\n",
       "       [9.99872208e-01, 1.27752472e-04],\n",
       "       [4.02042315e-05, 9.99959826e-01],\n",
       "       [3.33022108e-05, 9.99966741e-01],\n",
       "       [9.99748647e-01, 2.51395220e-04],\n",
       "       [5.57822168e-05, 9.99944210e-01],\n",
       "       [3.79675912e-05, 9.99961972e-01],\n",
       "       [9.99910116e-01, 8.98993021e-05],\n",
       "       [9.99790132e-01, 2.09827849e-04],\n",
       "       [9.99795616e-01, 2.04433425e-04]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d3fa9bf-b963-4ee2-998d-6f04d01b0768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]),\n",
       " array([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred = np.argmax(labels_pred_prob, axis = 1)\n",
    "labels_test = np.argmax(labels_test, axis = 1)\n",
    "labels_pred, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdc3ef40-0218-4b31-ab07-7886744c8e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  0]\n",
      " [ 0 50]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_test, labels_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b3478-7392-410e-9329-c34c752c210a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e0e471e-a0cb-47d4-89e3-633a26cc0442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        54\n",
      "           1       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00       104\n",
      "   macro avg       1.00      1.00      1.00       104\n",
      "weighted avg       1.00      1.00      1.00       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0e2c0a8-32e2-44c2-b006-cf52c8a03da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, labels_pred_prob[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "auc_score = roc_auc_score(labels_test, labels_pred_prob[:, 1])\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6481f3de-efbb-43b0-af6b-d9811bf73122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 1.]),\n",
       " array([0.  , 0.02, 1.  , 1.  ]),\n",
       " array([         inf, 9.999678e-01, 6.073161e-01, 5.998824e-05],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22127411-ee37-4c77-ab76-1360cf7a3e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB0wUlEQVR4nO3dd1QU198G8GdZekcRQVwF7F1BUbFgIWI0KmoUgyIaNXZjTayoiSX2khhboqjRn91ILJBo7BKN2BtEkVhBUaRJkd37/uHLJhtAWVwYyvM5h5PsnTszz+6y7pc7d2ZkQggBIiIiolJIT+oARERERFJhIURERESlFgshIiIiKrVYCBEREVGpxUKIiIiISi0WQkRERFRqsRAiIiKiUouFEBEREZVaLISIiIio1GIhRKQjTk5OGDBggNQxSp02bdqgTZs2Usd4p1mzZkEmkyEuLk7qKEWOTCbDrFmzdLKt6OhoyGQyBAUF6WR7VPKxEKJiISgoCDKZTP2jr68PR0dHDBgwAI8ePZI6XpGWkpKCr7/+GvXr14epqSmsrKzQqlUrbN68GcXlDjs3b97ErFmzEB0dLXWUbJRKJTZu3Ig2bdqgTJkyMDIygpOTEwYOHIgLFy5IHU8ntm3bhuXLl0sdQ0NRzETFk77UAYi08dVXX8HZ2RlpaWn4448/EBQUhNOnT+P69eswNjaWNFtERAT09IrW3xaxsbFo3749bt26hT59+mDUqFFIS0vDnj17EBAQgEOHDmHr1q2Qy+VSR32rmzdvYvbs2WjTpg2cnJw0lv3666/ShAKQmpqKHj16ICQkBK1bt8bUqVNRpkwZREdHY+fOndi0aRPu37+PihUrSpZRF7Zt24br169j7NixBbL91NRU6Otr93WUW6bKlSsjNTUVBgYGOkxIJRkLISpWPvzwQzRu3BgAMHjwYNja2mLBggUIDg5G7969Jc1mZGRU6PtMS0uDoaFhrgVYQEAAbt26hX379qFr167q9jFjxmDSpElYvHgxGjVqhC+//LKwIgN4M0plZmamk20ZGhrqZDv5MWnSJISEhGDZsmXZvpBnzpyJZcuWFWoeIQTS0tJgYmJSqPvND5VKhYyMDBgbG+v0jxiZTCb5H0VUzAiiYmDjxo0CgPjzzz812g8cOCAAiHnz5mm037p1S/Ts2VPY2NgIIyMj4ebmJvbv359tu/Hx8WLs2LGicuXKwtDQUDg6Ogp/f3/x7NkzdZ+0tDQRGBgoqlSpIgwNDUXFihXFpEmTRFpamsa2KleuLAICAoQQQvz5558CgAgKCsq2z5CQEAFA/PLLL+q2hw8fioEDBwo7OzthaGgoateuLX788UeN9Y4dOyYAiP/9739i2rRpokKFCkImk4n4+PgcX7OwsDABQHz66ac5Ln/9+rWoVq2asLGxEa9evRJCCHHv3j0BQCxatEgsXbpUVKpUSRgbG4vWrVuLa9euZdtGXl7nrPfu+PHjYvjw4aJcuXLC2tpaCCFEdHS0GD58uKhevbowNjYWZcqUER9//LG4d+9etvX/+3Ps2DEhhBCenp7C09Mz2+u0Y8cOMWfOHOHo6CiMjIxEu3btxF9//ZXtOXz33XfC2dlZGBsbiyZNmoiTJ09m22ZOHjx4IPT19cUHH3zw1n5ZZs6cKQCIv/76SwQEBAgrKythaWkpBgwYIFJSUjT6btiwQbRt21aUK1dOGBoailq1aonvv/8+2zYrV64sOnfuLEJCQoSbm5swMjISy5Yt02obQghx6NAh0bp1a2Fubi4sLCxE48aNxdatW4UQb17f/772lStXVq+b188HADFy5Ejx008/idq1awt9fX2xb98+9bKZM2eq+yYmJorPP/9c/bksV66c8PLyEuHh4e/MlPU7vHHjRo3937p1S/Tq1UvY2toKY2NjUb16dTF16tS3vWVUSnBEiIq1rDkjNjY26rYbN26gRYsWcHR0xOTJk2FmZoadO3fCx8cHe/bsQffu3QEAycnJaNWqFW7duoVPP/0Urq6uiIuLQ3BwMB4+fAhbW1uoVCp07doVp0+fxmeffYZatWrh2rVrWLZsGSIjI/Hzzz/nmKtx48ZwcXHBzp07ERAQoLFsx44dsLGxgbe3N4A3h6+aNWsGmUyGUaNGoVy5cjh8+DAGDRqExMTEbCMNX3/9NQwNDTFx4kSkp6fnOiLyyy+/AAD69++f43J9fX34+flh9uzZOHPmDLy8vNTLNm/ejKSkJIwcORJpaWlYsWIF2rVrh2vXrqF8+fJavc5ZRowYgXLlyiEwMBApKSkAgD///BNnz55Fnz59ULFiRURHR2P16tVo06YNbt68CVNTU7Ru3RpjxozBypUrMXXqVNSqVQsA1P/NzTfffAM9PT1MnDgRCQkJWLhwIfr27Ytz586p+6xevRqjRo1Cq1atMG7cOERHR8PHxwc2NjbvPJx1+PBhZGZmwt/f/639/qt3795wdnbG/PnzcfHiRfzwww+ws7PDggULNHLVqVMHXbt2hb6+Pn755ReMGDECKpUKI0eO1NheREQEPvnkEwwdOhRDhgxBjRo1tNpGUFAQPv30U9SpUwdTpkyBtbU1Ll26hJCQEPj5+WHatGlISEjAw4cP1SNc5ubmAKD15+P333/Hzp07MWrUKNja2mY7zJll2LBh2L17N0aNGoXatWvj+fPnOH36NG7dugVXV9e3ZsrJ1atX0apVKxgYGOCzzz6Dk5MT7t69i19++QVz587N2xtHJZfUlRhRXmSNChw5ckQ8e/ZMPHjwQOzevVuUK1dOGBkZiQcPHqj7tm/fXtSrV0/jL1KVSiU8PDxEtWrV1G2BgYECgNi7d2+2/alUKiGEEFu2bBF6enri1KlTGsvXrFkjAIgzZ86o2/49IiSEEFOmTBEGBgbixYsX6rb09HRhbW2tMUozaNAg4eDgIOLi4jT20adPH2FlZaUercka6XBxcVG3vY2Pj48AkOuIkRBC7N27VwAQK1euFEL889e0iYmJePjwobrfuXPnBAAxbtw4dVteX+es965ly5YiMzNTY/85PY+skazNmzer23bt2qUxCvRvuY0I1apVS6Snp6vbV6xYIQCoR7bS09NF2bJlRZMmTcTr16/V/YKCggSAd44IjRs3TgAQly5demu/LFkjQv8doevevbsoW7asRltOr4u3t7dwcXHRaKtcubIAIEJCQrL1z8s2Xr58KSwsLETTpk1FamqqRt+sz4AQQnTu3FljFCiLNp8PAEJPT0/cuHEj23bwnxEhKysrMXLkyGz9/i23TDmNCLVu3VpYWFiIv//+O9fnSKVX0ZrZSfQOXl5eKFeuHBQKBT7++GOYmZkhODhY/df7ixcv8Pvvv6N3795ISkpCXFwc4uLi8Pz5c3h7e+Ovv/5Sn2W2Z88eNGjQINvIBfBmngEA7Nq1C7Vq1ULNmjXV24qLi0O7du0AAMeOHcs1q6+vL16/fo29e/eq23799Ve8fPkSvr6+AN7M6dizZw+6dOkCIYTGPry9vZGQkICLFy9qbDcgICBPc0CSkpIAABYWFrn2yVqWmJio0e7j4wNHR0f1Y3d3dzRt2hSHDh0CoN3rnGXIkCHZJmX/+3m8fv0az58/R9WqVWFtbZ3teWtr4MCBGqNlrVq1AgBERUUBAC5cuIDnz59jyJAhGhN1+/btqzHCmJus1+xtr29Ohg0bpvG4VatWeP78ucZ78O/XJSEhAXFxcfD09ERUVBQSEhI01nd2dlaPLv5bXrbx22+/ISkpCZMnT842rybrM/A22n4+PD09Ubt27Xdu19raGufOncPjx4/f2fddnj17hpMnT+LTTz9FpUqVNJbl5TlSycdDY1SsrFq1CtWrV0dCQgI2bNiAkydPakxSvnPnDoQQmDFjBmbMmJHjNp4+fQpHR0fcvXsXPXv2fOv+/vrrL9y6dQvlypXLdVu5adCgAWrWrIkdO3Zg0KBBAN4cFrO1tVV/UTx79gwvX77EunXrsG7dujztw9nZ+a2Zs2R9QSclJcHa2jrHPrkVS9WqVcvWt3r16ti5cycA7V7nt+VOTU3F/PnzsXHjRjx69EjjdP7/fuFr679felnFTXx8PADg77//BgBUrVpVo5++vn6uh2z+zdLSEsA/r6EucmVt88yZM5g5cybCwsLw6tUrjf4JCQmwsrJSP87t9yEv27h79y4AoG7dulo9hyzafj7y+ru7cOFCBAQEQKFQwM3NDZ06dUL//v3h4uKidcaswje/z5FKPhZCVKy4u7urzxrz8fFBy5Yt4efnh4iICJibm0OlUgEAJk6cmONfyUD2L763UalUqFevHpYuXZrjcoVC8db1fX19MXfuXMTFxcHCwgLBwcH45JNP1CMQWXn79euXbS5Rlvr162s8zusZQbVq1cLPP/+Mq1evonXr1jn2uXr1KgDk6a/0f8vP65xT7tGjR2Pjxo0YO3YsmjdvDisrK8hkMvTp00e9j/zK7ZIAQkfXTqpZsyYA4Nq1a2jYsGGe13tXrrt376J9+/aoWbMmli5dCoVCAUNDQxw6dAjLli3L9rrk9Lpqu4380vbzkdff3d69e6NVq1bYt28ffv31VyxatAgLFizA3r178eGHH753bqJ/YyFExZZcLsf8+fPRtm1bfPfdd5g8ebL6L0YDAwONyb85qVKlCq5fv/7OPleuXEH79u3zNYzu6+uL2bNnY8+ePShfvjwSExPRp08f9fJy5crBwsICSqXynXm19dFHH2H+/PnYvHlzjoWQUqnEtm3bYGNjgxYtWmgs++uvv7L1j4yMVI+UaPM6v83u3bsREBCAJUuWqNvS0tLw8uVLjX4FcQijcuXKAN6MbrVt21bdnpmZiejo6GwF6H99+OGHkMvl+Omnn7SeMP02v/zyC9LT0xEcHKwxevS2w7D53UaVKlUAANevX3/rHwi5vf7v+/l4GwcHB4wYMQIjRozA06dP4erqirlz56oLobzuL+t39V2fdSq9OEeIirU2bdrA3d0dy5cvR1paGuzs7NCmTRusXbsWT548ydb/2bNn6v/v2bMnrly5gn379mXrl/XXee/evfHo0SOsX78+W5/U1FT12U+5qVWrFurVq4cdO3Zgx44dcHBw0ChK5HI5evbsiT179uT4D/W/82rLw8MDXl5e2LhxIw4cOJBt+bRp0xAZGYkvvvgi21/qP//8s8Ycn/Pnz+PcuXPqLyFtXue3kcvl2UZovv32WyiVSo22rGsO/bdAeh+NGzdG2bJlsX79emRmZqrbt27dqj589jYKhQJDhgzBr7/+im+//TbbcpVKhSVLluDhw4da5coaMfrvYcKNGzfqfBsdOnSAhYUF5s+fj7S0NI1l/17XzMwsx0OV7/v5yIlSqcy2Lzs7O1SoUAHp6envzPRf5cqVQ+vWrbFhwwbcv39fY5muRgepeOOIEBV7kyZNQq9evRAUFIRhw4Zh1apVaNmyJerVq4chQ4bAxcUFsbGxCAsLw8OHD3HlyhX1ert370avXr3w6aefws3NDS9evEBwcDDWrFmDBg0awN/fHzt37sSwYcNw7NgxtGjRAkqlErdv38bOnTsRGhqqPlSXG19fXwQGBsLY2BiDBg3KdvHDb775BseOHUPTpk0xZMgQ1K5dGy9evMDFixdx5MgRvHjxIt+vzebNm9G+fXt069YNfn5+aNWqFdLT07F3714cP34cvr6+mDRpUrb1qlatipYtW2L48OFIT0/H8uXLUbZsWXzxxRfqPnl9nd/mo48+wpYtW2BlZYXatWsjLCwMR44cQdmyZTX6NWzYEHK5HAsWLEBCQgKMjIzQrl072NnZ5fu1MTQ0xKxZszB69Gi0a9cOvXv3RnR0NIKCglClSpU8jTgsWbIEd+/exZgxY7B371589NFHsLGxwf3797Fr1y7cvn1bYwQwLzp06ABDQ0N06dIFQ4cORXJyMtavXw87O7sci8732YalpSWWLVuGwYMHo0mTJvDz84ONjQ2uXLmCV69eYdOmTQAANzc37NixA+PHj0eTJk1gbm6OLl266OTz8V9JSUmoWLEiPv74YzRo0ADm5uY4cuQI/vzzT42Rw9wy5WTlypVo2bIlXF1d8dlnn8HZ2RnR0dE4ePAgLl++rFU+KoEkOVeNSEu5XVBRCCGUSqWoUqWKqFKlivr07Lt374r+/fsLe3t7YWBgIBwdHcVHH30kdu/erbHu8+fPxahRo4Sjo6P6YnABAQEap7JnZGSIBQsWiDp16ggjIyNhY2Mj3NzcxOzZs0VCQoK6339Pn8/y119/qS/6dvr06RyfX2xsrBg5cqRQKBTCwMBA2Nvbi/bt24t169ap+2SdFr5r1y6tXrukpCQxa9YsUadOHWFiYiIsLCxEixYtRFBQULbTh/99QcUlS5YIhUIhjIyMRKtWrcSVK1eybTsvr/Pb3rv4+HgxcOBAYWtrK8zNzYW3t7e4fft2jq/l+vXrhYuLi5DL5Xm6oOJ/X6fcLrS3cuVKUblyZWFkZCTc3d3FmTNnhJubm+jYsWMeXl0hMjMzxQ8//CBatWolrKyshIGBgahcubIYOHCgxqn1WafP//tinf9+ff59Ecng4GBRv359YWxsLJycnMSCBQvEhg0bsvXLuqBiTvK6jay+Hh4ewsTERFhaWgp3d3fxv//9T708OTlZ+Pn5CWtr62wXVMzr5wP/f0HFnOBfp8+np6eLSZMmiQYNGggLCwthZmYmGjRokO1ikLllyu19vn79uujevbuwtrYWxsbGokaNGmLGjBk55qHSRSYExwaJ6I3o6Gg4Oztj0aJFmDhxotRxJKFSqVCuXDn06NEjx0M+RFSycI4QEZVaaWlp2eaJbN68GS9evECbNm2kCUVEhYpzhIio1Prjjz8wbtw49OrVC2XLlsXFixfx448/om7duujVq5fU8YioELAQIqJSy8nJCQqFAitXrsSLFy9QpkwZ9O/fH998842kd7UnosLDOUJERERUanGOEBEREZVaLISIiIio1Cp1c4RUKhUeP34MCwsL3nmYiIiomBBCICkpCRUqVMh2Ydr3UeoKocePH7/zRplERERUND148AAVK1bU2fZKXSFkYWEB4M0LaWlpKXEaIiIiyovExEQoFAr197iulLpCKOtwmKWlJQshIiKiYkbX01o4WZqIiIhKLRZCREREVGqxECIiIqJSi4UQERERlVoshIiIiKjUYiFEREREpRYLISIiIiq1WAgRERFRqcVCiIiIiEotFkJERERUaklaCJ08eRJdunRBhQoVIJPJ8PPPP79znePHj8PV1RVGRkaoWrUqgoKCCjwnERERlUySFkIpKSlo0KABVq1alaf+9+7dQ+fOndG2bVtcvnwZY8eOxeDBgxEaGlrASYmIiKgkkvSmqx9++CE+/PDDPPdfs2YNnJ2dsWTJEgBArVq1cPr0aSxbtgze3t4FFZOIiIhKqGI1RygsLAxeXl4abd7e3ggLC5MoERERERU0lUrgxo2nBbJtSUeEtBUTE4Py5ctrtJUvXx6JiYlITU2FiYlJtnXS09ORnp6ufpyYmPjmfzbUBEyKVR1IRERU6jxJMMHATZ44EVmmQLZfrAqh/Jg/fz5mz56dfUHKE0BZ+HmIiIgob/Zfr4HBu7oiLsUMQFqB7KNYFUL29vaIjY3VaIuNjYWlpWWOo0EAMGXKFIwfP179ODExEQqFApDJAPMKBZqXiIiI8udZkjH6/u9jpKQbAADsLFLxNEn3+ylWhVDz5s1x6NAhjbbffvsNzZs3z3UdIyMjGBkZZV9gag8MfajriERERKQD5QAst76IIUN+gY9PTSxd6gkXlxU634+khVBycjLu3Lmjfnzv3j1cvnwZZcqUQaVKlTBlyhQ8evQImzdvBgAMGzYM3333Hb744gt8+umn+P3337Fz504cPHhQqqdAREREOqBUqpCZqYKR0T+lyaBBjaBQWKJDhypISiqA4SBIfNbYhQsX0KhRIzRq1AgAMH78eDRq1AiBgYEAgCdPnuD+/fvq/s7Ozjh48CB+++03NGjQAEuWLMEPP/zAU+eJiIiKsQcPEuDltQUTJ/6q0S6TyeDtXRUymazA9i0TQogC23oRlJiYCCsrKyQsc4Dl2MdSxyEiIirVdu68gaFDD+DlyzeToQ8e9EOnTtWy9VN/fyckwNLSUmf7L1ZzhIiIiKhkSExMx5gxh7Fp0xV1m0JhCQsLw0LNwUKIiIiIClVY2AP067cPUVHx6jZf3zpYvbozbGxyPgu8oLAQIiIiokKRmanC3Lkn8fXXJ6FUvpmZY2FhiFWrOqFfv/oFOhcoNyyEiIiIqMA9f/4KXbr8D2Fh/1y6xsNDgZ9+6g5nZxvJcvEeE0RERFTgrK2Noa//puyQy2WYPbsNTpwYIGkRBLAQIiIiokIgl+thy5bucHV1wOnTnyIw0FNdGEmJh8aIiIhI506ciIaJiQHc3R3VbZUrW+PChSGSzAXKjfSlGBEREZUYGRlKTJlyBG3bbsInn+xBUlK6xvKiVAQBLISIiIhIRyIi4tC8+Y/45pszEAKIiorH6tUXpI71Vjw0RkRERO9FCIH16y9i7NgQpKZmAgAMDPQwd247TJjgIXG6t2MhRERERPn27FkKhgz5Bfv3R6jbatQoi23besLV1UHCZHnDQoiIiIjyJTT0DgYM2I+YmGR127BhbliyxBumpgYSJss7FkJERESktdjYZPj47EBa2ptDYba2ptiwoSu6dKkhcTLtcLI0ERERaa18eXN88017AIC3dxVcuza82BVBAEeEiIiIKA9UKgGlUgUDA7m6bfTopqhY0RLdu9eCnl7ROi0+rzgiRERERG/15EkSPvxwK6ZP/12jXU9Php49axfbIghgIURERERvsX//bdSrtxq//noXixadxe+/35M6kk7x0BgRERFlk5KSgQkTfsXateHqtvLlzSVMVDBYCBEREZGG8PDH8PPbi8jI5+q2bt1q4IcfusLW1lTCZLrHQoiIiIgAAEqlCosXn8X06ceQmakCAJiaGmD5cm8MHuxa5O4TpgsshIiIiAhxca/Qq9cuHD8erW5zc3PAtm09Ub16WemCFTBOliYiIiJYWRkhOTkDACCTAVOmtMTZs4NKdBEEsBAiIiIiAAYGcmzd2gO1atni2LEAzJvXHoaG8nevWMzx0BgREVEpFBb2AKamBmjQwF7dVr16WVy/PqJYXxdIWxwRIiIiKkUyM1WYPfs4WrXaiE8+2YNXr15rLC9NRRDAQoiIiKjUiIqKR+vWGzFr1gkolQK3bsXh++//lDqWpHhojIiIqIQTQmDLlqsYNeoQkpLeTIiWy2WYOdMTY8c2kzidtFgIERERlWDx8akYNuwgdu68oW6rUsUGP/3UA82aVZQwWdHAQoiIiKiEOn48Gv7++/DwYaK6beDAhlixoiMsLIwkTFZ0sBAiIiIqgZ48SYK390/IyFACAGxsjLF27Ufo1auOxMmKFk6WJiIiKoEcHCwwc6YnAKBtWydcvTqcRVAOOCJERERUAgghoFIJyOX/jHF8+WULKBSW6Nu3fqk7LT6vOCJERERUzD17loLu3XdgzpyTGu1yuR78/RuwCHoLjggREREVY6GhdzBgwH7ExCTjwIFIdOhQBc2bK6SOVWywECIiIiqG0tIyMWXKESxffk7dZmNjor5OEOUNCyEiIqJi5tq1WPTtuxfXrj1Vt3l7V0FQkA/s7c0lTFb8sBAiIiIqJlQqgW+/PYcvvzyC9PQ3p8UbGcmxcOEHGDXKnXOB8oGFEBERUTHw/Pkr9O27F6Ghd9Vt9erZYdu2nqhb107CZMUbzxojIiIqBszMDPHoUZL68bhxzXD+/BAWQe+JhRAREVExYGysj23besDZ2Rqhof2wdKk3jI15YOd98RUkIiIqgsLDH8PMzBA1a9qq2+rVK4/IyNHQ1+c4hq7wlSQiIipClEoVFiw4jWbNfsQnn+xBenqmxnIWQbrFV5OIiKiIePAgAe3bb8bkyUeRmanC5csx+P77P6WOVaLx0BgREVERsHPnDQwdegAvX6YBAGQyYPLklhg50l3iZCUbCyEiIiIJJSamY8yYw9i06Yq6TaGwxJYt3eHp6SRdsFKChRAREZFEwsIeoF+/fYiKile3+frWwerVnWFjYyJhstKDhRAREZEEHj1KRJs2m5CR8eYK0RYWhli1qhP69asPmYxXiC4snCxNREQkAUdHS0yc2BwA4OGhwJUrw+Dv34BFUCHjiBAREVEhEEIAgEahM2tWG1SqZIVBg1x5WrxE+KoTEREVsPj4VPTpswdLloRptBsYyDF0aGMWQRLiiBAREVEBOn48Gv7++/DwYSL27buF9u2d0aiRg9Sx6P+xBCUiIioAGRlKTJ58BO3abcLDh4kAAHNzQ8TEJEucjP6NI0JEREQ6FhERBz+/vbh48Ym6rW1bJ2ze3B0VK1pKmIz+i4UQERGRjgghsG5dOMaNC0Vq6pt7hBkY6GHu3HaYMMEDeno8I6yoYSFERESkAy9epGLgwP0IDo5Qt9WoURbbtvWEqyvnBBVVLISIiIh0wMhIjtu349SPhw9vjMWLO8DU1EDCVPQunCxNRESkA2Zmhti6tQcqVLBAcHAffP99ZxZBxQBHhIiIiPLh2rVYmJkZwsXFRt3WuHEFREWNgZERv16LC44IERERaUGlElix4g80abIeffvuRWamSmM5i6DihYUQERFRHj15koQPP9yKsWNDkZ6uxB9/PMTq1X9KHYveg+SF0KpVq+Dk5ARjY2M0bdoU58+ff2v/5cuXo0aNGjAxMYFCocC4ceOQlpZWSGmJiKi02r//NurVW41ff72rbhs3rhmGDHGTMBW9L0nH73bs2IHx48djzZo1aNq0KZYvXw5vb29ERETAzs4uW/9t27Zh8uTJ2LBhAzw8PBAZGYkBAwZAJpNh6dKlEjwDIiIq6VJSMjBhwq9YuzZc3ebgYI6gIB906FBFwmSkC5KOCC1duhRDhgzBwIEDUbt2baxZswampqbYsGFDjv3Pnj2LFi1awM/PD05OTujQoQM++eSTd44iERER5Ud4+GO4uq7TKIJ8fGri6tXhLIJKCMkKoYyMDISHh8PLy+ufMHp68PLyQlhYWI7reHh4IDw8XF34REVF4dChQ+jUqVOu+0lPT0diYqLGDxER0bs8eJAAD48NiIx8DgAwNTXA+vVdsHdvb9jamkqcjnRFskIoLi4OSqUS5cuX12gvX748YmJiclzHz88PX331FVq2bAkDAwNUqVIFbdq0wdSpU3Pdz/z582FlZaX+USgUOn0eRERUMikUVhgxojEAwM3NAZcuDcXgwa6QyXibjJJE8snS2jh+/DjmzZuH77//HhcvXsTevXtx8OBBfP3117muM2XKFCQkJKh/Hjx4UIiJiYioOBFCaDyeP98LS5d2wNmzg1C9elmJUlFBkmyytK2tLeRyOWJjYzXaY2NjYW9vn+M6M2bMgL+/PwYPHgwAqFevHlJSUvDZZ59h2rRp0NPLXtcZGRnByMhI90+AiIhKjMTEdIwZcxju7o4YMaKJut3YWB/jxjWXMBkVNMlGhAwNDeHm5oajR4+q21QqFY4ePYrmzXP+pXv16lW2YkculwPIXsUTERHlRVjYAzRsuAabNl3BhAm/4tatZ1JHokIk6enz48ePR0BAABo3bgx3d3csX74cKSkpGDhwIACgf//+cHR0xPz58wEAXbp0wdKlS9GoUSM0bdoUd+7cwYwZM9ClSxd1QURERJQXmZkqzJlzEnPmnIRS+eaPaQMDPdy9G49atcpJnI4Ki6SFkK+vL549e4bAwEDExMSgYcOGCAkJUU+gvn//vsYI0PTp0yGTyTB9+nQ8evQI5cqVQ5cuXTB37lypngIRERVDUVHx6NdvL8LCHqrbPDwU+Omn7nB2tnnLmlTSyEQpO6aUmJgIKysrJCxzgOXYx1LHISKiQiSEwObNVzBq1GEkJ2cAAORyGQIDPTF1aivo6xerc4hKFfX3d0ICLC0tdbZd3hmOiIhKhZcv0zB06AHs3HlD3ebiYoOtW3ugWbOKEiYjKbEQIiKiUkEmA86d++dQ2IABDbFyZUdYWPDM4tKMY4BERFQqWFkZY8uW7rC1NcXOnR9j48ZuLIKII0JERFQyRUTEwczMEBUr/jOfpFWryoiO/hxmZoYSJqOihCNCRERUogghsHbtBTRqtBb9+++DSqV5ThCLIPo3FkJERFRiPHuWAh+fHRg27CBSUzNx7Fg01q0Lf/eKVGrx0BgREZUIoaF3MGDAfsTEJKvbhg1zQ//+DSRMRUUdCyEiIirW0tIyMWXKESxffk7dZmtrig0buqJLlxoSJqPigIUQEREVW9euxaJv3724du2pus3buwqCgnxgb28uYTIqLlgIERFRsfT33y/RpMl6pKcrAQBGRnIsXPgBRo1yh56eTOJ0VFxwsjQRERVLlStbq+f/1KtnhwsXPsOYMU1ZBJFWOCJERETF1rJl3qhc2QoTJnjA2JhfaaQ9jggREVGRl5KSgWHDDiAo6LJGu5mZIaZNa80iiPKNvzlERFSkhYc/Rt++exER8Rxbt15Dq1aVUKVKGaljUQnBESEiIiqSlEoVFiw4jWbNfkRExHMAgEolcP3603esSZR3HBEiIqIi58GDBPj778OJE3+r29zcHLBtW09Ur15WwmRU0rAQIiKiImXnzhsYOvQAXr5MAwDIZMDkyS0xa1YbGBrKJU5HJQ0LISIiKhKSktIxevRhbNp0Rd2mUFhiy5bu8PR0ki4YlWgshIiIqEhIT1fi11/vqh/7+tbB6tWdYWNjImEqKuk4WZqIiIoEW1tTbNrkA0tLI2ze7IP//a8niyAqcBwRIiIiSURFxcPMzADly/9zT7APPqiCv/8eC2trYwmTUWnCESEiIipUQghs2nQZDRqswaefBkMIobGcRRAVJhZCRERUaOLjU9Gnzx4MGLAfyckZOHToL2zceFnqWFSK8dAYEREViuPHo+Hvvw8PHyaq2wYMaIhevWpLmIpKOxZCRERUoDIylAgMPIaFC88g6yiYjY0x1q79CL161ZE2HJV6LISIiKjA3L4dh7599+LixSfqtrZtnbB5c3dUrGgpYTKiN1gIERFRgYiKioer61qkpmYCAAwM9DB3bjtMmOABPT2ZxOmI3uBkaSIiKhAuLjbo0aMWAKBGjbL444/BmDSpBYsgKlI4IkRERAVm1apOqFzZCtOmtYapqYHUcYiyea8RobS0NF3lICKiYiwtLRPjxoVg164bGu1WVsaYO7c9iyAqsrQuhFQqFb7++ms4OjrC3NwcUVFRAIAZM2bgxx9/1HlAIiIq2q5di4W7+3osX34On312AA8eJEgdiSjPtC6E5syZg6CgICxcuBCGhobq9rp16+KHH37QaTgiIiq6VCqBFSv+QJMm63Ht2lMAQGrqa1y48FjiZER5p3UhtHnzZqxbtw59+/aFXC5Xtzdo0AC3b9/WaTgiIiqanjxJQqdOWzF2bCjS05UAgHr17HDhwmfo3r2WxOmI8k7rydKPHj1C1apVs7WrVCq8fv1aJ6GIiKjo2r//NgYP/gVxca/UbePGNcO8ee1hbMxzcKh40fo3tnbt2jh16hQqV66s0b579240atRIZ8GIiKhoSUnJwIQJv2Lt2nB1m4ODOYKCfNChQxUJkxHln9aFUGBgIAICAvDo0SOoVCrs3bsXERER2Lx5Mw4cOFAQGYmIqAhITEzHnj231I99fGpi/fousLU1lTAV0fvReo5Qt27d8Msvv+DIkSMwMzNDYGAgbt26hV9++QUffPBBQWQkIqIiwMHBAj/80AWmpgZYv74L9u7tzSKIij2ZEFm3wCsdEhMTYWVlhYRlDrAcyzMbiIhy8+BBAszMDFGmjIlG+9OnKbCzM5MoFZVW6u/vhARYWuruPnVajwi5uLjg+fPn2dpfvnwJFxcXnYQiIiJp7dx5A/Xrr8HQoQfw37+XWQRRSaJ1IRQdHQ2lUpmtPT09HY8ePdJJKCIikkZiYjoGDPgZvr678fJlGnbvvolt265JHYuowOR5snRwcLD6/0NDQ2FlZaV+rFQqcfToUTg5Oek0HBERFZ6wsAfo23cv7t17qW7z9a2DTp2qSReKqIDluRDy8fEBAMhkMgQEBGgsMzAwgJOTE5YsWaLTcEREVPAyM1WYO/ckvv76JJTKN4fBLCwMsWpVJ/TrVx8yGe8WTyVXngshlUoFAHB2dsaff/4JW1vbAgtFRESFIyoqHv367UVY2EN1m4eHAj/91B3OzjYSJiMqHFpfR+jevXsFkYOIiArZnTsv4Oq6FklJGQAAuVyGwEBPTJ3aCvr6Wk8hJSqW8nUt9JSUFJw4cQL3799HRkaGxrIxY8boJBgRERWsKlVs0L69C37++TZcXGywdWsPNGtWUepYRIVK60Lo0qVL6NSpE169eoWUlBSUKVMGcXFxMDU1hZ2dHQshIqJiQiaTYf36Lqhc2Qpff90WFhZGUkciKnRaj32OGzcOXbp0QXx8PExMTPDHH3/g77//hpubGxYvXlwQGYmI6D1lZCgxefIRHDwYqdFua2uK5cs7sgiiUkvrQujy5cuYMGEC9PT0IJfLkZ6eDoVCgYULF2Lq1KkFkZGIiN5DREQcmjf/EQsWnMGnnwYjNjZZ6khERYbWhZCBgQH09N6sZmdnh/v37wMArKys8ODBA92mIyKifBNCYO3aC2jUaC0uXnwCAIiPT8WZM/y3miiL1nOEGjVqhD///BPVqlWDp6cnAgMDERcXhy1btqBu3boFkZGIiLT07FkKBg/+BcHBEeq2GjXKYtu2nnB1dZAwGVHRovWI0Lx58+Dg8OZDNHfuXNjY2GD48OF49uwZ1q5dq/OARESkndDQO6hff41GETR8eGNcvDiURRDRf2g9ItS4cWP1/9vZ2SEkJESngYiIKH/S0jIxZcoRLF9+Tt1ma2uKDRu6okuXGhImIyq6dHbFrIsXL+Kjjz7S1eaIiEhLT5+mYOPGy+rHHTtWxbVrw1kEEb2FVoVQaGgoJk6ciKlTpyIqKgoAcPv2bfj4+KBJkybq23AQEVHhq1TJCqtXd4aRkRwrV3bEoUN+sLc3lzoWUZGW50NjP/74I4YMGYIyZcogPj4eP/zwA5YuXYrRo0fD19cX169fR61atQoyKxER/cuTJ0kwMzOEpeU/1wD65JN6aNmyEhQKKwmTERUfeR4RWrFiBRYsWIC4uDjs3LkTcXFx+P7773Ht2jWsWbOGRRARUSHav/826tdfgzFjDmdbxiKIKO/yXAjdvXsXvXr1AgD06NED+vr6WLRoESpW5H1piIgKS0pKBoYNOwAfnx2Ii3uFTZuuYM+em1LHIiq28nxoLDU1FaampgDe3J/GyMhIfRo9EREVvPDwx/Dz24vIyOfqNh+fmvD0dJIuFFExp9Xp8z/88APMzd9MvMvMzERQUBBsbW01+vCmq0REuqVUqrB48VlMn34MmZlvTkoxNTXAihUdMWhQI8hkMokTEhVfMiGEyEtHJyend37YZDKZ+myyvFq1ahUWLVqEmJgYNGjQAN9++y3c3d1z7f/y5UtMmzYNe/fuxYsXL1C5cmUsX74cnTp1ytP+EhMTYWVlhYRlDrAc+1irrEREhe3BgwT4++/DiRN/q9vc3BywbVtPVK9eVsJkRIVL/f2dkABLS0udbTfPI0LR0dE622mWHTt2YPz48VizZg2aNm2K5cuXw9vbGxEREbCzs8vWPyMjAx988AHs7Oywe/duODo64u+//4a1tbXOsxERSS0y8jmaNv0BL1+mAQBkMmDy5JaYNasNDA3lEqcjKhm0vrK0Li1duhRDhgzBwIEDAQBr1qzBwYMHsWHDBkyePDlb/w0bNuDFixc4e/YsDAwMALwZqSIiKomqVi2Dpk0dERp6FwqFJbZs6c75QEQ6prMrS2srIyMD4eHh8PLy+ieMnh68vLwQFhaW4zrBwcFo3rw5Ro4cifLly6Nu3bqYN28elEplYcUmIio0enoybNzYDZ995oorV4axCCIqAJKNCMXFxUGpVKJ8+fIa7eXLl8ft27dzXCcqKgq///47+vbti0OHDuHOnTsYMWIEXr9+jZkzZ+a4Tnp6OtLT09WPExMTdfckiIh0JDNThblzT6JVq8po185Z3e7gYIG1a7tImIyoZJP00Ji2VCoV7OzssG7dOsjlcri5ueHRo0dYtGhRroXQ/PnzMXv27EJOSkSUd1FR8ejXby/Cwh7C0dECV68OR5kyJlLHIioVJDs0ZmtrC7lcjtjYWI322NhY2Nvb57iOg4MDqlevDrn8n0mCtWrVQkxMDDIyMnJcZ8qUKUhISFD/PHjwQHdPgojoPQghsHnzFTRsuAZhYQ8BADExyTh27J7EyYhKj3wVQnfv3sX06dPxySef4OnTpwCAw4cP48aNG3nehqGhIdzc3HD06FF1m0qlwtGjR9G8efMc12nRogXu3LmjcXPXyMhIODg4wNDQMMd1jIyMYGlpqfFDRCS1+PhU9OmzBwEBPyMp6c0fci4uNjh9+lP07Flb4nREpYfWhdCJEydQr149nDt3Dnv37kVycjIA4MqVK7kensrN+PHjsX79emzatAm3bt3C8OHDkZKSoj6LrH///pgyZYq6//Dhw/HixQt8/vnniIyMxMGDBzFv3jyMHDlS26dBRCSZ48ejUb/+Guzc+c8fjwMGNMTly0PRrBlvW0RUmLSeIzR58mTMmTMH48ePh4WFhbq9Xbt2+O6777Talq+vL549e4bAwEDExMSgYcOGCAkJUU+gvn//PvT0/qnVFAoFQkNDMW7cONSvXx+Ojo74/PPP8eWXX2r7NIiICl1GhhIzZx7DggVnkHUpW2trY6xb9xF69aojbTiiUirPV5bOYm5ujmvXrsHZ2RkWFha4cuUKXFxcEB0djZo1ayItLa2gsuoEryxNRFKJiopH/fqrkZLyGgDQpo0TNm/24d3iifKgoK4srfWhMWtrazx58iRb+6VLl+Do6KiTUEREJZGLiw1WrOgIAwM9LFzohaNH+7MIIpKY1ofG+vTpgy+//BK7du2CTCaDSqXCmTNnMHHiRPTv378gMhIRFUtxca9gamoAU1MDddunnzaCp6cTqlYtI2EyIsqi9YjQvHnzULNmTSgUCiQnJ6N27dpo3bo1PDw8MH369ILISERU7ISG3kG9eqsxadKvGu0ymYxFEFERovUcoSz379/H9evXkZycjEaNGqFatWq6zlYgOEeIiApSWlompkw5guXLz6nbDhz4BJ07V5cwFVHxJ/nd57OcPn0aLVu2RKVKlVCpUiWdBSEiKu6uXYtF3757ce3aU3Vbx45V4eZWQcJURPQ2Wh8aa9euHZydnTF16lTcvHmzIDIRERUrKpXAihV/oEmT9eoiyMhIjpUrO+LQIT/Y25tLnJCIcqN1IfT48WNMmDABJ06cQN26ddGwYUMsWrQIDx8+LIh8RERF2pMnSejUaSvGjg1FeroSAFCvnh0uXPgMo0c3hUwmkzghEb2N1oWQra0tRo0ahTNnzuDu3bvo1asXNm3aBCcnJ7Rr164gMhIRFUkREXGoX38NQkPvqtvGjWuG8+eHoG5dOwmTEVFevddNV52dnTF58mR88803qFevHk6cOKGrXERERV7VqmVQu3Y5AICDgzlCQ/th6VJvGBtrPf2SiCSS70LozJkzGDFiBBwcHODn54e6devi4MGDusxGRFSkyeV62LKlO/z96+Pq1eHo0KGK1JGISEta/9kyZcoUbN++HY8fP8YHH3yAFStWoFu3bjA1NS2IfERERYJSqcLixWfRqlVleHgo1O2VKllh8+buEiYjovehdSF08uRJTJo0Cb1794atrW1BZCIiKlIePEiAv/8+nDjxN5ydrXH58jBYWhpJHYuIdEDrQujMmTMFkYOIqEjaufMGhg49gJcv39xQOjr6JX799S4+/ri2xMmISBfyVAgFBwfjww8/hIGBAYKDg9/at2vXrjoJRkQkpcTEdIwZcxibNl1RtykUltiypTs8PZ2kC0ZEOpWnQsjHxwcxMTGws7ODj49Prv1kMhmUSqWushERSSIs7AH69duHqKh4dZuvbx2sXt0ZNjYmEiYjIl3LUyGkUqly/H8iopIkM1OFuXNP4uuvT0KpfHMbRgsLQ6xa1Qn9+tXnxRGJSiCtT5/fvHkz0tPTs7VnZGRg8+bNOglFRCSFu3dfYP780+oiyMNDgStXhsHfvwGLIKISSutCaODAgUhISMjWnpSUhIEDB+okFBGRFGrUsMXChR9ALpdh9uw2OHFiAJydbaSORUQFSOuzxoQQOf5l9PDhQ1hZWekkFBFRYYiPT4WpqQGMjP75p3D0aHe0a+fMW2QQlRJ5LoQaNWoEmUwGmUyG9u3bQ1//n1WVSiXu3buHjh07FkhIIiJdO348Gv7++9CnTx0sWtRB3S6TyVgEEZUieS6Ess4Wu3z5Mry9vWFubq5eZmhoCCcnJ/Ts2VPnAYmIdCkjQ4mZM49hwYIzEAJYvDgMHTtWRfv2LlJHIyIJ5LkQmjlzJgDAyckJvr6+MDY2LrBQREQFISIiDn5+e3Hx4hN1W9u2TqhRg1fJJyqttJ4jFBAQUBA5iIgKjBAC69aFY9y4UKSmZgIADAz0MHduO0yY4AE9PZ4RRlRa5akQKlOmDCIjI2FrawsbG5u3nkb64sULnYUjInpfz56lYPDgXxAcHKFuq1GjLLZt6wlXVwcJkxFRUZCnQmjZsmWwsLBQ/z+vp0FExUFERBzatNmEmJhkddvw4Y2xeHEHmJoaSJiMiIqKPBVC/z4cNmDAgILKQkSkUy4uNlAoLBETkwxbW1Ns2NAVXbrUkDoWERUhWl9Q8eLFi7h27Zr68f79++Hj44OpU6ciIyNDp+GIiN6HgYEcW7f2QI8etXDt2nAWQUSUjdaF0NChQxEZGQkAiIqKgq+vL0xNTbFr1y588cUXOg9IRJQXKpXAypXncOnSE432atXKYs+e3rC3N89lTSIqzbQuhCIjI9GwYUMAwK5du+Dp6Ylt27YhKCgIe/bs0XU+IqJ3evIkCZ06bcXnn4fAz28vXr16LXUkIiomtC6EhBDqO9AfOXIEnTp1AgAoFArExcXpNh0R0Tvs338b9euvQWjoXQDA7dtxOHz4L4lTEVFxofV1hBo3bow5c+bAy8sLJ06cwOrVqwEA9+7dQ/ny5XUekIgoJykpGZgw4VesXRuubnNwMEdQkA86dKgiYTIiKk60LoSWL1+Ovn374ueff8a0adNQtWpVAMDu3bvh4eGh84BERP8VHv4Yfn57ERn5XN3m41MT69d3ga2tqYTJiKi4kQkhhC42lJaWBrlcDgODon1tjsTERFhZWSFhmQMsxz6WOg4RaUGpVGHRorOYMeMYMjPfHKI3NTXA8uXeGDzYldc4IyrB1N/fCQmwtLTU2Xa1HhHKEh4ejlu3bgEAateuDVdXV52FIiLKye3bcRpFkJubA7Zt64nq1ctKnIyIiiutC6GnT5/C19cXJ06cgLW1NQDg5cuXaNu2LbZv345y5crpOiMREQCgTh07fP11W0ydehSTJ7fErFltYGgolzoWERVjWp81Nnr0aCQnJ+PGjRt48eIFXrx4gevXryMxMRFjxowpiIxEVEolJaWrR3+yTJrkgfPnh2DevPYsgojovWldCIWEhOD7779HrVq11G21a9fGqlWrcPjwYZ2GI6LSKyzsARo2XIs5c05qtMvlemjcuIJEqYiopNG6EFKpVDlOiDYwMFBfX4iIKL8yM1WYPfs4WrXaiKioeHz99UmcPftA6lhEVEJpXQi1a9cOn3/+OR4//ueMq0ePHmHcuHFo3769TsMRUekSFRWP1q03YtasE1Aq35zQ2qxZRTg48PYYRFQwtC6EvvvuOyQmJsLJyQlVqlRBlSpV4OzsjMTERHz77bcFkZGISjghBDZvvoKGDdcgLOwhAEAul2H27DY4cWIAnJ1tpA1IRCWW1meNKRQKXLx4EUePHlWfPl+rVi14eXnpPBwRlXzx8akYPvwgduy4oW5zcbHB1q090KxZRQmTEVFpoFUhtGPHDgQHByMjIwPt27fH6NGjCyoXEZUCERFx+OCDLXjwIFHdNmBAQ6xc2REWFkYSJiOi0iLPhdDq1asxcuRIVKtWDSYmJti7dy/u3r2LRYsWFWQ+IirBKle2hrW1MR48SISNjTHWrv0IvXrVkToWEZUieZ4j9N1332HmzJmIiIjA5cuXsWnTJnz//fcFmY2ISjhjY31s29YTnTpVw9Wrw1kEEVGhy3MhFBUVhYCAAPVjPz8/ZGZm4smTJwUSjIhKFiEE1q0Lx82bzzTa69a1w8GDfqhYUXf3DiIiyqs8F0Lp6ekwMzP7Z0U9PRgaGiI1NbVAghFRyfHsWQp8fHZg6NAD8PPbg/T0TKkjEREB0HKy9IwZM2Bqaqp+nJGRgblz58LKykrdtnTpUt2lI6JiLzT0DgYM2I+YmGQAwJUrsThwIBI9e9aWOBkRkRaFUOvWrREREaHR5uHhgaioKPVjmUymu2REVKylpWVi8uQjWLHinLrN1tYUGzZ0RZcuNSRMRkT0jzwXQsePHy/AGERUkly7Fgs/v724fv2pus3buwqCgnxgb8+rRBNR0aH1BRWJiHKjUgl8++05fPnlEaSnKwEARkZyLFz4AUaNcoeeHkeNiahoYSFERDpz7Vosxo//FSrVm/uE1atnh23beqJuXTuJkxER5Uzre40REeWmQQN7TJ3aEgAwblwznD8/hEUQERVpHBEionx79eo1jI31NQ55BQZ6okOHKmjVqrKEyYiI8oYjQkSUL+Hhj9Go0VosWXJWo93AQM4iiIiKjXwVQqdOnUK/fv3QvHlzPHr0CACwZcsWnD59WqfhiKjoUSpVWLDgNJo1+xGRkc8xbdrvuHiRV5gnouJJ60Joz5498Pb2homJCS5duoT09HQAQEJCAubNm6fzgERUdDx4kID27Tdj8uSjyMxUAQDq1y8Pc3NDiZMREeWP1oXQnDlzsGbNGqxfvx4GBgbq9hYtWuDixYs6DUdERcfOnTdQv/4anDjxNwBAJgOmTGmJs2cHoXr1shKnIyLKH60nS0dERKB169bZ2q2srPDy5UtdZCKiIiQxMR1jxhzGpk1X1G0KhSW2bOkOT08n6YIREemA1oWQvb097ty5AycnJ43206dPw8XFRVe5iKgIiIiIQ6dO2xAVFa9u8/WtgzVrPoK1tbGEyYiIdEPrQ2NDhgzB559/jnPnzkEmk+Hx48fYunUrJk6ciOHDhxdERiKSSMWKltDXf/PPhIWFITZv9sH//teTRRARlRhaF0KTJ0+Gn58f2rdvj+TkZLRu3RqDBw/G0KFDMXr06HyFWLVqFZycnGBsbIymTZvi/PnzeVpv+/btkMlk8PHxydd+iejtzMwMsW1bD7Rp44QrV4bB378Bb65MRCWKTAgh8rNiRkYG7ty5g+TkZNSuXRvm5vm7keKOHTvQv39/rFmzBk2bNsXy5cuxa9cuREREwM4u9yvSRkdHo2XLlnBxcUGZMmXw888/52l/iYmJsLKyQsIyB1iOfZyvzEQlkRACW7ZcRYsWClSpUibbMhZARCQl9fd3QgIsLS11tt18X1DR0NAQtWvXhru7e76LIABYunQphgwZgoEDB6J27dpYs2YNTE1NsWHDhlzXUSqV6Nu3L2bPns15SUQ6EB+fij599iAg4Gf07bsXr18rNZazCCKikkrrydJt27Z96z+Kv//+e563lZGRgfDwcEyZMkXdpqenBy8vL4SFheW63ldffQU7OzsMGjQIp06deus+0tPT1dc6At5UlET0j+PHo+Hvvw8PH775bJw79wgHDkSie/daEicjIip4WhdCDRs21Hj8+vVrXL58GdevX0dAQIBW24qLi4NSqUT58uU12suXL4/bt2/nuM7p06fx448/4vLly3nax/z58zF79mytchGVBhkZSgQGHsPChWeQdYDcxsYY69Z1YRFERKWG1oXQsmXLcmyfNWsWkpOT3zvQ2yQlJcHf3x/r16+Hra1tntaZMmUKxo8fr36cmJgIhUJRUBGJioWIiDj4+e3VuDVG27ZO2Ly5OypW1N2xdyKiok5nd5/v168f3N3dsXjx4jyvY2trC7lcjtjYWI322NhY2NvbZ+t/9+5dREdHo0uXLuo2lerNZf719fURERGBKlWqaKxjZGQEIyMjbZ4KUYklhMC6deEYNy4UqamZAAADAz3MndsOEyZ4aNxFnoioNNBZIRQWFgZjY+2uLWJoaAg3NzccPXpUfQq8SqXC0aNHMWrUqGz9a9asiWvXrmm0TZ8+HUlJSVixYgVHeoje4dKlGAwbdlD9uEaNsti2rSdcXR0kTEVEJB2tC6EePXpoPBZC4MmTJ7hw4QJmzJihdYDx48cjICAAjRs3hru7O5YvX46UlBQMHDgQANC/f384Ojpi/vz5MDY2Rt26dTXWt7a2BoBs7USUnaurA8aPb4alS//A8OGNsXhxB5iaGrx7RSKiEkrrQsjKykrjsZ6eHmrUqIGvvvoKHTp00DqAr68vnj17hsDAQMTExKBhw4YICQlRT6C+f/8+9PTyfZY/UamWnp4JQ0O5xpme8+a1R8eOVfHBB1XesiYRUemg1QUVlUolzpw5g3r16sHGxqYgcxUYXlCRSotr12Lh57cXw4c3xogRTaSOQ0T0XorEBRXlcjk6dOjAu8wTFWEqlcCKFX+gSZP1uH79KSZM+BU3bz6TOhYRUZGk9aGxunXrIioqCs7OzgWRh4jew5MnSRg4cD9CQ++q26pVK/OWNYiISjetJ9/MmTMHEydOxIEDB/DkyRMkJiZq/BCRNPbvv4369ddoFEHjxjXD+fNDULt2OQmTEREVXXkeEfrqq68wYcIEdOrUCQDQtWtXjQmYWTdlVCqVuW2CiApASkoGJkz4FWvXhqvbHBzMERTkgw4dOCGaiOht8lwIzZ49G8OGDcOxY8cKMg8RaSEy8jm6dPkfIiOfq9t8fGpi/fousLU1lTAZEVHxkOdCKOvkMk9PzwILQ0TaKV/eDBkZb0ZhTU0NsGJFRwwa1Ih3iyciyiOt5gjxH1eiosXKyhg//dQdTZs64tKloRg82JWfUyIiLWh11lj16tXf+Y/sixcv3isQEeVu164baNasIhSKfy5s2qJFJYSFDWIBRESUD1oVQrNnz852ZWkiKniJiekYM+YwNm26gjZtnHDkiD/k8n8GdFkEERHlj1aFUJ8+fWBnZ1dQWYgoB2FhD9Cv3z5ERcUDAI4fj8aBA5Ho1q2mxMmIiIq/PM8R4l+cRIUrM1OF2bOPo1WrjeoiyMLCEJs3+6Br1xoSpyMiKhm0PmuMiApeVFQ8+vXbi7Cwh+o2Dw8FfvqpO5ydi+d9/oiIiqI8F0IqlaogcxAR3vzBsWXLVYwadQhJSRkAALlchsBAT0yd2gr6+lpfDJ6IiN5C63uNEVHBuXDhMQICflY/dnGxwdatPdCsWUXpQhERlWD885KoCGnSxBFDh7oBAAYMaIjLl4eyCCIiKkAcESKS0OvXSujr62mcjLBkSQd06lSNE6KJiAoBR4SIJBIREYdmzX7Epk1XNNrNzAxZBBERFRIWQkSFTAiBtWsvoFGjtbh48QlGjz6MO3d4RXYiIinw0BhRIXr2LAWDB/+C4OAIdZujowVSU19LmIqIqPRiIURUSEJD72DAgP2IiUlWtw0b5oYlS7xhamogYTIiotKLhRBRAUtLy8SUKUewfPk5dZutrSk2bOiKLl04F4iISEoshIgK0J07L9Cjxw5cu/ZU3daxY1Vs3NgN9vbmEiYjIiKAhRBRgbKxMcbz56kAACMjORYt+gCjRrnz3n1EREUEzxojKkBly5oiKKgbGjQojwsXPsPo0U1ZBBERFSEcESLSoV9+iUCTJo4ah70++KAKwsOdIZfz7w4ioqKG/zIT6UBKSgaGDTuArl2349NP90MIobGcRRARUdHEf52J3lN4+GO4uq7D2rXhAIDDh+/gwIFIiVMREVFesBAiyielUoUFC06jWbMfERn5HABgamqA9eu74KOPqkucjoiI8oJzhIjy4cGDBPj778OJE3+r29zcHLBtW09Ur15WwmRERKQNFkJEWtqx4zqGDTuIly/TAAAyGTB5ckvMmtUGhoZyidMREZE2WAgRaeGPPx6iT5896scKhSW2bOkOT08n6UIREVG+cY4QkRaaNasIf//6AABf3zq4cmUYiyAiomKMI0JEb6FSCejpaV4A8bvvOqFz52ro3bsOL45IRFTMcUSIKBdRUfFo2XIDdu68odFuaWkEX9+6LIKIiEoAjggR/YcQAlu2XMWoUYeQlJSBW7cOoHnzilAorKSORkREOsYRIaJ/iY9PRZ8+exAQ8DOSkjIAAGXKmKhvnEpERCULR4SI/t/x49Hw99+Hhw8T1W0DBjTEypUdYWFhJGEyIiIqKCyEqNTLyFAiMPAYFi48g6xbhFlbG2Pduo/Qq1cdacMREVGBYiFEpVpUVDx69dqFixefqNvatHHC5s0+nBNERFQKcI4QlWomJvq4fz8BAGBgoIeFC71w9Gh/FkFERKUECyEq1RwcLPDjj11Rs6Yt/vhjMCZNapHtukFERFRy8dAYlSpHjkShUSN7lC1rqm7r2rUGPvywKgwMeJ8wIqLShiNCVCqkpWVi3LgQfPDBFgwdegAia1b0/2MRRERUOrEQohLv2rVYuLuvx/Ll5wAAe/bcQkjIHYlTERFRUcBCiEoslUpgxYo/0KTJely79hQAYGQkx8qVHdGxY1WJ0xERUVHAOUJUIj15koSBA/cjNPSuuq1ePTts29YTdevaSZiMiIiKEhZCVOIEB0dg0KBgxMW9UreNG9cM8+a1h7Exf+WJiOgf/FagEuXMmfvo1m27+rG9vTk2bfJBhw5VJExFRERFFecIUYni4aFA9+41AQDdutXAtWvDWQQREVGuOCJExZoQAjLZPxdAlMlkWL++C7p2rYGAgAYay4iIiP6LI0JUbD14kIB27TbjwIFIjfayZU0xYEBDFkFERPROHBGiYmnnzhsYOvQAXr5Mw40bT3H16nDY25tLHYuIiIoZjghRsZKYmI4BA36Gr+9uvHyZBgAwNtbH48dJEicjIqLiiCNCVGyEhT1A3757ce/eS3Wbr28drF7dGTY2JtIFIyKiYouFEBV5mZkqzJlzEnPmnIRS+eYeYRYWhli1qhP69avPuUBERJRvLISoSIuOfgk/vz0IC3uobvPwUOCnn7rD2dlGwmRERFQScI4QFWl6ejLcvPkMACCXyzB7dhucODGARRAREekECyEq0ipVssKaNR/BxcUGp09/isBAT+jr89eWiIh0g98oVKScOvU3EhPTNdr69KmLGzdGoFmzihKlIiKikqpIFEKrVq2Ck5MTjI2N0bRpU5w/fz7XvuvXr0erVq1gY2MDGxsbeHl5vbU/FQ8ZGUpMnnwEnp5BGD36cLblvFkqEREVBMkLoR07dmD8+PGYOXMmLl68iAYNGsDb2xtPnz7Nsf/x48fxySef4NixYwgLC4NCoUCHDh3w6NGjQk5OuhIREYfmzX/EggVnIASwefMV/PrrXaljERFRKSATQggpAzRt2hRNmjTBd999BwBQqVRQKBQYPXo0Jk+e/M71lUolbGxs8N1336F///7v7J+YmAgrKyskLHOA5djH752f8k8IgXXrwjFuXChSUzMBAAYGepg7tx0mTPCAnh5PiyciojfU398JCbC0tNTZdiU93pCRkYHw8HBMmTJF3aanpwcvLy+EhYXlaRuvXr3C69evUaZMmRyXp6enIz39nzkniYmJ7xeadOLZsxQMHvwLgoMj1G01apTFtm094erqIGEyIiIqTSQ9NBYXFwelUony5ctrtJcvXx4xMTF52saXX36JChUqwMvLK8fl8+fPh5WVlfpHoVC8d256P6Ghd1C//hqNImj48Ma4eHEoiyAiIipUks8Reh/ffPMNtm/fjn379sHY2DjHPlOmTEFCQoL658GDB4Wckv7t1Km/0bHjVsTEJAMAbG1NERzcB99/3xmmpgYSpyMiotJG0kNjtra2kMvliI2N1WiPjY2Fvb39W9ddvHgxvvnmGxw5cgT169fPtZ+RkRGMjIx0kpfeX8uWldCxY1WEhNxBx45VsXFjN941noiIJCPpiJChoSHc3Nxw9OhRdZtKpcLRo0fRvHnzXNdbuHAhvv76a4SEhKBx48aFEZV0RCaTYePGbvj++044dMiPRRAREUlK8kNj48ePx/r167Fp0ybcunULw4cPR0pKCgYOHAgA6N+/v8Zk6gULFmDGjBnYsGEDnJycEBMTg5iYGCQnJ0v1FCgXMTHJ6Nx5G44ejdJot7c3x/DhTXizVCIikpzkV6nz9fXFs2fPEBgYiJiYGDRs2BAhISHqCdT379+Hnt4/9drq1auRkZGBjz/+WGM7M2fOxKxZswozOr1FcHAEBg0KRlzcK1y5EoMrV4ahbFlTqWMRERFpkPw6QoWN1xEqWCkpGZgw4VesXRuubnNwMMcvv3wCN7cKEiYjIqLirEReR4hKlvDwx+jbdy8iIp6r23x8amL9+i6wteVoEBERFT0shOi9KZUqLF58FtOnH0NmpgoAYGpqgBUrOmLQoEacC0REREUWCyF6Lw8fJsLffx+OH49Wt7m5OWDbtp6oXr2sdMGIiIjyQPKzxqh4S019jT//fHPDW5kMmDKlJc6eHcQiiIiIigUWQvReqlUri5UrP4RCYYljxwIwb157GBrKpY5FRESUJyyESCvnzz/Cq1evNdoGDmyImzdHwtPTSZpQRERE+cRCiPIkM1OF2bOPw8PjR0yc+KvGMplMBnNzQ4mSERER5R8LIXqnqKh4tG69EbNmnYBSKbB69QUcO3ZP6lhERETvjWeNUa6EENiy5SpGjTqEpKQMAIBcLkNgoCdataoscToiIqL3x0KIchQfn4rhww9ix44b6jYXFxts3doDzZpVlDAZERGR7rAQomxOnIiGv/8+PHiQqG4bMKAhVq7sCAsLIwmTERER6RYLIdJw4kQ02rbdhKw70NnYGGPt2o/Qq1cdaYMREREVAE6WJg0tW1ZC69Zv5v+0beuEq1eHswgiIqISiyNCpEEu18OWLd2xa9dNjB3bDHp6vE8YERGVXBwRKsWePUtBz547cebMfY12hcIK48c3ZxFEREQlHkeESqnQ0DsYMGA/YmKScfHiE1y5MgyWlpwITUREpQtHhEqZtLRMjB0bgo4dtyImJhkAkJycgcjI5xInIyIiKnwcESpFrl2LhZ/fXly//lTd1rFjVWzc2A329uYSJiMiIpIGC6FSQKUS+Pbbc/jyyyNIT1cCAIyM5Fi06AOMGuUOmYxzgYiIqHRiIVTCPXmShIED9yM09K66rV49O2zb1hN169pJmIyIiEh6nCNUwr14kYrjx6PVj8eNa4bz54ewCCIiIgILoRKvTh07LFr0AeztzREa2g9Ll3rD2JgDgURERAALoRLnypUYpKdnarSNGuWOmzdHoEOHKhKlIiIiKppYCJUQSqUKCxacRuPG6zFt2u8ay2QyGWxsTCRKRkREVHSxECoBHjxIQPv2mzF58lFkZqqwZEkYTp++/+4ViYiISjlOFinmdu68gaFDD+DlyzQAgEwGTJ7cEu7ujhInIyIiKvpYCBVTiYnpGDPmMDZtuqJuUygssWVLd3h6OkkXjIiIqBhhIVQMhYU9QL9++xAVFa9u8/Wtg9WrO3MuEBERkRZYCBUzx49Hw8trM5RKAQCwsDDEqlWd0K9ffV4hmoiISEucLF3MtGihgJtbBQCAh4cCV64Mg79/AxZBRERE+cARoWLGwECOrVt7YMeO6/jyy5bQ12ctS0RElF8shIqw+PhUjBp1GOPHN1OPAgFA1aplMG1aawmTEZUuQghkZmZCqVRKHYWoRDMwMIBcLi/UfbIQKqKOH4+Gv/8+PHyYiPDwx7h4cShMTQ2kjkVU6mRkZODJkyd49eqV1FGISjyZTIaKFSvC3Ny80PbJQqiIychQIjDwGBYuPAPxZj40nj5NwY0bT9GkCa8NRFSYVCoV7t27B7lcjgoVKsDQ0JDz8YgKiBACz549w8OHD1GtWrVCGxliIVSERETEwc9vLy5efKJua9vWCZs3d0fFipYSJiMqnTIyMqBSqaBQKGBqaip1HKISr1y5coiOjsbr169ZCJUmQgisWxeOceNCkZr65oapBgZ6mDu3HSZM8ICeHv8CJZKSnh5PSiAqDFKMuLIQktizZykYPPgXBAdHqNtq1CiLbdt6wtXVQcJkREREJR8LIYk9eJCIQ4f+Uj8ePrwxFi/uwInRREREhYDjvRJzdXXAnDltYWtriuDgPvj++84sgoiIJBQREQF7e3skJSVJHaVEycjIgJOTEy5cuCB1FA0shArZ7dtxeP1a81okEyd64MaNEejSpYZEqYiopBkwYABkMhlkMhkMDAzg7OyML774Amlpadn6HjhwAJ6enrCwsICpqSmaNGmCoKCgHLe7Z88etGnTBlZWVjA3N0f9+vXx1Vdf4cWLFwX8jArPlClTMHr0aFhYWEgdpUCcPHkSXbp0QYUKFSCTyfDzzz/nab3jx4/D1dUVRkZGqFq1ao6/I6tWrYKTkxOMjY3RtGlTnD9/Xr3M0NAQEydOxJdffqmjZ6IbLIQKiUolsGLFH2jYcA3mzDmpsUwu14OdnZlEyYiopOrYsSOePHmCqKgoLFu2DGvXrsXMmTM1+nz77bfo1q0bWrRogXPnzuHq1avo06cPhg0bhokTJ2r0nTZtGnx9fdGkSRMcPnwY169fx5IlS3DlyhVs2bKl0J5XRkZGgW37/v37OHDgAAYMGPBe2ynIjO8rJSUFDRo0wKpVq/K8zr1799C5c2e0bdsWly9fxtixYzF48GCEhoaq++zYsQPjx4/HzJkzcfHiRTRo0ADe3t54+vSpuk/fvn1x+vRp3LhxQ6fP6b2IUiYhIUEAEAnLHAptn48fJwpv7y0CmCWAWUJPb7Y4d+5hoe2fiPInNTVV3Lx5U6SmpkodRWsBAQGiW7duGm09evQQjRo1Uj++f/++MDAwEOPHj8+2/sqVKwUA8ccffwghhDh37pwAIJYvX57j/uLj43PN8uDBA9GnTx9hY2MjTE1NhZubm3q7OeX8/PPPhaenp/qxp6enGDlypPj8889F2bJlRZs2bcQnn3wievfurbFeRkaGKFu2rNi0aZMQQgilUinmzZsnnJychLGxsahfv77YtWtXrjmFEGLRokWicePGGm1xcXGiT58+okKFCsLExETUrVtXbNu2TaNPThmFEOLatWuiY8eOwszMTNjZ2Yl+/fqJZ8+eqdc7fPiwaNGihbCyshJlypQRnTt3Fnfu3HlrRl0CIPbt2/fOfl988YWoU6eORpuvr6/w9vZWP3Z3dxcjR45UP1YqlaJChQpi/vz5Guu1bdtWTJ8+Pcf9vO0zp/7+Tkh4Z15tcLJ0Adu//zYGD/4FcXH/XJV2zBh31K9fXsJURPRefmoMpMQU/n7N7IF++Ztfcf36dZw9exaVK1dWt+3evRuvX7/ONvIDAEOHDsXUqVPxv//9D02bNsXWrVthbm6OESNG5Lh9a2vrHNuTk5Ph6ekJR0dHBAcHw97eHhcvXoRKpdIq/6ZNmzB8+HCcOXMGAHDnzh306tULycnJ6qsQh4aG4tWrV+jevTsAYP78+fjpp5+wZs0aVKtWDSdPnkS/fv1Qrlw5eHp65rifU6dOoXHjxhptaWlpcHNzw5dffglLS0scPHgQ/v7+qFKlCtzd3XPN+PLlS7Rr1w6DBw/GsmXLkJqaii+//BK9e/fG77//DuDN6Mz48eNRv359JCcnIzAwEN27d8fly5dzvWzDvHnzMG/evLe+Xjdv3kSlSpXe9bLmWVhYGLy8vDTavL29MXbsWABvRsDCw8MxZcoU9XI9PT14eXkhLCxMYz13d3ecOnVKZ9neFwuhApKSkoEJE37F2rXh6jZ7e3Ns2uSDDh2qSJiMiN5bSgyQ/EjqFO904MABmJubIzMzE+np6dDT08N3332nXh4ZGQkrKys4OGS/VIehoSFcXFwQGRkJAPjrr7/g4uICAwPtTubYtm0bnj17hj///BNlypQBAFStWlXr51KtWjUsXLhQ/bhKlSowMzPDvn374O/vr95X165dYWFhgfT0dMybNw9HjhxB8+bNAQAuLi44ffo01q5dm2sh9Pfff2crhBwdHTWKxdGjRyM0NBQ7d+7UKIT+m3HOnDlo1KiRRtGyYcMGKBQKREZGonr16ujZs6fGvjZs2IBy5crh5s2bqFu3bo4Zhw0bht69e7/19apQocJbl2srJiYG5ctr/gFfvnx5JCYmIjU1FfHx8VAqlTn2uX37drZsf//9t07zvQ8WQgUgPPwx/Pz2IjLyubqtW7ca+OGHrrC15dVpiYo9M/tisd+2bdti9erVSElJwbJly6Cvr5/tizevRNY9f7R0+fJlNGrUSF0E5Zebm5vGY319ffTu3Rtbt26Fv78/UlJSsH//fmzfvh3AmxGjV69e4YMPPtBYLyMjA40aNcp1P6mpqTA2NtZoUyqVmDdvHnbu3IlHjx4hIyMD6enp2a42/t+MV65cwbFjx3K8b9bdu3dRvXp1/PXXXwgMDMS5c+cQFxenHim7f/9+roVQmTJl3vv1lJKJiUmRuncfCyEd+/33e/D2/gmZmW9+mU1NDbB8uTcGD3blPYqISop8Hp4qbGZmZurRlw0bNqBBgwb48ccfMWjQIABA9erVkZCQgMePH2cbQcjIyMDdu3fRtm1bdd/Tp0/j9evXWo0KmZiYvHW5np5etiLr9evXOT6X/+rbty88PT3x9OlT/PbbbzAxMUHHjh0BvDkkBwAHDx6Eo6PmfRqNjIxyzWNra4v4+HiNtkWLFmHFihVYvnw56tWrBzMzM4wdOzbbhOj/ZkxOTkaXLl2wYMGCbPvJGoXr0qULKleujPXr16NChQpQqVSoW7fuWydbS3FozN7eHrGxsRptsbGxsLS0hImJCeRyOeRyeY597O01C/gXL16gXLlyOsv2vnjWmI61aKFA7dpv3mA3NwdcujQUQ4a4sQgiIknp6elh6tSpmD59OlJTUwEAPXv2hIGBAZYsWZKt/5o1a5CSkoJPPvkEAODn54fk5GR8//33OW7/5cuXObbXr18fly9fzvX0+nLlyuHJkycabZcvX87Tc/Lw8IBCocCOHTuwdetW9OrVS12k1a5dG0ZGRrh//z6qVq2q8aNQKHLdZqNGjXDz5k2NtjNnzqBbt27o168fGjRooHHI8G1cXV1x48YNODk5ZctgZmaG58+fIyIiAtOnT0f79u1Rq1atbEVYToYNG4bLly+/9UfXh8aaN2+Oo0eParT99ttv6sOOhoaGcHNz0+ijUqlw9OhRdZ8s169ff+uoXKHT6dTrYqAwzhq7fj1WTJt2VKSnZxbYPoio4JW0s8Zev34tHB0dxaJFi9Rty5YtE3p6emLq1Kni1q1b4s6dO2LJkiXCyMhITJgwQWP9L774QsjlcjFp0iRx9uxZER0dLY4cOSI+/vjjXM8mS09PF9WrVxetWrUSp0+fFnfv3hW7d+8WZ8+eFUIIERISImQymdi0aZOIjIwUgYGBwtLSMttZY59//nmO2582bZqoXbu20NfXF6dOncq2rGzZsiIoKEjcuXNHhIeHi5UrV4qgoKBcX7fg4GBhZ2cnMjP/+fd73LhxQqFQiDNnzoibN2+KwYMHC0tLS43XN6eMjx49EuXKlRMff/yxOH/+vLhz544ICQkRAwYMEJmZmUKpVIqyZcuKfv36ib/++kscPXpUNGnSJM9ncuVXUlKSuHTpkrh06ZIAIJYuXSouXbok/v77b3WfyZMnC39/f/XjqKgoYWpqKiZNmiRu3bolVq1aJeRyuQgJCVH32b59uzAyMhJBQUHi5s2b4rPPPhPW1tYiJiZGY/+VK1cWmzdvzjGbFGeNsRB6r22licGD94vr12N1kIyIipqSVggJIcT8+fNFuXLlRHJysrpt//79olWrVsLMzEwYGxsLNzc3sWHDhhy3u2PHDtG6dWthYWEhzMzMRP369cVXX3311tPno6OjRc+ePYWlpaUwNTUVjRs3FufOnVMvDwwMFOXLlxdWVlZi3LhxYtSoUXkuhG7evCkAiMqVKwuVSqWxTKVSieXLl4saNWoIAwMDUa5cOeHt7S1OnDiRa9bXr1+LChUqaHzBP3/+XHTr1k2Ym5sLOzs7MX36dNG/f/93FkJCCBEZGSm6d+8urK2thYmJiahZs6YYO3asOutvv/0matWqJYyMjET9+vXF8ePHC7wQOnbsmACQ7ScgIEDdJyAgQOM9yFqvYcOGwtDQULi4uIiNGzdm2/a3334rKlWqJAwNDYW7u7v6MglZzp49K6ytrcWrV69yzCZFISQTIp8z4IqpxMREWFlZIWGZAyzHPs73dsLCHqBfv32IiopH/frlcf78YBgZccoVUUmSlpaGe/fuwdnZOdsEWiq5Vq1aheDgYI2LBZJu+Pr6okGDBpg6dWqOy9/2mVN/fyckwNLSUmeZOEdIS5mZKsyefRytWm1EVNSbY7n37sXj6tXYd6xJRETFwdChQ9G6dWvea0zHMjIyUK9ePYwbN07qKBo4hKGFqKh49Ou3F2FhD9VtHh4K/PRTdzg720iYjIiIdEVfXx/Tpk2TOkaJY2hoiOnTp0sdIxsWQnkghMCWLVcxatQhJCW9OaVRLpchMNATU6e2gr4+B9aIiIiKIxZC7xAfn4rhww9ix45/bhDn4mKDrVt7oFmzihImIyIiovfFQugdbt2Kw65d/1xTYsCAhli5siMsLHK/IBcRlSyl7JwSIslI8VnjMZ138PBQYNq0VrC2NsbOnR9j48ZuLIKISomsi/MVpdsBEJVkWVfUlsvlhbZPjgj9x7178ahUyQpy+T814owZrTF0qBscHXV3uh4RFX1yuRzW1tZ4+vQpAMDU1JRXiScqICqVCs+ePYOpqSn09QuvPGEh9P+EEFi3LhzjxoVi5kxPfPllS/UyAwM5iyCiUirrPklZxRARFRw9PT1UqlSpUP/gYCEE4NmzFAwe/AuCgyMAANOnH0OHDlXQqJGDxMmISGoymQwODg6ws7PL8WagRKQ7hoaG0NMr3Fk7RaIQWrVqFRYtWoSYmBg0aNAA3377Ldzd3XPtv2vXLsyYMQPR0dGoVq0aFixYgE6dOuVr36GhdzBgwH7ExCSr2wYPboQaNWzztT0iKpmy7q5NRCWL5JOld+zYgfHjx2PmzJm4ePEiGjRoAG9v71yHoc+ePYtPPvkEgwYNwqVLl+Dj4wMfHx9cv35dq/2mvZZj7NgQdOy4VV0E2dqaIji4D1av/gimpgbv/dyIiIioaJP8XmNNmzZFkyZN8N133wF4M1lKoVBg9OjRmDx5crb+vr6+SElJwYEDB9RtzZo1Q8OGDbFmzZp37i/rXiW17IfiVsw/h746dqyKjRu7wd7eXAfPioiIiHSpRN5rLCMjA+Hh4fDy8lK36enpwcvLC2FhYTmuExYWptEfALy9vXPtn5tbMW9uiWFkJMfKlR1x6JAfiyAiIqJSRtI5QnFxcVAqlShfvrxGe/ny5XH79u0c14mJicmxf0xMTI7909PTkZ6ern6ckJCQtQS1a5fDjz92Q+3a5XhzPSIioiIsMTERgO4vulgkJksXpPnz52P27Nk5LFmGmzeB5s0nFHomIiIiyp/nz5/DyspKZ9uTtBCytbWFXC5HbGysRntsbKz62h3/ZW9vr1X/KVOmYPz48erHL1++ROXKlXH//n2dvpCkvcTERCgUCjx48ECnx3spf/h+FB18L4oOvhdFR0JCAipVqoQyZcrodLuSFkKGhoZwc3PD0aNH4ePjA+DNZOmjR49i1KhROa7TvHlzHD16FGPHjlW3/fbbb2jevHmO/Y2MjGBklP2WGFZWVvylLiIsLS35XhQhfD+KDr4XRQffi6JD19cZkvzQ2Pjx4xEQEIDGjRvD3d0dy5cvR0pKCgYOHAgA6N+/PxwdHTF//nwAwOeffw5PT08sWbIEnTt3xvbt23HhwgWsW7dOyqdBRERExZDkhZCvry+ePXuGwMBAxMTEoGHDhggJCVFPiL5//75G9efh4YFt27Zh+vTpmDp1KqpVq4aff/4ZdevWleopEBERUTEleSEEAKNGjcr1UNjx48eztfXq1Qu9evXK176MjIwwc+bMHA+XUeHie1G08P0oOvheFB18L4qOgnovJL+gIhEREZFUJL/FBhEREZFUWAgRERFRqcVCiIiIiEotFkJERERUapXIQmjVqlVwcnKCsbExmjZtivPnz7+1/65du1CzZk0YGxujXr16OHToUCElLfm0eS/Wr1+PVq1awcbGBjY2NvDy8nrne0fa0fazkWX79u2QyWTqC5/S+9P2vXj58iVGjhwJBwcHGBkZoXr16vy3Ske0fS+WL1+OGjVqwMTEBAqFAuPGjUNaWlohpS25Tp48iS5duqBChQqQyWT4+eef37nO8ePH4erqCiMjI1StWhVBQUHa71iUMNu3bxeGhoZiw4YN4saNG2LIkCHC2tpaxMbG5tj/zJkzQi6Xi4ULF4qbN2+K6dOnCwMDA3Ht2rVCTl7yaPte+Pn5iVWrVolLly6JW7duiQEDBggrKyvx8OHDQk5eMmn7fmS5d++ecHR0FK1atRLdunUrnLAlnLbvRXp6umjcuLHo1KmTOH36tLh37544fvy4uHz5ciEnL3m0fS+2bt0qjIyMxNatW8W9e/dEaGiocHBwEOPGjSvk5CXPoUOHxLRp08TevXsFALFv37639o+KihKmpqZi/Pjx4ubNm+Lbb78VcrlchISEaLXfElcIubu7i5EjR6ofK5VKUaFCBTF//vwc+/fu3Vt07txZo61p06Zi6NChBZqzNND2vfivzMxMYWFhITZt2lRQEUuV/LwfmZmZwsPDQ/zwww8iICCAhZCOaPterF69Wri4uIiMjIzCilhqaPtejBw5UrRr106jbfz48aJFixYFmrO0yUsh9MUXX4g6depotPn6+gpvb2+t9lWiDo1lZGQgPDwcXl5e6jY9PT14eXkhLCwsx3XCwsI0+gOAt7d3rv0pb/LzXvzXq1ev8Pr1a53fYK80yu/78dVXX8HOzg6DBg0qjJilQn7ei+DgYDRv3hwjR45E+fLlUbduXcybNw9KpbKwYpdI+XkvPDw8EB4erj58FhUVhUOHDqFTp06Fkpn+oavv7yJxZWldiYuLg1KpVN+eI0v58uVx+/btHNeJiYnJsX9MTEyB5SwN8vNe/NeXX36JChUqZPtFJ+3l5/04ffo0fvzxR1y+fLkQEpYe+XkvoqKi8Pvvv6Nv3744dOgQ7ty5gxEjRuD169eYOXNmYcQukfLzXvj5+SEuLg4tW7aEEAKZmZkYNmwYpk6dWhiR6V9y+/5OTExEamoqTExM8rSdEjUiRCXHN998g+3bt2Pfvn0wNjaWOk6pk5SUBH9/f6xfvx62trZSxyn1VCoV7OzssG7dOri5ucHX1xfTpk3DmjVrpI5W6hw/fhzz5s3D999/j4sXL2Lv3r04ePAgvv76a6mjUT6VqBEhW1tbyOVyxMbGarTHxsbC3t4+x3Xs7e216k95k5/3IsvixYvxzTff4MiRI6hfv35Bxiw1tH0/7t69i+joaHTp0kXdplKpAAD6+vqIiIhAlSpVCjZ0CZWfz4aDgwMMDAwgl8vVbbVq1UJMTAwyMjJgaGhYoJlLqvy8FzNmzIC/vz8GDx4MAKhXrx5SUlLw2WefYdq0aRo3CaeCldv3t6WlZZ5Hg4ASNiJkaGgINzc3HD16VN2mUqlw9OhRNG/ePMd1mjdvrtEfAH777bdc+1Pe5Oe9AICFCxfi66+/RkhICBo3blwYUUsFbd+PmjVr4tq1a7h8+bL6p2vXrmjbti0uX74MhUJRmPFLlPx8Nlq0aIE7d+6oi1EAiIyMhIODA4ug95Cf9+LVq1fZip2sAlXw1p2FSmff39rN4y76tm/fLoyMjERQUJC4efOm+Oyzz4S1tbWIiYkRQgjh7+8vJk+erO5/5swZoa+vLxYvXixu3bolZs6cydPndUTb9+Kbb74RhoaGYvfu3eLJkyfqn6SkJKmeQomi7fvxXzxrTHe0fS/u378vLCwsxKhRo0RERIQ4cOCAsLOzE3PmzJHqKZQY2r4XM2fOFBYWFuJ///ufiIqKEr/++quoUqWK6N27t1RPocRISkoSly5dEpcuXRIAxNKlS8WlS5fE33//LYQQYvLkycLf31/dP+v0+UmTJolbt26JVatW8fT5LN9++62oVKmSMDQ0FO7u7uKPP/5QL/P09BQBAQEa/Xfu3CmqV68uDA0NRZ06dcTBgwcLOXHJpc17UblyZQEg28/MmTMLP3gJpe1n499YCOmWtu/F2bNnRdOmTYWRkZFwcXERc+fOFZmZmYWcumTS5r14/fq1mDVrlqhSpYowNjYWCoVCjBgxQsTHxxd+8BLm2LFjOX4HZL3+AQEBwtPTM9s6DRs2FIaGhsLFxUVs3LhR6/3KhOBYHhEREZVOJWqOEBEREZE2WAgRERFRqcVCiIiIiEotFkJERERUarEQIiIiolKLhRARERGVWiyEiIiIqNRiIUREGoKCgmBtbS11jHyTyWT4+eef39pnwIAB8PHxKZQ8RFS0sRAiKoEGDBgAmUyW7efOnTtSR0NQUJA6j56eHipWrIiBAwfi6dOnOtn+kydP8OGHHwIAoqOjIZPJcPnyZY0+K1asQFBQkE72l5tZs2apn6dcLodCocBnn32GFy9eaLUdFm1EBatE3X2eiP7RsWNHbNy4UaOtXLlyEqXRZGlpiYiICKhUKly5cgUDBw7E48ePERoa+t7bzu2u4f9mZWX13vvJizp16uDIkSNQKpW4desWPv30UyQkJGDHjh2Fsn8iejeOCBGVUEZGRrC3t9f4kcvlWLp0KerVqwczMzMoFAqMGDECycnJuW7nypUraNu2LSwsLGBpaQk3NzdcuHBBvfz06dNo1aoVTExMoFAoMGbMGKSkpLw1m0wmg729PSpUqIAPP/wQY8aMwZEjR5CamgqVSoWvvvoKFStWhJGRERo2bIiQkBD1uhkZGRg1ahQcHBxgbGyMypUrY/78+Rrbzjo05uzsDABo1KgRZDIZ2rRpA0BzlGXdunWoUKGCxp3dAaBbt2749NNP1Y/3798PV1dXGBsbw8XFBbNnz0ZmZuZbn6e+vj7s7e3h6OgILy8v9OrVC7/99pt6uVKpxKBBg+Ds7AwTExPUqFEDK1asUC+fNWsWNm3ahP3796tHl44fPw4AePDgAXr37g1ra2uUKVMG3bp1Q3R09FvzEFF2LISIShk9PT2sXLkSN27cwKZNm/D777/jiy++yLV/3759UbFiRfz5558IDw/H5MmTYWBgAAC4e/cuOnbsiJ49e+Lq1avYsWMHTp8+jVGjRmmVycTEBCqVCpmZmVixYgWWLFmCxYsX4+rVq/D29kbXrl3x119/AQBWrlyJ4OBg7Ny5ExEREdi6dSucnJxy3O758+cBAEeOHMGTJ0+wd+/ebH169eqF58+f49ixY+q2Fy9eICQkBH379gUAnDp1Cv3798fnn3+OmzdvYu3atQgKCsLcuXPz/Byjo6MRGhoKQ0NDdZtKpULFihWxa9cu3Lx5E4GBgZg6dSp27twJAJg4cSJ69+6Njh074smTJ3jy5Ak8PDzw+vVreHt7w8LCAqdOncKZM2dgbm6Ojh07IiMjI8+ZiAgokXefJyrtAgIChFwuF2ZmZuqfjz/+OMe+u3btEmXLllU/3rhxo7CyslI/trCwEEFBQTmuO2jQIPHZZ59ptJ06dUro6emJ1NTUHNf57/YjIyNF9erVRePGjYUQQlSoUEHMnTtXY50mTZqIESNGCCGEGD16tGjXrp1QqVQ5bh+A2LdvnxBCiHv37gkA4tKlSxp9AgICRLdu3dSPu3XrJj799FP147Vr14oKFSoIpVIphBCiffv2Yt68eRrb2LJli3BwcMgxgxBCzJw5U+jp6QkzMzNhbGysvpP20qVLc11HCCFGjhwpevbsmWvWrH3XqFFD4zVIT08XJiYmIjQ09K3bJyJNnCNEVEK1bdsWq1evVj82MzMD8GZ0ZP78+bh9+zYSExORmZmJtLQ0vHr1Cqamptm2M378eAwePBhbtmxRH96pUqUKgDeHza5evYqtW7eq+wshoFKpcO/ePdSqVSvHbAkJCTA3N4dKpUJaWhpatmyJH374AYmJiXj8+DFatGih0b9Fixa4cuUKgDeHtT744APUqFEDHTt2xEcffYQOHTq812vVt29fDBkyBN9//z2MjIywdetW9OnTB3p6eurneebMGY0RIKVS+dbXDQBq1KiB4OBgpKWl4aeffsLly5cxevRojT6rVq3Chg0bcP/+faSmpiIjIwMNGzZ8a94rV67gzp07sLCw0GhPS0vD3bt38/EKEJVeLISISigzMzNUrVpVoy06OhofffQRhg8fjrlz56JMmTI4ffo0Bg0ahIyMjBy/0GfNmgU/Pz8cPHgQhw8fxsyZM7F9+3Z0794dycnJGDp0KMaMGZNtvUqVKuWazcLCAhcvXoSenh4cHBxgYmICAEhMTHzn83J1dcW9e/dw+PBhHDlyBL1794aXlxd27979znVz06VLFwghcPDgQTRp0gSnTp3CsmXL1MuTk5Mxe/Zs9OjRI9u6xsbGuW7X0NBQ/R5888036Ny5M2bPno2vv/4aALB9+3ZMnDgRS5YsQfPmzWFhYYFFixbh3Llzb82bnJwMNzc3jQI0S1GZEE9UXLAQIipFwsPDoVKpsGTJEvVoR9Z8lLepXr06qlevjnHjxuGTTz7Bxo0b0b17d7i6uuLmzZvZCq530dPTy3EdS0tLVKhQAWfOnIGnp6e6/cyZM3B3d9fo5+vrC19fX3z88cfo2LEjXrx4gTJlymhsL2s+jlKpfGseY2Nj9OjRA1u3bsWdO3dQo0YNuLq6qpe7uroiIiJC6+f5X9OnT0e7du0wfPhw9fP08PDAiBEj1H3+O6JjaGiYLb+rqyt27NgBOzs7WFpavlcmotKOk6WJSpGqVavi9evX+PbbbxEVFYUtW7ZgzZo1ufZPTU3FqFGjcPz4cfz99984c+YM/vzzT/Uhry+//BJnz57FqFGjcPnyZfz111/Yv3+/1pOl/23SpElYsGABduzYgYiICEyePBmXL1/G559/DgBYunQp/ve//+H27duIjIzErl27YG9vn+NFIO3s7GBiYoKQkBDExsYiISEh1/327dsXBw8exIYNG9STpLMEBgZi8+bNmD17Nm7cuIFbt25h+/btmD59ulbPrXnz5qhfvz7mzZsHAKhWrRouXLiA0NBQREZGYsaMGfjzzz811nFycsLVq1cRERGBuLg4vH79Gn379oWtrS26deuGU6dO4d69ezh+/DjGjBmDhw8fapWJqNSTepISEeleThNssyxdulQ4ODgIExMT4e3tLTZv3iwAiPj4eCGE5mTm9PR00adPH6FQKIShoaGoUKGCGDVqlMZE6PPnz4sPPvhAmJubCzMzM1G/fv1sk53/7b+Tpf9LqVSKWbNmCUdHR2FgYCAaNGggDh8+rF6+bt060bBhQ2FmZiYsLS1F+/btxcWLF9XL8a/J0kIIsX79eqFQKISenp7w9PTM9fVRKpXCwcFBABB3797NliskJER4eHgIExMTYWlpKdzd3cW6detyfR4zZ84UDRo0yNb+v//9TxgZGYn79++LtLQ0MWDAAGFlZSWsra3F8OHDxeTJkzXWe/r0qfr1BSCOHTsmhBDiyZMnon///sLW1lYYGRkJFxcXMWTIEJGQkJBrJiLKTiaEENKWYkRERETS4KExIiIiKrVYCBEREVGpxUKIiIiISi0WQkRERFRqsRAiIiKiUouFEBEREZVaLISIiIio1GIhRERERKUWCyEiIiIqtVgIERERUanFQoiIiIhKLRZCREREVGr9H828XHG3V9GpAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ce8ca-10d4-4899-bb18-559edebe45c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa0fec-5ed0-44a8-bce7-4d6b0b139467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a534861-e555-4a08-9b66-ef9a7bb76362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_metric(measure_name_1, measure_name_2, plot_title):\n",
    "  \n",
    " \n",
    "  measure_value_1 = model_training_history.history[measure_name_1]\n",
    "  measure_value_2 = model_training_history.history[measure_name_2] \n",
    "  epochs = range(len(measure_value_1))\n",
    "\n",
    "  plt.plot(epochs, measure_value_1, 'blue', label = measure_name_1)\n",
    "  plt.plot(epochs, measure_value_2, 'red', label = measure_name_2)   \n",
    "\n",
    "  plt.title(str(plot_title))\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0ed272e-7af6-4ff1-8df1-b92c6139334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('loss', 'val_loss', 'Total Training Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8d88c8b-177e-4fab-a3f7-0be5ae9915dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9deef-e07c-486b-86b1-ba3e8f1124b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1c225-6070-4719-a440-3804bf2069d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7679e01-65a0-4e65-9752-3e07a5644de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e0fed-d033-4bc1-b123-7b7ba1ab0c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc950c7-e9b5-4a47-8f51-fcc3dec0e350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81879f5c-cb19-4be1-bebb-776859eae031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a093cf6-9133-486a-9052-f83cf2800011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62594a8d-640c-4e38-82ae-516522137f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894cfcb-d034-4c97-a4db-7f4f74779a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016f105-c131-49f8-8f7d-4590472b37a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182ae4c-c033-4475-b39d-e4408f440a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7181d-172e-41fc-8b22-7d217135ed30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d13c1b-3795-4c8c-98ac-6eb0b0b42292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccfc07-5b38-4922-9c71-c67a80e0118c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08245b91-c4bf-4d47-bf13-a4c610bcd48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002e0ce-833b-4d84-89fc-62e3f15db34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
