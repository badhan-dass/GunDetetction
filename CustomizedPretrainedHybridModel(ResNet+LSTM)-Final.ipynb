{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79628168-369c-462f-a874-ef1b3e1e7080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 18:41:33.470463: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 18:41:33.483710: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 18:41:33.487791: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 18:41:33.497322: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 18:41:34.083505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import *\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Input, RepeatVector, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam, Adam\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe7e8fd-b73e-457d-bc9f-5d3d6e010c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3cd6a4-a4a6-4a78-8b5e-0d0b40abd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 23\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69eee8d-a3d1-4bd6-b403-c410182a9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  \"Gun_NoGun_Dataset_augmented/\"\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH= 224,224\n",
    "\n",
    "SEQUENCE_LENGTH =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1901d2-fa71-4604-8fea-d17930c83387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_categories_list = [\"Gun\", \"NoGun\"]\n",
    "model_output_length = len(class_categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8d0353-8edc-48de-baf1-7da24a58a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pixel_value = 255\n",
    "def extract_frame(video_path):\n",
    "  # frames_list = []\n",
    "\n",
    "  # #print(\" the video file path is : {}\".format(video_path))\n",
    "  # videoObj = cv2.VideoCapture(video_path)\n",
    "  # #print(\"the video object is: {}\".format(videoObj))\n",
    "\n",
    "  # \"\"\" Iterating through Video Frames \"\"\"\n",
    "  # while True:\n",
    "\n",
    "  #   # Reading a frame from the video file\n",
    "  #   success, image = videoObj.read()\n",
    "  #   #print(\"the value of success is: {}\".format(success))\n",
    "\n",
    "  #   if not success:\n",
    "  #     break\n",
    "\n",
    "  #   resized_frame = cv2.resize(image, (image_height, image_width))\n",
    "\n",
    "  #   \"\"\"Normalize the resized frame by dividing it with 255 so that \n",
    "  #   each pixel value then lies between 0 and 1\"\"\"\n",
    "\n",
    "  #   normalized_frame = resized_frame / max_pixel_value\n",
    "  #   frames_list.append(normalized_frame)\n",
    "\n",
    "    \n",
    "  # videoObj.release()\n",
    "\n",
    "\n",
    "    frames_list = []\n",
    "    \n",
    "    # Read the Video File\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the total number of frames in the video.\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the the interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    "    \n",
    "    # Iterate through the Video Frames.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "    \n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "    \n",
    "        # Reading the frame from the video. \n",
    "        success, frame = video_reader.read() \n",
    "    \n",
    "        if not success:\n",
    "            break\n",
    "    \n",
    "        # Resize the Frame to fixed height and width.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Normalize the resized frame\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Append the normalized frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    \n",
    "    video_reader.release()\n",
    "\n",
    "\n",
    "    return frames_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943a452f-3497-4bdb-8c45-51d27da91e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_creation():\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "    \n",
    "    # Iterating through all the classes.\n",
    "    for class_index, class_name in enumerate(class_categories_list):\n",
    "        \n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Get the list of video files present in the specific class name directory.\n",
    "        files_list = os.listdir(os.path.join(data_dir, class_name))\n",
    "        \n",
    "        # Iterate through all the files present in the files list.\n",
    "        for file_name in files_list:\n",
    "            \n",
    "            # Get the complete video path.\n",
    "            video_file_path = os.path.join(data_dir, class_name, file_name)\n",
    " \n",
    "            # Extract the frames of the video file.\n",
    "            frames = extract_frame(video_file_path)\n",
    " \n",
    "            # Check if the extracted frames are equal to the SEQUENCE_LENGTH specified.\n",
    "            # So ignore the videos having frames less than the SEQUENCE_LENGTH.\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    " \n",
    "                # Append the data to their repective lists.\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    " \n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8318f13-5f00-4ccf-bfde-5f469c9c19eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: Gun\n",
      "Extracting Data of Class: NoGun\n"
     ]
    }
   ],
   "source": [
    "features, labels = data_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e29e94-5e4b-466c-87c4-710328f43f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the feature = (516, 30, 224, 224, 3)\n",
      "the shape of the labels = (516,)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the feature = {}\".format(features.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a591ab-de67-4797-bdf8-8e35f8d138a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27ff7c15-6485-437f-9c2e-a556d7ac3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, \n",
    "                                                                            test_size = 0.2, \n",
    "                                                                            shuffle = True, \n",
    "                                                                            random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3bc01e-72fb-4b03-a98d-542d51bd7979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the feature = (412, 30, 224, 224, 3)\n",
      "the shape of the labels = (412, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the feature = {}\".format(features_train.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8935243-0edb-4d1a-a2fc-a5beeb6933b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the feature = (104, 30, 224, 224, 3)\n",
      "the shape of the labels = (104, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the feature = {}\".format(features_test.shape))\n",
    "print(\"the shape of the labels = {}\".format(labels_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab9657e-4d72-4f4f-bd0d-7a70b8e3c12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725921831.196496 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.197555 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.213335 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.214487 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.215497 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.216497 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.412582 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.413683 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.414707 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.415734 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.416713 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.417717 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.427070 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.428121 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.429119 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.430134 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725921831.431139 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-09 18:43:51.432132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46385 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1725921831.432862 2752358 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-09 18:43:51.433848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46764 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:4d:00.0, compute capability: 8.6\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1_pad           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │ conv1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1_pad           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1_pool          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pool1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block1_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ conv2_block1_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block1_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_0_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block1_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_0_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ conv2_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block2_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ conv2_block2_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block2_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block2_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ conv2_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block3_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │ conv2_block3_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2_block3_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block3_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ conv2_block3_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ conv2_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │ conv3_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block1_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block1_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block1_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_0_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ conv3_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block1_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_0_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv3_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ conv3_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block2_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block2_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block2_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block2_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv3_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ conv3_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block3_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block3_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block3_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block3_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv3_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ conv3_block4_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block4_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> │ conv3_block4_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv3_block4_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block4_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv3_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ conv3_block4_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ conv3_block4_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv3_block4_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │ conv4_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block1_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block1_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block1_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_0_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ conv4_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block1_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_0_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block2_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block2_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block2_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block2_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block3_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block3_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block3_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block3_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block4_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block4_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block4_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block4_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block4_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block4_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block4_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block5_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block5_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block5_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block5_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block5_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block4_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block5_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block5_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block6_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block6_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block6_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block6_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block6_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block5_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block6_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block6_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block7_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block7_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block7_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block7_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block7_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block6_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block7_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block7_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block8_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block8_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block8_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block8_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block8_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block7_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block8_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block8_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block9_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block9_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block9_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block9_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block9_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block8_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block9_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block9_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block10_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block10_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block10_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block10_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block10_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block9_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block10_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block10_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block11_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block11_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block11_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block11_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block11_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block10_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block11_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block11_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block12_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block12_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block12_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block12_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block12_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block11_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block12_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block12_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block13_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block13_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block13_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block13_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block13_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block12_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block13_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block13_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block14_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block14_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block14_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block14_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block14_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block13_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block14_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block14_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block15_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block15_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block15_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block15_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block15_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block14_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block15_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block15_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block16_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block16_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block16_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block16_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block16_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block15_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block16_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block16_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block17_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block17_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block17_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block17_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block17_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block16_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block17_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block17_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block18_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block18_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block18_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block18_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block18_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block17_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block18_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block18_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block19_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block19_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block19_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block19_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block19_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block18_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block19_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block19_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block20_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block20_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block20_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block20_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block20_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block19_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block20_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block20_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block21_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block21_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block21_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block21_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block21_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block20_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block21_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block21_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block22_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block22_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block22_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block22_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block22_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block21_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block22_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block22_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_prea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block23_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │ conv4_block23_pr… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block23_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block23_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_pad │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block23_1_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824</span> │ conv4_block23_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_bn  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv4_block23_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_re… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block23_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv4_block22_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_3_co… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ conv4_block23_2_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ conv4_block23_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv4_block23_ou… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │ conv5_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block1_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │ conv5_block1_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block1_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_0_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ conv5_block1_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block1_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_0_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │ conv5_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span> │ conv5_block2_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block2_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │ conv5_block2_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block2_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block2_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block1_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │ conv5_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_preac… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span> │ conv5_block3_pre… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block3_1_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_1_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_pad  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_1_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,296</span> │ conv5_block3_2_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_bn   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv5_block3_2_c… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_relu │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block3_2_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_3_conv │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ conv5_block3_2_r… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_out    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv5_block2_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │ conv5_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ post_bn             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv5_block3_out… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ post_relu           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ post_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ post_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1_pad           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m230\u001b[0m, \u001b[38;5;34m230\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1_conv (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │      \u001b[38;5;34m9,472\u001b[0m │ conv1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1_pad           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv1_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pool1_pool          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ pool1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv2_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block1_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,864\u001b[0m │ conv2_block1_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block1_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_0_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,640\u001b[0m │ conv2_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,640\u001b[0m │ conv2_block1_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block1_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_0_c… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2_block1_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,384\u001b[0m │ conv2_block2_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block2_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,864\u001b[0m │ conv2_block2_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block2_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,640\u001b[0m │ conv2_block2_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block2_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block1_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2_block2_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block3_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m16,384\u001b[0m │ conv2_block3_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block3_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block3_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block3_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m36,864\u001b[0m │ conv2_block3_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2_block3_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block3_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2_block2_out… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m16,640\u001b[0m │ conv2_block3_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2_block3_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m256\u001b[0m)              │            │ conv2_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2_block3_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m32,768\u001b[0m │ conv3_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block1_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m147,456\u001b[0m │ conv3_block1_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block1_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_0_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m131,584\u001b[0m │ conv3_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m66,048\u001b[0m │ conv3_block1_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block1_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_0_c… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m512\u001b[0m)              │            │ conv3_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv3_block1_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m65,536\u001b[0m │ conv3_block2_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block2_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m147,456\u001b[0m │ conv3_block2_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block2_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m66,048\u001b[0m │ conv3_block2_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block2_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block1_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m512\u001b[0m)              │            │ conv3_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv3_block2_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m65,536\u001b[0m │ conv3_block3_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block3_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m147,456\u001b[0m │ conv3_block3_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block3_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m66,048\u001b[0m │ conv3_block3_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block3_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block2_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m512\u001b[0m)              │            │ conv3_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv3_block3_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block4_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m65,536\u001b[0m │ conv3_block4_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block4_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block4_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block4_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m147,456\u001b[0m │ conv3_block4_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv3_block4_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block4_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv3_block3_out… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m66,048\u001b[0m │ conv3_block4_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv3_block4_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m512\u001b[0m)              │            │ conv3_block4_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv3_block4_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m131,072\u001b[0m │ conv4_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block1_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block1_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block1_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_0_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m525,312\u001b[0m │ conv4_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block1_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block1_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_0_c… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block1_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block2_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block2_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block2_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block2_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block2_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block2_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block1_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block2_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block3_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block3_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block3_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block3_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block3_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block3_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block2_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block3_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block4_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block4_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block4_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block4_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block4_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block4_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block3_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block4_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block4_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block5_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block5_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block5_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block5_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block5_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block5_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block4_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block5_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block5_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block6_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block6_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block6_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block6_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block6_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block6_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block5_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block6_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block6_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block7_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block7_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block7_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block7_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block7_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block7_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block6_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block7_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block7_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block8_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block8_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block8_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block8_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block8_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block8_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block7_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block8_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block8_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block9_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block9_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block9_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block9_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block9_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block9_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block8_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block9_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block9_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block10_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block10_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block10_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block10_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block10_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block10_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block9_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block10_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block10_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block11_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block11_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block11_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block11_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block11_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block11_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block10_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block11_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block11_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block12_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block12_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block12_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block12_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block12_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block12_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block11_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block12_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block12_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block13_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block13_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block13_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block13_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block13_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block13_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block12_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block13_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block13_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block14_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block14_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block14_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block14_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block14_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block14_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block13_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block14_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block14_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block15_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block15_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block15_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block15_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block15_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block15_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block14_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block15_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block15_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block16_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block16_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block16_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block16_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block16_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block16_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block15_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block16_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block16_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block17_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block17_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block17_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block17_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block17_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block17_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block16_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block17_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block17_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block18_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block18_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block18_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block18_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block18_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block18_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block17_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block18_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block18_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block19_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block19_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block19_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block19_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block19_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block19_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block18_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block19_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block19_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block20_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block20_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block20_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block20_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block20_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block20_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block19_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block20_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block20_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block21_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block21_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block21_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block21_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block21_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block21_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block20_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block21_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block21_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block22_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block22_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block22_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block22_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block22_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block22_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block21_ou… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block22_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block22_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_prea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block23_pr… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m262,144\u001b[0m │ conv4_block23_pr… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block23_1_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_1_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block23_1_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_pad │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv4_block23_1_… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m589,824\u001b[0m │ conv4_block23_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_bn  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv4_block23_2_… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_2_re… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv4_block23_2_… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv4_block22_ou… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_3_co… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │    \u001b[38;5;34m263,168\u001b[0m │ conv4_block23_2_… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv4_block23_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m1024\u001b[0m)             │            │ conv4_block23_3_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv4_block23_ou… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │    \u001b[38;5;34m524,288\u001b[0m │ conv5_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block1_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,296\u001b[0m │ conv5_block1_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block1_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_0_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m2,099,200\u001b[0m │ conv5_block1_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block1_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block1_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_0_c… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m2048\u001b[0m)             │            │ conv5_block1_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │      \u001b[38;5;34m8,192\u001b[0m │ conv5_block1_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m1,048,576\u001b[0m │ conv5_block2_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block2_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,296\u001b[0m │ conv5_block2_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block2_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block2_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block2_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block1_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m2048\u001b[0m)             │            │ conv5_block2_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │      \u001b[38;5;34m8,192\u001b[0m │ conv5_block2_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_preac… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block3_pre… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m1,048,576\u001b[0m │ conv5_block3_pre… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block3_1_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_1_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block3_1_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_pad  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block3_1_r… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,296\u001b[0m │ conv5_block3_2_p… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_bn   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv5_block3_2_c… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_2_relu │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv5_block3_2_b… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_3_conv │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m1,050,624\u001b[0m │ conv5_block3_2_r… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv5_block3_out    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv5_block2_out… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m2048\u001b[0m)             │            │ conv5_block3_3_c… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ post_bn             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │      \u001b[38;5;34m8,192\u001b[0m │ conv5_block3_out… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ post_relu           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ post_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ post_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> (162.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,626,560\u001b[0m (162.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,868,416</span> (30.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,868,416\u001b[0m (30.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,758,144</span> (132.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,758,144\u001b[0m (132.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "no_of_channels = 3\n",
    "\n",
    "# Load the saved model\n",
    "ResNet_model = load_model('ResNet_Date_Time_2024_08_20__21_12_43___Loss_0.050666701048612595___Accuracy_0.9838435649871826.h5')\n",
    "\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, no_of_channels)\n",
    "\n",
    "# Remove the classification head (last layer)\n",
    "ResNet_model = Model(inputs=ResNet_model.inputs, outputs=ResNet_model.layers[-5].output)\n",
    "\n",
    "# Set the new input shape\n",
    "ResNet_model.build(input_shape)\n",
    "\n",
    "# Print the updated model summary\n",
    "ResNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7db383-fee1-431e-b2a1-44843a124825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a37e3d45-9841-42fe-a1c6-a17c94829adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input = Input(shape=(SEQUENCE_LENGTH,\n",
    "                           IMAGE_HEIGHT,\n",
    "                            IMAGE_WIDTH,\n",
    "                            no_of_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db999892-7656-4766-9e1d-ebb3fb8d3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_encoded = TimeDistributed(ResNet_model)(video_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "325d9785-25f2-4870-9736-0d4b6ad3ad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 30, 2048), dtype=float32, sparse=False, name=keras_tensor_798>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_frames_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "133bd4c9-8327-4ec0-979e-c8521aa2fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1786e6c3-eb7d-4c43-94e1-87879d62da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_encoded_sequence = LSTM(256)(video_frames_encoded)\n",
    "#video_frames_encoded_sequence = Dropout(0.5)(video_frames_encoded_sequence)\n",
    "\n",
    "hidden_layer1 = Dense(1024, activation=\"relu\")(video_frames_encoded_sequence)\n",
    "#hidden_layer1 = Dropout(0.5)(hidden_layer1)\n",
    "\n",
    "hidden_layer2 = Dense(512, activation=\"relu\")(hidden_layer1)\n",
    "#hidden_layer2 = Dropout(0.5)(hidden_layer2)\n",
    "\n",
    "hidden_layer3 = Dense(256, activation=\"relu\")(hidden_layer2)\n",
    "#hidden_layer3 = Dropout(0.25)(hidden_layer3)\n",
    "\n",
    "hidden_layer4 =  Dense(128, activation=\"relu\")(hidden_layer3)\n",
    "#hidden_layer4 = Dropout(0.25)(hidden_layer4)\n",
    "\n",
    "hidden_layer5 =  Dense(64, activation=\"relu\")(hidden_layer4)\n",
    "#hidden_layer5 = Dropout(0.25)(hidden_layer5)\n",
    "\n",
    "outputs = Dense(no_of_classes, activation=\"softmax\")(hidden_layer5)\n",
    "model = Model([video_input], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4690bef4-3c70-4796-9219-7105a62eb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.00001)\n",
    "                  # beta_1=0.9,\n",
    "                  # beta_2=0.999,\n",
    "                  # epsilon=1e-08,\n",
    "                  # weight_decay=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13492e04-2f4f-4d39-896c-1a357a2757ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06e80d2e-e297-4476-a85d-10a01f46c867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,360,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2048\u001b[0m)       │    \u001b[38;5;34m42,626,560\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m2,360,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,947,458</span> (175.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,947,458\u001b[0m (175.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,189,314</span> (42.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,189,314\u001b[0m (42.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,758,144</span> (132.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,758,144\u001b[0m (132.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b291f04b-07ce-453c-ae4e-4587efefa47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Early Stopping Callback\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\",\n",
    "                      mode=\"min\",\n",
    "                      restore_best_weights=True,\n",
    "                      patience=5)\n",
    "checkpoint = ModelCheckpoint('ResNet+LSTM_best_weights.keras',\n",
    "                             monitor='val_accuracy',\n",
    "                            #  monitor='val_f1_score',\n",
    "                             verbose=1,\n",
    "                             mode='max',\n",
    "                             save_best_only=True)\n",
    "callbacks = [early_stopping_callback, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0237416-13bd-4356-8110-b860c3a7c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((412, 30, 224, 224, 3), (412, 2))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30f9ba48-922e-483a-a643-d40e16044ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 18:46:16.541717: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "W0000 00:00:1725921976.592345 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.609052 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.609620 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.610211 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.610763 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.616719 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.617958 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.620616 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.621763 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.622894 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.623551 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.624271 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.625748 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.626573 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.627444 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.628247 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.629916 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.631074 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.632270 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.633411 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.634504 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.635711 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.643497 2766763 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.973636 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.974157 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.974550 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.974952 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.975816 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.976789 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.977865 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.978938 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.979388 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.980486 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.981547 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.981996 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.983148 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.983613 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.984078 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.985103 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.985589 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.986077 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.986565 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.987037 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.987532 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.988641 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.989167 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.989692 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.990191 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.990808 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.991430 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.992802 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.994170 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.994782 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.995384 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.995989 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.996599 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.997210 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.997816 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.998419 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.999034 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921976.999648 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.000258 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.001397 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.012879 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.013254 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.013600 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.013937 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.014287 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.014639 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.014998 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.015358 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.015722 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.016091 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.016453 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.016823 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.017198 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.017574 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.017958 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.018337 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.018723 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.019108 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.019502 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.019890 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.020281 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.020678 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.021077 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.021478 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.021880 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.022313 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.022741 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.023160 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.023589 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.024008 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.024437 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.024858 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.025287 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.025713 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.026140 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.026560 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.026986 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.027409 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.027831 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.028251 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.041388 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.041872 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.042333 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.042789 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.043360 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.043829 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.044294 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.044772 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.045240 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.045753 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.046264 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.046783 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.047263 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.047737 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.048243 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.048751 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.049247 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.049755 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.050278 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.050782 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.051311 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.051836 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.052357 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.053340 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.053857 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.054377 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.054907 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.056057 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.056570 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.057110 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.057687 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.058263 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.058883 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.059497 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.060167 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.060779 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.061420 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.062063 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.062729 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.063477 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.111376 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.111817 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.112206 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.112601 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.113007 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.113420 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.113867 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.114324 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.114800 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.115286 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.115748 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.116266 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.116763 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.117275 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.117820 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.118373 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.118942 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.119491 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.120050 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.120607 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.121169 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.121721 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.122279 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.122861 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.123447 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.124017 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.124596 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.125182 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.125768 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.126358 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.126941 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.127527 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.128129 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.128723 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.129310 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.129914 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.130533 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.131129 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.131754 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.132344 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.148026 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.190521 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.190914 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.191294 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.191686 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.192079 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.192462 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.192847 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.193245 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.193642 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.194040 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.194421 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.194804 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.195198 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.195578 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.195968 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.196354 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.196737 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.197122 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.197513 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.197912 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.198298 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.198685 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.199081 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.199473 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.199886 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.200269 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.200658 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.201053 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.201448 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.201825 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.202241 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.202621 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.203039 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.203467 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.203883 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.214869 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.215223 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.215544 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.215860 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.216199 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.216533 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.216871 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.217206 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.217551 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.217886 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.218231 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.218570 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.218906 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.219242 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.219581 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.219922 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.220260 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.220603 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.220956 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.221296 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.221634 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.221986 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.222352 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.222705 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.223054 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.223427 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.223801 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.224180 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.224556 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.224935 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.225311 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.225694 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.226069 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.226453 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.226828 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.227201 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.227578 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.227951 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.228322 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.228703 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.240055 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.240477 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.240857 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.241244 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.241657 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.242072 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.242485 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.242923 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.243355 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.243788 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.244222 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.244671 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.245138 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.245595 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.246084 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.246588 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.247083 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.247578 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.248060 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.248552 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.249050 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.249552 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.250067 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.250592 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.251116 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.251644 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.252167 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.252690 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.253196 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.253729 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.254259 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.254798 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.255332 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.255887 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.256416 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.256974 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.257493 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.258067 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.258577 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.259168 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.269728 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.270089 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.270408 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.270730 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.271089 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.271454 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.271816 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.272182 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.272546 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.272924 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.273291 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.273663 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.274037 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.274403 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.274776 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.275155 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.275544 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.275931 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.276316 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.276706 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.277087 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.277473 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.277856 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.278250 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.278651 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.279043 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.279438 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.279831 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.280215 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.280616 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.281002 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.281372 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.281785 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.282196 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.282556 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.282977 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.283392 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.283796 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.284150 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.284570 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.298378 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.298828 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.299238 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.299646 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.300061 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.300473 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.300894 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.301305 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.301715 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.302127 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.302539 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.302960 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.303387 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.303813 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.304225 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.304651 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.305082 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.305513 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.305954 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.306392 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.306813 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.307267 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.307716 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.308178 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.308648 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.309092 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.309546 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.310022 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.310504 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.310960 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.311462 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.311928 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.312417 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.312892 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.313392 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.313900 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.314429 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.314930 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.315499 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.316079 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.327621 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.328001 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.328349 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.328701 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.329080 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.329455 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.329833 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.330219 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.330607 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.330998 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.331386 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.331782 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.332178 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.332573 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.332981 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.333381 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.333793 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.334206 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.334639 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.335085 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.335543 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.336005 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.336462 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.336913 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.337359 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.337818 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.338254 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.338716 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.339167 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.339630 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.340082 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.340553 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.341023 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.341489 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.341959 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.342428 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.342900 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.343371 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.343851 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.344340 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.355932 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.361276 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.361618 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.361962 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.362382 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.362808 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.363227 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.363654 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.364077 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.364501 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.364930 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.365369 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.365805 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.366229 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.366664 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.367116 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.367556 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.368002 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.368451 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.368902 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.369349 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.369804 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.370257 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.370721 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.371191 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.371636 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.372093 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.372561 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.373012 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.373432 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.373888 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.374366 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.374845 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.375307 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.375702 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.376107 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.376599 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.377079 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.377566 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.377989 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.399748 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.436361 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.436717 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.437072 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.437427 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.437796 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.438140 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.438486 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.438844 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.439208 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.439580 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.439948 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.440307 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.440684 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.441048 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.441442 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.441791 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.442164 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.442534 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.442899 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.443275 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.443642 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.444027 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.444404 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.444779 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.445150 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.445529 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.445895 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.446270 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.446675 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.447080 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.447508 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.447886 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.448247 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.448633 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.449039 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.449457 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.449870 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.450256 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.450649 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.462377 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.462731 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.463042 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.463352 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.463683 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.464008 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.464344 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.464692 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.465019 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.465354 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.465701 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.466032 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.466375 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.466717 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.467059 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.467390 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.467722 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.468045 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.468374 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.468715 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.469061 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.469408 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.469759 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.470106 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.470455 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.470797 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.471148 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.471499 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.471842 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.472193 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.472545 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.472874 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.473213 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.473557 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.473906 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.474237 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.474586 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.474952 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.475281 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.475610 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.486958 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.487392 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.487789 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.488183 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.488603 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.489027 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.489449 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.489871 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.490305 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.490748 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.491199 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.491678 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.492124 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.492558 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.493025 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.493478 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.493927 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.494396 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.494851 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.495310 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.495796 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.496295 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.496785 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.497254 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.497708 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.498163 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.498686 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.499184 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.499690 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.500200 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.500695 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.501192 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.501671 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.502209 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.502707 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.503227 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.503756 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.504247 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.504813 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.505327 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.515753 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.516111 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.516440 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.516766 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.517116 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.517462 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.517819 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.518174 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.518531 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.518882 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.519239 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.519595 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.519955 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.520306 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.520661 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.521023 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.521392 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.521762 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.522120 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.522484 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.522852 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.523212 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.523570 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.523932 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.524295 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.524659 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.525024 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.525402 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.525776 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.526157 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.526524 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.526889 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.527251 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.527612 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.527993 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.528363 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.528731 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.529103 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.529480 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.529862 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.543041 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.543492 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.543896 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.544295 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.544706 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.545099 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.545515 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.545936 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.546345 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.546771 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.547175 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.547579 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.547985 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.548394 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.548802 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.549205 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.549633 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.550052 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.550468 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.550911 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.551392 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.551839 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.552278 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.552716 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.553198 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.553641 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.554119 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.554582 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.555045 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.555506 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.555955 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.556439 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.556896 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.557309 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.557787 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.558274 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.558821 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.559394 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.559985 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.560580 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.572514 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.572913 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.573265 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.573622 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.573989 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.574360 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.574724 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.575099 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.575475 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.575863 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.576243 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.576636 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.577018 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.577402 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.577814 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.578217 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.578622 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.579041 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.579452 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.579859 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.580257 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.580664 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.581089 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.581480 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.581890 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.582304 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.582719 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.583145 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.583566 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.583984 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.584407 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.584824 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.585242 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.585678 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.586101 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.586526 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.586978 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.587423 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.587861 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.588297 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.599903 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.600295 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.600784 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.601215 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.601620 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.602014 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.602423 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.602822 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.603218 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.603611 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.604013 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.604417 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.604822 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.605222 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.605621 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.606026 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.606459 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.606885 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.607295 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.607705 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.608118 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.608530 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.608934 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.609346 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.609757 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.610167 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.610587 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.611041 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.611474 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.611914 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.612356 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.612780 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.613201 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.613617 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.614077 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.614507 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.614931 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.615364 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.615826 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.616288 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.968815 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.988310 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.988673 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.989033 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.989394 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.989757 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.990121 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.990487 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.990862 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.991231 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.991597 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.991968 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.992339 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.992710 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.993078 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.993465 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.993839 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.994255 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.994650 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.995057 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.995465 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.995874 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.996285 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.996696 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.997102 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.997510 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.997924 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.998339 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.998777 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.999221 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921977.999667 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.000125 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.000604 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.001072 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.001558 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.002050 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.002540 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.003053 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.003557 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.014868 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.015233 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.015553 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.015872 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.016201 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.016536 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.016876 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.017213 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.017544 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.017885 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.018226 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.018570 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.018914 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.019284 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.019624 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.019960 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.020312 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.020651 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.021003 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.021335 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.021684 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.022022 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.022361 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.022702 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.023039 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.023387 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.023724 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.024058 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.024401 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.024760 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.025092 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.025426 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.025772 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.026115 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.026458 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.026813 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.027161 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.027510 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.038058 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.038554 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.039012 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.039468 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.039989 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.040504 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.041022 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.041531 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.042051 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.042590 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.043118 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.043599 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.044117 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.044664 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.045179 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.045688 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.046239 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.046772 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.047304 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.047816 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.048325 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.048859 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.049399 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.049922 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.050456 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.050997 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.051511 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.052045 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.052586 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.053136 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.053701 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.054288 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.054837 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.055386 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.055986 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.056567 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.057147 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.057715 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.058264 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.068049 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.068426 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.068769 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.069109 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.069475 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.069845 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.070218 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.070577 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.070947 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.071314 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.071695 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.072071 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.072460 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.072842 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.073219 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.073596 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.073975 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.074354 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.074735 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.075123 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.075504 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.075889 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.076271 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.076653 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.077035 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.077415 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.077800 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.078187 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.078567 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.078946 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.079332 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.079716 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.080103 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.080500 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.080897 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.081304 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.081719 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.082134 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.082558 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.095176 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.095647 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.096068 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.096490 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.096996 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.097427 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.097857 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.098275 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.098713 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.099135 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.099629 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.100051 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.100547 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.101045 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.101538 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.102034 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.102520 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.102981 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.103450 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.103942 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.104449 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.104945 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.105431 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.106081 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.106593 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.107103 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.107768 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.108267 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.108788 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.109344 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.109885 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.110382 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.111018 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.111647 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.112333 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.113027 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.113915 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.114708 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.126210 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.126633 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.127014 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.127391 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.127785 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.128196 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.128611 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.129022 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.129442 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.129860 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.130282 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.130704 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.131121 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.131549 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.131970 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.132398 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.132823 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.133251 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.133659 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.134091 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.134521 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.134942 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.135366 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.135808 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.136240 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.136683 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.137129 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.137552 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.137961 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.138405 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.138841 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.139268 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.139714 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.140151 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.140595 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.141040 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.141494 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.141920 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.142388 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.142833 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.153541 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.153960 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.154341 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.154730 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.155150 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.155582 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.156004 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.156422 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.156843 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.157277 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.157717 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.158159 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.158601 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.159057 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.159512 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.159965 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.160407 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.160851 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.161295 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.161749 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.162209 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.162661 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.163117 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.163576 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.164034 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.164497 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.164963 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.165423 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.165874 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.166338 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.166806 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.167271 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.167750 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.168239 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.168728 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.169246 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.169772 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.170310 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.170864 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47:14\u001b[0m 142s/step - accuracy: 0.4375 - loss: 0.7391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725921978.401099 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.401543 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.401927 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.402306 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.402734 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.405389 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.406656 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.407091 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.407511 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.407962 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.408406 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.408854 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.409290 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.409749 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.410208 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.410675 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.411140 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.411603 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.412147 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.413344 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.414107 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.414655 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.415181 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.415723 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.416650 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.419067 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.446073 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.446610 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.446968 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.447335 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.447827 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.448296 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.448657 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.449025 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.449468 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.449841 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.450225 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.450611 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.450999 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.451399 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.451800 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.452193 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.452587 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.453108 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.453523 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.454772 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.455664 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.456152 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.457303 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.458176 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.458676 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.459174 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.459696 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.460212 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.460739 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.461312 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.461856 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.462397 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.477941 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.478476 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.478979 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.479496 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.479938 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.480375 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.480874 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.481335 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.481780 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.482276 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.482769 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.483263 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.483762 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.484292 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.484786 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.485410 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.486280 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.486936 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.487596 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.488519 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.489412 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.490202 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.490777 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.491392 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.492315 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.493382 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.500599 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.501024 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.501439 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.501848 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.502255 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.502674 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.503090 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.503514 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.503954 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.504418 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.504879 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.505359 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.506282 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.506831 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.507426 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.508048 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.508633 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.509456 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.510276 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.510899 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.511714 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.534484 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.534908 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.535280 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.535658 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.536075 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.536485 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.536915 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.537354 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.537781 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.538211 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.538642 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.539078 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.539510 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.539947 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.540375 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.540802 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.541239 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.541688 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.542139 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.542587 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.543041 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.543486 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.543970 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.544461 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.545106 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.545797 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.547019 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.555658 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.556034 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.556398 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.556757 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.557117 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.557484 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.557853 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.558222 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.558599 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.558972 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.559354 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.559737 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.560130 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.560521 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.560901 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.561293 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.561695 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.562092 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.562497 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.562919 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.563370 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.563843 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.564333 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.564844 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.565392 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.565941 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.566490 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.567009 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.567527 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.568060 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.568559 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921978.569062 2766768 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 824ms/step - accuracy: 0.4562 - loss: 0.7026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725921994.272101 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.272621 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.273044 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.273487 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.273919 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.274458 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.274984 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.275469 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.276006 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.276709 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.277273 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.277877 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.278560 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.279299 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.280102 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.280812 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.281792 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.282802 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.283836 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.284871 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.285781 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.286782 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.288893 2766719 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.363002 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.363429 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.363778 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.364133 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.364511 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.364889 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.365272 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.365650 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.366025 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.366402 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.366783 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.367164 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.367539 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.367921 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.368306 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.368691 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.369083 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.369469 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.369889 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.370288 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.370687 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.371096 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.371507 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.371929 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.372391 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.372851 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.373319 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.373779 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.374246 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.374714 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.375187 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.375659 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.376130 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.376598 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.377064 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.377535 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.378003 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.378487 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.378963 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.379441 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.389152 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.389494 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.389811 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.390121 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.390439 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.390745 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.391071 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.391386 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.391713 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.392041 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.392370 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.392704 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.393031 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.393359 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.393710 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.394054 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.394399 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.394741 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.395082 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.395427 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.395784 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.396132 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.396487 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.396839 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.397183 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.397550 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.397915 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.398280 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.398647 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.399014 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.399373 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.399735 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.400095 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.400462 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.400825 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.401181 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.401547 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.401902 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.402267 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.402643 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.415667 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.416098 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.416487 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.416869 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.417261 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.417655 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.418048 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.418439 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.418832 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.419229 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.419646 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.420072 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.420472 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.420899 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.421310 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.421733 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.422158 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.422580 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.422995 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.423414 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.423822 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.424242 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.424652 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.425068 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.425487 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.425913 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.426341 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.426768 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.427195 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.427630 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.428053 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.428506 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.428945 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.429390 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.429843 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.430311 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.430788 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.431260 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.431789 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.432270 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.444690 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.455843 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.456189 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.456533 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.456892 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.457241 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.457598 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.457959 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.458344 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.458737 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.459129 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.459557 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.459971 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.460388 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.460829 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.461275 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.461717 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.462156 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.462604 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.463057 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.463504 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.463947 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.464401 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.464860 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.465318 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.465771 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.466224 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.466688 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.467148 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.467616 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.468074 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.468537 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.469003 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.469475 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.469932 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.470406 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.470881 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.471354 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.471832 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.472304 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.487725 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.506522 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.506866 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.507216 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.507558 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.507911 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.508270 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.508613 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.508971 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.509353 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.509709 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.510079 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.510441 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.510800 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.511160 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.511510 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.511870 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.512223 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.512583 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.512936 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.513289 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.513652 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.514005 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.514366 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.514724 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.515087 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.515448 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.515812 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.516169 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.516526 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.516920 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.517287 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.517646 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.518013 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.518360 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.518708 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.519099 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.519475 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.530259 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.530613 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.530921 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.531234 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.531556 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.531882 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.532213 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.532539 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.532862 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.533188 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.533522 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.533848 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.534174 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.534501 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.534829 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.535154 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.535482 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.535815 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.536149 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.536472 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.536795 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.537122 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.537453 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.537784 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.538113 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.538459 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.538797 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.539152 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.539496 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.539842 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.540193 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.540536 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.540885 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.541233 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.541581 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.541926 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.542270 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.542618 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.542963 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.543313 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.554295 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.554672 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.555023 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.555370 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.555747 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.556119 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.556493 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.556881 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.557270 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.557656 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.558037 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.558426 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.558821 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.559229 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.559626 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.560045 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.560461 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.560879 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.561295 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.561720 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.562146 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.562569 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.562991 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.563417 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.563847 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.564286 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.564729 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.565144 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.565582 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.566023 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.566460 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.566903 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.567340 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.567770 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.568210 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.568647 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.569097 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.569566 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.570029 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.570482 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.580305 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.580653 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.580968 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.581279 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.581610 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.581954 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.582290 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.582632 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.582966 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.583305 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.583640 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.583983 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.584329 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.584678 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.585021 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.585360 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.585703 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.586047 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.586388 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.586739 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.587080 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.587416 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.587761 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.588099 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.588446 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.588795 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.589144 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.589494 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.589842 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.590188 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.590535 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.590883 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.591239 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.591590 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.591937 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.592294 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.592647 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.593003 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.593357 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.593712 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.606356 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.606760 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.607126 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.607495 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.607863 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.608228 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.608601 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.608968 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.609340 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.609709 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.610080 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.610448 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.610818 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.611193 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.611571 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.611940 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.612325 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.612704 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.613096 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.613501 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.613886 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.614278 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.614671 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.615071 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.615472 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.615874 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.616263 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.616685 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.617075 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.617494 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.617889 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.618299 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.618705 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.619130 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.619546 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.619980 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.620392 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.620838 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.621296 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.621773 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.633125 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.633505 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.633838 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.634167 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.634517 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.634866 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.635215 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.635575 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.635928 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.636282 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.636641 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.636994 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.637360 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.637719 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.638080 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.638455 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.638814 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.639174 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.639553 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.639946 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.640335 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.640721 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.641114 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.641515 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.641911 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.642308 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.642704 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.643086 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.643486 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.643885 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.644285 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.644690 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.645070 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.645470 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.645863 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.646263 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.646649 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.647055 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.647466 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.647879 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.659001 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.659366 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.659701 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.660029 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.660388 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.660747 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.661127 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.661523 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.661917 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.662288 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.662670 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.663054 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.663431 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.663823 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.664203 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.664589 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.664977 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.665363 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.665752 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.666138 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.666526 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.666914 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.667294 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.667677 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.668057 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.668457 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.668842 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.669233 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.669614 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.670005 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.670398 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.670797 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.671195 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.671589 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.671986 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.672382 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.672774 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.673166 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.673570 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.673969 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.693294 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.709316 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.709659 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.710010 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.710352 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.710685 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.711031 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.711374 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.711722 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.712060 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.712420 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.712755 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.713101 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.713445 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.713796 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.714153 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.714493 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.714862 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.715229 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.715586 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.715954 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.716316 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.716657 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.717022 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.717383 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.717750 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.718117 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.718481 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.718844 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.719203 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.719582 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.719967 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.720355 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.720763 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.721173 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.721554 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.721961 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.722372 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.722788 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.723181 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.734498 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.734848 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.735156 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.735467 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.735789 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.736112 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.736438 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.736758 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.737086 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.737412 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.737735 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.738062 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.738391 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.738714 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.739043 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.739361 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.739693 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.740025 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.740345 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.740670 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.741004 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.741332 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.741664 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.741989 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.742318 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.742639 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.742975 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.743299 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.743628 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.743957 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.744281 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.744605 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.744936 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.745275 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.745615 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.745942 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.746269 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.746592 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.746917 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.747238 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.758217 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.758599 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.758950 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.759305 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.759698 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.760094 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.760486 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.760872 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.761267 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.761662 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.762071 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.762470 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.762897 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.763304 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.763710 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.764113 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.764525 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.764934 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.765320 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.765735 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.766141 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.766548 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.766960 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.767388 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.767811 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.768243 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.768674 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.769120 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.769552 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.769989 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.770394 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.770821 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.771256 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.771688 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.772110 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.772548 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.772974 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.773414 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.773874 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.774330 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.784676 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.785032 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.785347 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.785661 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.786009 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.786358 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.786711 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.787049 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.787382 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.787716 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.788061 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.788413 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.788757 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.789104 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.789455 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.789805 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.790151 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.790499 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.790846 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.791193 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.791543 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.791889 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.792236 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.792580 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.792929 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.793275 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.793620 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.793975 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.794325 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.794686 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.795033 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.795387 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.795736 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.796088 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.796441 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.796780 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.797127 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.797479 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.797842 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.798204 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.810464 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.810874 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.811248 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.811656 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.812041 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.812416 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.812799 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.813204 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.813582 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.813941 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.814301 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.814707 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.815107 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.815508 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.815910 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.816273 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.816676 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.817062 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.817457 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.817845 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.818259 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.818624 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.819054 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.819450 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.819859 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.820240 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.820635 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.821061 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.821464 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.821874 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.822284 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.822694 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.823113 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.823532 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.824015 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.824503 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.825057 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.825555 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.826079 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.837199 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.837579 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.837907 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.838238 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.838590 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.838946 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.839306 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.839663 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.840023 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.840380 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.840744 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.841102 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.841469 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.841822 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.842188 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.842548 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.842907 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.843292 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.843671 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.844055 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.844444 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.844820 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.845193 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.845572 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.845954 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.846323 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.846707 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.847088 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.847466 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.847848 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.848225 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.848598 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.848982 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.849375 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.849749 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.850138 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.850518 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.850897 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.851292 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.851675 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.863093 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.863462 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.863797 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.864140 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.864515 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.864892 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.865266 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.865631 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.865998 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.866364 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.866745 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.867132 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.867511 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.867896 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.868272 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.868655 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.869035 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.869420 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.869804 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.870193 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.870578 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.870965 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.871349 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.871729 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.872132 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.872518 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.872899 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.873290 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.873678 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.874094 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.874481 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.874876 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.875263 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.875650 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.876050 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.876443 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.876827 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.877212 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.877634 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921994.878059 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.098917 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.108986 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.109333 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.109683 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.110028 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.110381 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.110725 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.111074 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.111429 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.111787 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.112137 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.112505 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.112865 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.113228 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.113597 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.113965 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.114347 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.114726 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.115108 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.115512 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.115903 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.116317 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.116721 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.117117 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.117525 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.117930 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.118342 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.118746 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.119182 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.119628 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.120071 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.120507 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.120947 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.121424 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.121914 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.122401 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.122881 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.123391 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.123908 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.135068 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.135421 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.135738 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.136048 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.136368 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.136693 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.137021 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.137347 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.137691 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.138031 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.138362 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.138707 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.139046 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.139393 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.139732 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.140072 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.140413 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.140747 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.141078 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.141420 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.141763 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.142093 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.142430 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.142767 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.143106 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.143443 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.143780 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.144119 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.144472 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.144816 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.145152 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.145491 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.145834 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.146173 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.146509 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.146845 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.147200 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.147538 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.147890 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.148239 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.158662 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.159092 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.159487 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.159878 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.160297 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.160722 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.161158 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.161606 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.162058 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.162525 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.162997 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.163469 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.163944 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.164430 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.164920 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.165403 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.165885 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.166368 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.166854 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.167333 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.167807 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.168299 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.168784 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.169268 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.169754 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.170238 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.170750 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.171236 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.171743 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.172241 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.172755 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.173259 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.173777 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.174278 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.174811 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.175328 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.175836 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.176315 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.176843 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.177370 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.186698 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.187043 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.187365 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.187684 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.188064 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.188451 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.188834 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.189202 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.189567 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.189934 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.190319 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.190704 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.191084 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.191446 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.191835 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.192198 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.192563 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.192949 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.193309 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.193687 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.194066 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.194458 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.194845 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.195205 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.195565 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.195933 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.196351 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.196750 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.197113 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.197476 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.197844 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.198266 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.198631 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.199065 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.199447 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.199828 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.211740 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.212196 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.212620 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.213045 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.213438 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.213853 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.214236 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.214646 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.215079 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.215496 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.215938 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.216349 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.216812 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.217211 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.217613 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.218110 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.218611 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.219112 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.219610 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.220048 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.220543 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.221045 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.221551 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.221981 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.222465 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.222964 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.223456 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.223894 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.224388 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.224812 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.225365 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.226026 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.226694 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.227314 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.227917 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.228422 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.229130 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.229755 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.240038 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.240424 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.240778 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.241129 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.241497 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.241876 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.242234 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.242634 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.243021 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.243410 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.243793 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.244181 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.244554 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.244946 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.245346 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.245745 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.246141 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.246543 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.246942 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.247348 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.247750 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.248157 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.248567 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.248969 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.249388 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.249793 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.250214 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.250617 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.251035 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.251460 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.251885 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.252300 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.252714 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.253126 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.253545 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.253948 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.254347 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.254783 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.255216 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.266973 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.267349 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.267697 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.268042 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.268498 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.268948 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.269401 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.269821 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.270239 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.270654 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.271105 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.271554 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.272002 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.272412 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.272835 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.273250 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.273666 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.274120 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.274530 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.274980 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.275428 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.275907 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.276317 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.276723 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.277139 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.277667 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.278193 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.278614 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.279032 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.279464 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.279892 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.280457 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.280912 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.281367 2766722 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843ms/step - accuracy: 0.4614 - loss: 0.7012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725921995.315280 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.315677 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.316020 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.316355 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.316763 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.317161 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.317574 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.317973 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.318377 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.318790 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.319213 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.319619 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.320066 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.320514 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.321004 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.321446 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.321897 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.322429 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.322883 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.323341 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.323821 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.324353 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.324772 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.325304 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.325849 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.333695 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.334049 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.334401 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.334747 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.335098 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.335443 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.335782 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.336124 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.336469 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.336821 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.337177 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.337531 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.337891 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.338253 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.338617 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.338971 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.339347 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.339729 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.340100 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.340474 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.340857 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.341258 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.341683 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.342102 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.342509 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.342930 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.343356 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.343782 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.344210 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.344654 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.345096 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.345538 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.353564 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.354027 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.354464 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.354882 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.355320 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.355733 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.356149 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.356570 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.357029 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.357522 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.357982 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.358481 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.358972 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.359466 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.359940 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.360569 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.361074 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.361605 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.362245 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.362905 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.363576 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.364278 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.364912 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.365714 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.369797 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.370195 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.370581 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.370971 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.371350 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.371747 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.372127 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.372518 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.372917 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.373333 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.373758 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.374192 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.374646 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.375121 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.375592 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.376163 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.376650 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.377134 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.377741 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.378344 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.378949 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.379669 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.380381 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.381597 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.391056 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.397670 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.398013 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.398360 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.398727 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.399101 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.399497 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.399897 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.400290 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.400696 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.401098 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.401498 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.401896 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.402279 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.402698 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.403102 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.403511 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.403920 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.404328 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.404762 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.405178 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.405590 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.405998 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.406416 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.406927 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.407455 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.414472 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.414831 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.415167 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.415511 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.415854 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.416200 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.416538 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.416879 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.417219 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.417579 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.417924 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.418275 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.418624 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.418977 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.419336 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.419690 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.420056 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.420444 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.420821 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.421185 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.421558 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.422000 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.422443 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.422883 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.423277 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.423696 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.424098 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.424512 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.424936 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.425359 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.425794 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725921995.426215 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.542408 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.543051 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.543684 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.544331 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.545047 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.546917 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.547760 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.563637 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.564658 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.565685 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.566917 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.568151 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.569405 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.570783 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.572119 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.573447 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.574948 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.577635 2766750 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.647498 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.648002 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.648447 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.648865 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.649340 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.649804 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.650275 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.650756 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.651231 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.651708 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.652180 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.652670 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.653171 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.653640 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.654127 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.654623 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.655097 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.655591 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.656132 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.656638 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.657158 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.657722 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.658283 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.658899 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.659425 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.659980 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.660618 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.661149 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.661708 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.662322 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.662895 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.663422 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.664127 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.664718 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.665299 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.665851 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.666401 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.667108 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.668003 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.668810 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.686043 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.761016 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.761388 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.761770 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.762164 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.762570 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.762955 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.763345 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.763729 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.764112 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.764500 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.764885 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.765276 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.765667 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.766052 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.766443 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.766846 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.767229 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.767617 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.768023 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.768432 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.768832 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.769227 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.769644 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.770054 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.770456 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.770878 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.771273 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.771679 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.772097 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.772492 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.772961 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.773388 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.773820 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.774237 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.774669 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.775137 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.775613 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.789656 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.794887 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.795282 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.795681 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.796103 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.796521 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.796959 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.797394 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.797821 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.798245 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.798658 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.799069 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.799512 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.799934 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.800375 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.800811 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.801246 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.801685 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.802116 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.802567 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.803023 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.803460 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.803917 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.804370 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.804809 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.805322 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.805815 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.806339 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.806840 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.807334 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.807769 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.808204 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.808708 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.809346 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.809936 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.810720 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.811360 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.811856 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.812353 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.812953 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.850507 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.889534 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.889894 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.890242 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.890595 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.890975 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.891331 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.891719 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.892082 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.892449 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.892828 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.893204 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.893578 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.893962 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.894323 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.894692 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.895071 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.895439 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.895819 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.896199 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.896587 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.896968 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.897360 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.897727 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.898106 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.898493 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.898869 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.899250 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.899625 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.900008 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.900429 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.900851 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.901229 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.901650 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.902117 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.902549 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.902971 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.916505 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.917187 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.917627 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.918065 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.918456 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.918883 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.919283 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.919743 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.920175 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.920621 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.921112 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.921532 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.922000 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.922485 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.922889 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.923294 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.923792 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.924211 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.924647 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.925066 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.925469 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.925869 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.926276 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.926686 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.927130 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.927575 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.927981 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.928459 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.928863 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.929274 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.929723 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.930209 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.930706 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.931289 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.932082 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.932696 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.933630 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922034.934270 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.258608 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.278977 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.279326 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.279682 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.280031 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.280402 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.280760 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.281135 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.281493 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.281867 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.282235 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.282603 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.282983 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.283345 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.283708 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.284090 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.284505 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.284909 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.285288 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.285697 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.286107 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.286512 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.286910 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.287314 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.287720 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.288115 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.288520 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.288930 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.289357 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.289853 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.290348 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.290803 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.291273 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.291741 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.292243 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.292735 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.293376 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.306711 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.307171 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.307596 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.308025 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.308457 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.308874 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.309316 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.309745 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.310178 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.310621 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.311132 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.311600 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.312062 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.312536 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.313012 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.313507 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.314008 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.314502 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.315005 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.315509 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.316001 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.316501 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.317025 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.317538 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.318030 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.318541 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.319078 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.319579 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.320139 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.320827 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.321486 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.322156 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.322833 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.323517 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.324240 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.325001 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.325946 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922035.326910 2766767 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.151236 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.151660 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.152009 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.152356 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.152712 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.153065 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.153421 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.153800 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.154185 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.154571 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.155005 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.155431 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.155874 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.156310 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.156742 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.157213 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.157648 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.228444 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.228838 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.229168 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.229493 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.229836 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.230179 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.230514 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.230856 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.231193 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.231529 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.231874 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.232207 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.232545 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.232875 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.233221 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.233576 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.233920 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.234258 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.234592 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.234928 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.235270 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.235617 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.235968 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.236317 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.236666 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.237030 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.237389 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.237740 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.238095 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.238441 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.238778 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.239137 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.242724 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.243095 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.243459 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.243827 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.244199 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.244584 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.244976 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.245336 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.263053 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.266605 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.266922 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.267249 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.267577 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.267909 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.268234 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.268554 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.268877 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.269212 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.269552 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.269872 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.270207 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.270538 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.270867 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.271194 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.271521 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.271859 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.272191 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.272526 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.272871 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.273209 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.273539 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.273861 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.274206 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.274544 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.274898 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.275226 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.275550 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.275892 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.276252 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.276597 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.276965 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.277296 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.277641 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.278006 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.278353 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.292594 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.292972 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.293315 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.293655 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.293990 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.294315 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.294653 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.294987 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.295327 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.295654 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.295991 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.296330 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.296679 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.297036 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.297387 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.297729 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.298077 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.298443 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.298797 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.299158 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.299518 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.299880 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.300229 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.300583 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.300935 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.301291 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.301648 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.301994 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.302346 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.302680 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.303028 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.303403 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.303753 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.304157 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.304537 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.304937 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.305320 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.305717 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.306100 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.306464 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.325866 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.326232 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.326565 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.326882 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.327208 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.327541 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.327874 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.328197 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.328521 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.328853 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.329176 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.329502 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.329836 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.330174 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.330514 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.330856 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.331189 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.331528 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.331877 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.332228 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.332581 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.332939 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.333281 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.333633 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.333999 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.334357 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.334715 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.335073 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.335418 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.335780 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.336148 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.336505 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.336871 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.337248 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.337624 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.338007 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.338390 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.338788 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.339192 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.339589 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.353478 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.353863 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.354200 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.354538 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.354878 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.355218 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.355576 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.355923 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.356282 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.356636 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.356995 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.357346 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.357706 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.358070 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.358421 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.358767 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.359120 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.359496 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.359866 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.360238 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.360613 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.360998 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.361374 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.361734 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.362095 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.362497 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.362900 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.363301 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.363696 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.364092 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.364490 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.364893 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.365294 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.365713 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.366165 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.366580 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.367061 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.367549 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.368023 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.472878 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.473269 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.473604 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.473945 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.474277 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.474606 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.474937 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.475277 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.475617 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.475972 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.476323 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.476670 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.477023 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.477380 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.477736 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.478095 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.478465 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.478862 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.479231 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.479614 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.479991 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.480358 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.480752 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.481151 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.481551 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.481923 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.482316 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.482710 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.483116 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.483519 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.483975 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.484388 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.484845 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.485291 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.485769 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.486248 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.486735 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.500730 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.501140 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.501498 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.501877 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.502234 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.502615 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.502995 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.503371 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.503780 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.504192 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.504609 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.505025 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.505400 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.505803 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.506219 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.506598 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.507014 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.507386 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.507845 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.508325 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.508803 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.509296 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.509792 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.510269 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.510762 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.511251 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.511738 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.512230 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.512670 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.513121 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.513661 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.514275 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.514838 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.515452 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.516108 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.516773 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725922038.517384 2766752 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75904, saving model to ResNet+LSTM_best_weights.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.4661 - loss: 0.7000 - val_accuracy: 0.7590 - val_loss: 0.6200\n",
      "Epoch 2/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814ms/step - accuracy: 0.7056 - loss: 0.6135\n",
      "Epoch 2: val_accuracy improved from 0.75904 to 0.80723, saving model to ResNet+LSTM_best_weights.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.7076 - loss: 0.6125 - val_accuracy: 0.8072 - val_loss: 0.5501\n",
      "Epoch 3/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step - accuracy: 0.8033 - loss: 0.5421\n",
      "Epoch 3: val_accuracy improved from 0.80723 to 0.96386, saving model to ResNet+LSTM_best_weights.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.8065 - loss: 0.5410 - val_accuracy: 0.9639 - val_loss: 0.4641\n",
      "Epoch 4/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824ms/step - accuracy: 0.9324 - loss: 0.4632\n",
      "Epoch 4: val_accuracy improved from 0.96386 to 0.98795, saving model to ResNet+LSTM_best_weights.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9327 - loss: 0.4621 - val_accuracy: 0.9880 - val_loss: 0.3790\n",
      "Epoch 5/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 0.9638 - loss: 0.3711\n",
      "Epoch 5: val_accuracy did not improve from 0.98795\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9638 - loss: 0.3699 - val_accuracy: 0.9639 - val_loss: 0.2790\n",
      "Epoch 6/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 0.9357 - loss: 0.2957\n",
      "Epoch 6: val_accuracy did not improve from 0.98795\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9365 - loss: 0.2945 - val_accuracy: 0.9880 - val_loss: 0.2148\n",
      "Epoch 7/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.9743 - loss: 0.2146\n",
      "Epoch 7: val_accuracy did not improve from 0.98795\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9743 - loss: 0.2138 - val_accuracy: 0.9880 - val_loss: 0.1541\n",
      "Epoch 8/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.9813 - loss: 0.1567\n",
      "Epoch 8: val_accuracy did not improve from 0.98795\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9815 - loss: 0.1559 - val_accuracy: 0.9880 - val_loss: 0.1101\n",
      "Epoch 9/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.9907 - loss: 0.1148\n",
      "Epoch 9: val_accuracy did not improve from 0.98795\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9908 - loss: 0.1140 - val_accuracy: 0.9880 - val_loss: 0.0755\n",
      "Epoch 10/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.9907 - loss: 0.0768\n",
      "Epoch 10: val_accuracy improved from 0.98795 to 1.00000, saving model to ResNet+LSTM_best_weights.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9908 - loss: 0.0765 - val_accuracy: 1.0000 - val_loss: 0.0523\n",
      "Epoch 11/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 0.9953 - loss: 0.0610\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0608 - val_accuracy: 1.0000 - val_loss: 0.0483\n",
      "Epoch 12/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 0.9875 - loss: 0.0610\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9878 - loss: 0.0606 - val_accuracy: 1.0000 - val_loss: 0.0328\n",
      "Epoch 13/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 0.9953 - loss: 0.0384\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0382 - val_accuracy: 1.0000 - val_loss: 0.0236\n",
      "Epoch 14/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 0.9953 - loss: 0.0247\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0247 - val_accuracy: 0.9880 - val_loss: 0.0256\n",
      "Epoch 15/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 0.9931 - loss: 0.0287\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9927 - loss: 0.0290 - val_accuracy: 0.9880 - val_loss: 0.0269\n",
      "Epoch 16/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0197\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.9880 - val_loss: 0.0441\n",
      "Epoch 17/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 0.9953 - loss: 0.0223\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0222 - val_accuracy: 0.9880 - val_loss: 0.0233\n",
      "Epoch 18/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876ms/step - accuracy: 0.9953 - loss: 0.0155\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0153 - val_accuracy: 0.9880 - val_loss: 0.0201\n",
      "Epoch 19/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9880 - val_loss: 0.0208\n",
      "Epoch 20/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0141\n",
      "Epoch 21/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0118\n",
      "Epoch 22/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
      "Epoch 23/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 24/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
      "Epoch 25/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
      "Epoch 26/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0060\n",
      "Epoch 27/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
      "Epoch 28/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0053\n",
      "Epoch 29/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
      "Epoch 30/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
      "Epoch 31/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 31: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 32: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 33/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 33: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 34/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 34: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 35/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 35: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 36/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 36: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 37/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 0.0010\n",
      "Epoch 37: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 38/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 9.7887e-04\n",
      "Epoch 38: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.7630e-04 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 39/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 9.1883e-04\n",
      "Epoch 39: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1641e-04 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 40/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 8.6378e-04\n",
      "Epoch 40: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.6149e-04 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 41/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 8.1341e-04\n",
      "Epoch 41: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.1125e-04 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 42/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 7.6680e-04\n",
      "Epoch 42: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.6477e-04 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 43/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 7.2389e-04\n",
      "Epoch 43: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.2197e-04 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 44/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 6.8376e-04\n",
      "Epoch 44: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.8195e-04 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 45/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 6.4645e-04\n",
      "Epoch 45: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.4473e-04 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 46/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 6.1170e-04\n",
      "Epoch 46: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.1009e-04 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 47/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 5.7961e-04\n",
      "Epoch 47: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.7809e-04 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 48/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 5.4990e-04\n",
      "Epoch 48: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.4846e-04 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 49/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 5.2226e-04\n",
      "Epoch 49: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.2090e-04 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 50/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 4.9632e-04\n",
      "Epoch 50: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.9503e-04 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 51/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 4.7199e-04\n",
      "Epoch 51: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.7077e-04 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 52/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 4.4956e-04\n",
      "Epoch 52: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.4841e-04 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 4.2881e-04\n",
      "Epoch 53: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.2772e-04 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 54/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 4.0942e-04\n",
      "Epoch 54: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.0838e-04 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.9118e-04\n",
      "Epoch 55: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.9018e-04 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 56/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 3.7415e-04\n",
      "Epoch 56: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.7319e-04 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 57/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.5814e-04\n",
      "Epoch 57: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.5723e-04 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 58/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.4313e-04\n",
      "Epoch 58: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.4225e-04 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 59/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 3.2891e-04\n",
      "Epoch 59: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.2806e-04 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 60/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.1554e-04\n",
      "Epoch 60: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.1471e-04 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 61/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 3.0259e-04\n",
      "Epoch 61: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.0178e-04 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 62/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.9023e-04\n",
      "Epoch 62: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.8944e-04 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 63/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 2.7837e-04\n",
      "Epoch 63: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.7761e-04 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 64/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 2.6713e-04\n",
      "Epoch 64: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6641e-04 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 65/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 2.5626e-04\n",
      "Epoch 65: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5558e-04 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 66/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 2.4562e-04\n",
      "Epoch 66: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.4499e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 67/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.3620e-04\n",
      "Epoch 67: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.3559e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 68/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 2.2732e-04\n",
      "Epoch 68: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.2674e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 69/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 2.1897e-04\n",
      "Epoch 69: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1840e-04 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 70/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 2.1104e-04\n",
      "Epoch 70: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.1049e-04 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 71/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 2.0347e-04\n",
      "Epoch 71: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0295e-04 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 72/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 1.9630e-04\n",
      "Epoch 72: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9580e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 73/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.8946e-04\n",
      "Epoch 73: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8898e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 74/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.8288e-04\n",
      "Epoch 74: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8242e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 75/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.7660e-04\n",
      "Epoch 75: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7616e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 76/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 1.7063e-04\n",
      "Epoch 76: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7020e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.6491e-04\n",
      "Epoch 77: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.6449e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 78/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.5944e-04\n",
      "Epoch 78: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5904e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 79/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.5414e-04\n",
      "Epoch 79: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5375e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.4901e-04\n",
      "Epoch 80: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4863e-04 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.4411e-04\n",
      "Epoch 81: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4374e-04 - val_accuracy: 1.0000 - val_loss: 9.9935e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.3944e-04\n",
      "Epoch 82: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3909e-04 - val_accuracy: 1.0000 - val_loss: 9.7384e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.3499e-04\n",
      "Epoch 83: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3465e-04 - val_accuracy: 1.0000 - val_loss: 9.4756e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.3071e-04\n",
      "Epoch 84: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3038e-04 - val_accuracy: 1.0000 - val_loss: 9.2257e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 1.0000 - loss: 1.2664e-04\n",
      "Epoch 85: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2632e-04 - val_accuracy: 1.0000 - val_loss: 8.9690e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.2275e-04\n",
      "Epoch 86: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2244e-04 - val_accuracy: 1.0000 - val_loss: 8.7257e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.1899e-04\n",
      "Epoch 87: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1869e-04 - val_accuracy: 1.0000 - val_loss: 8.4399e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.1542e-04\n",
      "Epoch 88: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1513e-04 - val_accuracy: 1.0000 - val_loss: 8.2277e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.1196e-04\n",
      "Epoch 89: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1167e-04 - val_accuracy: 1.0000 - val_loss: 7.9799e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.0862e-04\n",
      "Epoch 90: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0834e-04 - val_accuracy: 1.0000 - val_loss: 7.7825e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.0543e-04\n",
      "Epoch 91: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0516e-04 - val_accuracy: 1.0000 - val_loss: 7.5834e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 1.0236e-04\n",
      "Epoch 92: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0210e-04 - val_accuracy: 1.0000 - val_loss: 7.3897e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 9.9400e-05\n",
      "Epoch 93: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.9147e-05 - val_accuracy: 1.0000 - val_loss: 7.2906e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 9.6560e-05\n",
      "Epoch 94: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.6315e-05 - val_accuracy: 1.0000 - val_loss: 7.1539e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 9.3838e-05\n",
      "Epoch 95: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.3600e-05 - val_accuracy: 1.0000 - val_loss: 6.9964e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 9.1237e-05\n",
      "Epoch 96: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.1007e-05 - val_accuracy: 1.0000 - val_loss: 6.8289e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 8.8709e-05\n",
      "Epoch 97: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.8485e-05 - val_accuracy: 1.0000 - val_loss: 6.6791e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 8.6292e-05\n",
      "Epoch 98: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.6074e-05 - val_accuracy: 1.0000 - val_loss: 6.5371e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 8.3957e-05\n",
      "Epoch 99: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.3745e-05 - val_accuracy: 1.0000 - val_loss: 6.3870e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 1.0000 - loss: 8.1673e-05\n",
      "Epoch 100: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.1467e-05 - val_accuracy: 1.0000 - val_loss: 6.2334e-04\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "model_training_history = model.fit(x = features_train, \n",
    "                                   y = labels_train, \n",
    "                                   epochs = 100, \n",
    "                                   batch_size = 16,\n",
    "                                   shuffle = True, \n",
    "                                   callbacks=[callbacks],\n",
    "                                   validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2255e125-e7cd-405e-8c76-e0b65d4521a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 30, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf7356f-7d79-42cf-ae47-0377e61ad03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# import datetime as dt\n",
    "\n",
    "# model2_evaluation_history = model.evaluate(features_test, labels_test)\n",
    "\n",
    "# date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "# current_date_time_dt = dt.datetime.now()\n",
    "\n",
    "# current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "# model_evaluation_loss, model_evaluation_accuracy = model2_evaluation_history\n",
    "model_name = \"ResNet+LSTM.h5\"\n",
    "# Saving your Model\n",
    "model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fb82a-1e5f-4c6d-9c47-3fb1cdfd8128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01c47a-eaf7-4edb-89a1-2f81191e9414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa7a3824-c046-4049-aecd-0f49026c4256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725924210.381170 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.386020 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.386860 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.387726 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.388748 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.389956 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.391176 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.392550 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.394114 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.395721 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.397866 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.399964 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.402140 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.404442 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.406674 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.409019 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.411842 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.416507 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.495340 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.505160 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.505708 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.506238 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.506853 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.507456 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.508058 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.508687 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.509298 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.509920 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.510526 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.511164 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.511806 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.512408 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.513046 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.513689 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.514292 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.514937 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.515695 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.516380 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.517068 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.517854 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.518628 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.519463 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.520173 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.520894 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.521741 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.522470 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.523197 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.524030 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.524817 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.525555 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.526579 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.527394 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.528189 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.528945 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.529710 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.530750 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.532131 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.533357 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.550832 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.709681 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.710118 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.710581 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.711054 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.711564 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.712037 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.712507 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.712959 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.713416 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.713889 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.714383 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.714848 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.715312 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.715764 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.716235 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.716744 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.717233 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.717713 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.718245 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.718775 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.719274 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.719766 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.720294 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.720802 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.721327 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.721881 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.722358 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.722909 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.723442 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.723934 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.724517 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.725063 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.725611 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.726195 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.726744 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.727327 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.727941 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.741010 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.762790 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.763269 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.763746 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.764229 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.764714 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.765215 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.765685 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.766155 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.766686 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.767291 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.767903 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.768463 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.769001 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.769531 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.770115 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.770713 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.771258 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.771822 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.772424 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.772996 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.773576 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.774158 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.774752 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.775431 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.776104 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.776817 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.777553 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.778238 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.779144 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.780039 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.780886 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.781654 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.782406 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.783088 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.783911 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.784954 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.785878 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.786823 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.787931 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.849683 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.931550 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.931961 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.932378 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.932776 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.933174 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.933584 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.933988 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.934385 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.934797 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.935210 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.935627 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.936041 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.936439 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.936854 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.937290 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.937710 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.938110 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.938531 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.938944 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.939366 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.939785 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.940204 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.940648 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.941079 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.941491 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.941948 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.942365 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.942846 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.943297 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.943799 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.944244 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.944703 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.945203 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.945781 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.946294 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.946907 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.947529 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.948086 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.948661 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.962338 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.971151 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.971653 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.972117 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.972621 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.973116 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.973580 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.974037 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.974547 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.975069 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.975582 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.976112 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.976630 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.977123 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.977642 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.978165 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.978670 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.979177 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.979671 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.980206 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.980734 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.981338 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.981881 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.982411 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.982957 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.983490 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.984042 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.984581 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.985220 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.985868 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.986508 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.987165 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.987820 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.988496 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.989135 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.990059 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.990916 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924210.991887 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 38s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725924211.578479 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.623844 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.624263 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.624671 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.625095 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.625525 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.625905 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.626297 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.626722 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.627145 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.627565 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.627991 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.628411 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.628816 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.629219 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.629624 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.630020 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.630444 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.630869 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.631252 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.631674 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.632105 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.632494 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.632873 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.633296 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.633728 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.634164 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.634608 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.635071 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.635582 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.636099 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.636616 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.637164 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.637816 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.638380 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.639050 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.639710 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.652430 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.656571 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.657082 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.657635 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.658153 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.658657 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.659179 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.659664 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.660242 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.660776 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.661359 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.661889 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.662468 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.663027 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.663579 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.664086 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.664594 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.665099 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.665614 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.666278 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.666892 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.667406 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.668016 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.668710 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.669311 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.669824 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.670510 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.671194 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.671794 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.672493 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.673174 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.674052 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.675381 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.676379 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.677653 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924211.679255 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725924252.173526 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.174014 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.174432 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.174838 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.175281 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.175747 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.176215 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.176748 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.177291 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.177805 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.178463 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.179273 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.180090 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.180938 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.181808 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.182772 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.183645 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.185650 2766746 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.261859 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.262308 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.262689 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.263060 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.263456 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.263843 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.264245 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.264637 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.265045 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.265452 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.265851 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.266249 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.266661 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.267062 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.267465 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.267879 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.268286 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.268708 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.269133 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.269560 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.269982 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.270417 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.270862 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.271315 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.271755 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.272178 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.272636 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.273096 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.273552 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.273984 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.274458 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.274907 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.275490 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.276141 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.276661 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.277182 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.277690 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.278209 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.278745 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.279310 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.295326 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.328518 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.328868 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.329213 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.329575 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.329926 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.330291 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.330642 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.331002 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.331362 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.331726 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.332085 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.332442 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.332798 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.333152 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.333519 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.333877 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.334235 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.334594 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.334959 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.335321 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.335692 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.336066 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.336439 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.336805 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.337191 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.337588 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.337962 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.338335 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.338717 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.339104 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.339496 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.339870 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.340263 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.340668 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.341088 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.354709 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.355117 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.355497 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.355878 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.356247 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.356622 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.356998 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.357376 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.357766 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.358140 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.358523 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.358909 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.359286 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.359685 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.360076 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.360469 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.360867 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.361259 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.361656 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.362053 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.362448 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.362847 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.363247 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.363639 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.364071 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.364494 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.364894 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.365333 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.365749 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.366167 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.366579 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.366990 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.367414 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.367853 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.368299 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.368786 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.369268 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.369766 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.370237 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.370809 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.396401 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.413642 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.413996 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.414337 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.414678 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.415026 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.415385 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.415736 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.416095 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.416456 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.416813 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.417180 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.417534 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.417898 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.418256 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.418626 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.418996 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.419346 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.419713 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.420055 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.420413 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.420782 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.421151 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.421530 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.421908 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.422293 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.422642 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.422992 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.423363 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.423739 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.424125 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.424547 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.424975 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.425360 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.425764 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.426175 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.426578 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.427046 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.427463 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.427867 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.440828 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.441256 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.441650 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.442067 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.442450 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.442845 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.443241 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.443668 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.444097 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.444517 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.444908 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.445294 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.445667 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.446036 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.446463 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.446839 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.447207 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.447643 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.448049 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.448470 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.448865 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.449261 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.449678 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.450096 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.450511 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.450919 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.451339 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.451752 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.452169 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.452586 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.453022 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.453576 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.454094 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.454628 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.455250 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.455865 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.456346 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.456831 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725924252.652831 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.660540 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.660871 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.661210 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.661550 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.661888 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.662222 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.662573 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.662917 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.663266 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.663615 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.663972 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.664334 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.664695 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.665058 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.665418 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.665806 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.666184 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.666582 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.666956 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.667344 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.667736 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.668130 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.668535 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.668931 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.669325 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.669722 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.670124 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.670546 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.670974 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.671419 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.671875 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.672339 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.672799 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.673289 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.673775 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.674256 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.687465 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.687930 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.688337 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.688717 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.689092 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.689505 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.689915 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.690326 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.690733 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.691155 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.691592 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.692031 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.692423 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.692821 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.693254 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.693705 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.694166 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.694609 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.695100 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.695588 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.696069 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.696570 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.697067 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.697546 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.698031 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.698520 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.699007 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.699421 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.699967 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.700484 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.701007 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.701673 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.702324 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.702931 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.703542 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.704163 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1725924252.704867 2766732 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    }
   ],
   "source": [
    "labels_pred_prob = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae6b7b5f-410e-4ce3-b5ad-15340b106ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99919415e-01, 8.05685995e-05],\n",
       "       [6.47755666e-03, 9.93522465e-01],\n",
       "       [9.99882102e-01, 1.17850403e-04],\n",
       "       [1.27270876e-04, 9.99872684e-01],\n",
       "       [1.11924594e-04, 9.99888062e-01],\n",
       "       [7.55497604e-05, 9.99924421e-01],\n",
       "       [9.99928474e-01, 7.14928756e-05],\n",
       "       [9.99357045e-01, 6.42986619e-04],\n",
       "       [5.66683375e-05, 9.99943376e-01],\n",
       "       [9.95901287e-01, 4.09868918e-03],\n",
       "       [9.99917626e-01, 8.23947994e-05],\n",
       "       [1.03706858e-04, 9.99896288e-01],\n",
       "       [6.61458762e-05, 9.99933839e-01],\n",
       "       [1.02979375e-05, 9.99989748e-01],\n",
       "       [9.99918103e-01, 8.19236229e-05],\n",
       "       [9.99897361e-01, 1.02600061e-04],\n",
       "       [1.11421650e-04, 9.99888539e-01],\n",
       "       [2.90854932e-05, 9.99970913e-01],\n",
       "       [8.39692875e-05, 9.99916077e-01],\n",
       "       [9.99919534e-01, 8.04322626e-05],\n",
       "       [9.99507189e-01, 4.92840074e-04],\n",
       "       [7.12749839e-01, 2.87250161e-01],\n",
       "       [6.57224155e-05, 9.99934316e-01],\n",
       "       [4.33838650e-05, 9.99956608e-01],\n",
       "       [9.96224523e-01, 3.77546181e-03],\n",
       "       [9.99912262e-01, 8.77297571e-05],\n",
       "       [9.99923706e-01, 7.62841228e-05],\n",
       "       [8.42664031e-06, 9.99991536e-01],\n",
       "       [9.99925494e-01, 7.45361176e-05],\n",
       "       [7.94873049e-05, 9.99920487e-01],\n",
       "       [4.51229716e-05, 9.99954820e-01],\n",
       "       [9.99927044e-01, 7.30015672e-05],\n",
       "       [9.03241307e-05, 9.99909639e-01],\n",
       "       [9.99914050e-01, 8.59645006e-05],\n",
       "       [9.99918103e-01, 8.18656772e-05],\n",
       "       [1.00019934e-04, 9.99899983e-01],\n",
       "       [8.31547550e-06, 9.99991655e-01],\n",
       "       [9.82294478e-06, 9.99990225e-01],\n",
       "       [2.33596202e-05, 9.99976635e-01],\n",
       "       [5.35217914e-05, 9.99946475e-01],\n",
       "       [9.99916553e-01, 8.34276725e-05],\n",
       "       [8.91429227e-06, 9.99991059e-01],\n",
       "       [9.99939203e-01, 6.08055052e-05],\n",
       "       [1.54207577e-04, 9.99845743e-01],\n",
       "       [1.37355441e-04, 9.99862671e-01],\n",
       "       [9.99915123e-01, 8.48401542e-05],\n",
       "       [9.99911070e-01, 8.89490184e-05],\n",
       "       [1.87597878e-04, 9.99812424e-01],\n",
       "       [5.00648384e-05, 9.99949932e-01],\n",
       "       [1.10470419e-05, 9.99988914e-01],\n",
       "       [9.99934435e-01, 6.55880503e-05],\n",
       "       [9.19340134e-01, 8.06599259e-02],\n",
       "       [9.99922872e-01, 7.71111008e-05],\n",
       "       [9.99882936e-01, 1.16995070e-04],\n",
       "       [9.22728941e-06, 9.99990821e-01],\n",
       "       [9.99906063e-01, 9.39376696e-05],\n",
       "       [9.99926209e-01, 7.38103336e-05],\n",
       "       [9.99923468e-01, 7.65593795e-05],\n",
       "       [9.99912143e-01, 8.78731807e-05],\n",
       "       [9.99935985e-01, 6.40426006e-05],\n",
       "       [9.99898672e-01, 1.01369194e-04],\n",
       "       [9.99941468e-01, 5.84973059e-05],\n",
       "       [9.99939799e-01, 6.02012551e-05],\n",
       "       [2.69001233e-03, 9.97310042e-01],\n",
       "       [9.99843359e-01, 1.56606489e-04],\n",
       "       [9.99868274e-01, 1.31729350e-04],\n",
       "       [1.02586077e-04, 9.99897361e-01],\n",
       "       [9.99912620e-01, 8.73627650e-05],\n",
       "       [4.03025842e-05, 9.99959707e-01],\n",
       "       [1.27472624e-04, 9.99872565e-01],\n",
       "       [9.99917269e-01, 8.27081822e-05],\n",
       "       [9.99850869e-01, 1.49125728e-04],\n",
       "       [1.43783327e-04, 9.99856234e-01],\n",
       "       [3.50067596e-04, 9.99649882e-01],\n",
       "       [9.99482108e-06, 9.99989986e-01],\n",
       "       [9.99940515e-01, 5.95365382e-05],\n",
       "       [9.99916315e-01, 8.37140906e-05],\n",
       "       [1.13069736e-05, 9.99988675e-01],\n",
       "       [1.05998319e-04, 9.99894023e-01],\n",
       "       [9.99919295e-01, 8.06574608e-05],\n",
       "       [4.70764899e-05, 9.99952912e-01],\n",
       "       [9.99930739e-01, 6.92165486e-05],\n",
       "       [9.99920845e-01, 7.91195562e-05],\n",
       "       [7.73543161e-06, 9.99992251e-01],\n",
       "       [3.10593052e-04, 9.99689460e-01],\n",
       "       [9.99918580e-01, 8.14375890e-05],\n",
       "       [9.99914050e-01, 8.59535139e-05],\n",
       "       [1.10500063e-04, 9.99889493e-01],\n",
       "       [9.99936342e-01, 6.36930636e-05],\n",
       "       [7.86082092e-06, 9.99992132e-01],\n",
       "       [9.99923229e-01, 7.67697857e-05],\n",
       "       [1.84284509e-04, 9.99815762e-01],\n",
       "       [9.99911666e-01, 8.83030079e-05],\n",
       "       [7.42849224e-05, 9.99925733e-01],\n",
       "       [9.99647856e-01, 3.52109142e-04],\n",
       "       [9.99902129e-01, 9.78180469e-05],\n",
       "       [1.79059116e-05, 9.99982119e-01],\n",
       "       [9.11932693e-06, 9.99990940e-01],\n",
       "       [9.99936581e-01, 6.34019380e-05],\n",
       "       [6.68845605e-05, 9.99933124e-01],\n",
       "       [4.03600425e-05, 9.99959588e-01],\n",
       "       [9.99917746e-01, 8.22674556e-05],\n",
       "       [9.99919891e-01, 8.01148199e-05],\n",
       "       [9.99916315e-01, 8.37198386e-05]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d3fa9bf-b963-4ee2-998d-6f04d01b0768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]),\n",
       " array([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred = np.argmax(labels_pred_prob, axis = 1)\n",
    "labels_test = np.argmax(labels_test, axis = 1)\n",
    "labels_pred, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3984063b-21de-4cf8-9487-c34f9d6dc598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  0]\n",
      " [ 1 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_test, labels_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e0e471e-a0cb-47d4-89e3-633a26cc0442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        54\n",
      "           1       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.99       104\n",
      "   macro avg       0.99      0.99      0.99       104\n",
      "weighted avg       0.99      0.99      0.99       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(labels_test, labels_pred)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44fb3dcb-4cbd-4f67-a5bd-585b0c154a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992592592592593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, labels_pred_prob[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "auc_score = roc_auc_score(labels_test, labels_pred_prob[:, 1])\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ed13310-19b8-4087-aea2-1a2ba9647221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.03703704, 0.03703704,\n",
       "        1.        ]),\n",
       " array([0.  , 0.02, 0.98, 0.98, 1.  , 1.  ]),\n",
       " array([          inf, 9.9999225e-01, 9.9352247e-01, 8.0659926e-02,\n",
       "        4.0986892e-03, 5.8497306e-05], dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c6a6fcb-02b6-4256-89b0-3af6c25cf006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca114b0-7fde-4882-8f23-9cc301c3280c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a534861-e555-4a08-9b66-ef9a7bb76362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_metric(measure_name_1, measure_name_2, plot_title):\n",
    "  \n",
    " \n",
    "  measure_value_1 = model_training_history.history[measure_name_1]\n",
    "  measure_value_2 = model_training_history.history[measure_name_2] \n",
    "  epochs = range(len(measure_value_1))\n",
    "\n",
    "  plt.plot(epochs, measure_value_1, 'blue', label = measure_name_1)\n",
    "  plt.plot(epochs, measure_value_2, 'red', label = measure_name_2)   \n",
    "\n",
    "  plt.title(str(plot_title))\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0ed272e-7af6-4ff1-8df1-b92c6139334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('loss', 'val_loss', 'Total Training Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8d88c8b-177e-4fab-a3f7-0be5ae9915dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABP6klEQVR4nO3dd1xTV+MG8CessIeyRBEQqaMiTixaV7V1tNS6qpQKrtqqvK6+rjr7tmrHq7X62tr6c1Vx1Fmt1lHUttY9sLW4F04QkD1Nzu+PkJhAGGHkCjzfzycfwr0n954cE/J4xo1MCCFAREREJBETqStARERENRvDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwhVmCNHjkAmk+HIkSNSV4WqCaleU7dv34ZMJsOaNWs02+bOnQuZTFaqx8tkMsydO7dC69SlSxd06dKlQo9J9LxgGKniZDJZqW6l+WM+f/587Ny5s9LrrO2bb76BTCZDu3btjHpeKlpVe029+eabsLa2RlpaWpFlQkNDYWFhgcTExEqtS3nFxMRg7ty5uH37ttRV0Wvv3r2QyWTw8PCAUqmUujpUjZhJXQEqn3Xr1un8/sMPP+DgwYOFtjdp0qTEY82fPx8DBgzAW2+9VZFVLFZkZCS8vb1x6tQpXL9+HQ0bNjTauUm/qvaaCg0Nxe7du7Fjxw6EhYUV2p+ZmYmffvoJPXv2RO3atct8npkzZ2LatGnlqWqJYmJi8PHHH6NLly7w9vbW2XfgwIFKPXdpqN+vt2/fxqFDh9C9e3epq0TVBMNIFffuu+/q/H7ixAkcPHiw0Pbn0a1bt3Ds2DFs374d77//PiIjIzFnzhypq6VXRkYGbGxspK6GUVS119Sbb74JOzs7bNiwQW8Y+emnn5CRkYHQ0NByncfMzAxmZtL9ybSwsJDs3IDqPfDTTz9hwYIFWL16NSIjI5/bMFKT3q/VBYdpaoCMjAx8+OGH8PT0hFwuR6NGjfDf//4X2l/YLJPJkJGRgbVr12q64YcOHQoAuHPnDsaMGYNGjRrBysoKtWvXxsCBA8vdlRwZGQknJye8/vrrGDBgACIjI/WWS05OxsSJE+Ht7Q25XI569eohLCwMCQkJmjLZ2dmYO3cuXnjhBVhaWqJOnTro168fbty4AaDouQf65gYMHToUtra2uHHjBnr37g07OzvNB9kff/yBgQMHon79+pDL5fD09MTEiRORlZVVqN6XL1/G22+/DRcXF1hZWaFRo0aYMWMGAODw4cOQyWTYsWNHocdt2LABMpkMx48f19seZ86cgUwmw9q1awvt279/P2QyGX7++WcAQFpaGiZMmKBpO1dXV7z66qs4d+6c3mOX1vP0mrKyskK/fv0QFRWF+Pj4Qvs3bNgAOzs7vPnmm0hKSsK///1v+Pv7w9bWFvb29ujVqxcuXLhQ4nn0zRnJycnBxIkT4eLiojnHvXv3Cj22NM93zZo1GDhwIACga9euhYbD9M0ZiY+Px4gRI+Dm5gZLS0sEBAQUel2oX+P//e9/8f3338PX1xdyuRxt27bF6dOnS3zeajt27EBWVhYGDhyIwYMHY/v27cjOzi5UrqT3IgAolUp8/fXX8Pf3h6WlJVxcXNCzZ0+cOXNGp87a70u1gvNx1P8uMTExeOedd+Dk5ISXX34ZAPDXX39h6NChaNCgASwtLeHu7o7hw4frHa67f/8+RowYAQ8PD8jlcvj4+GD06NHIzc3FzZs3IZPJ8NVXXxV63LFjxyCTybBx48ZStyUVxp6Rak4IgTfffBOHDx/GiBEj0KJFC+zfvx+TJ0/G/fv3NW+udevWYeTIkQgMDMSoUaMAAL6+vgCA06dP49ixYxg8eDDq1auH27dv49tvv0WXLl0QExMDa2vrMtUtMjIS/fr1g4WFBUJCQvDtt9/i9OnTaNu2raZMeno6OnbsiEuXLmH48OFo1aoVEhISsGvXLty7dw/Ozs5QKBR44403EBUVhcGDB2P8+PFIS0vDwYMHcfHiRc3zMMTTp0/Ro0cPvPzyy/jvf/+reY5btmxBZmYmRo8ejdq1a+PUqVNYunQp7t27hy1btmge/9dff6Fjx44wNzfHqFGj4O3tjRs3bmD37t2YN28eunTpAk9PT0RGRqJv376F2sXX1xdBQUF669amTRs0aNAAP/74I8LDw3X2bd68GU5OTujRowcA4IMPPsDWrVsRERGBpk2bIjExEUePHsWlS5fQqlUrg9sFeD5fU6GhoVi7di1+/PFHREREaLYnJSVh//79CAkJgZWVFf755x/s3LkTAwcOhI+PD+Li4vDdd9+hc+fOiImJgYeHh0HnHTlyJNavX4933nkH7du3x6FDh/D6668XKlea59upUyeMGzcOS5YswUcffaQZBitqOCwrKwtdunTB9evXERERAR8fH2zZsgVDhw5FcnIyxo8fr1N+w4YNSEtLw/vvvw+ZTIYvvvgC/fr1w82bN2Fubl7ic42MjETXrl3h7u6OwYMHY9q0adi9e7cmQAEo9XtxxIgRWLNmDXr16oWRI0fi6dOn+OOPP3DixAm0adOm1O2vbeDAgfDz88P8+fM1ofjgwYO4efMmhg0bBnd3d/zzzz/4/vvv8c8//+DEiROacPngwQMEBgYiOTkZo0aNQuPGjXH//n1s3boVmZmZaNCgATp06IDIyEhMnDixULvY2dmhT58+Zao35RNUrYwdO1Zo/7Pu3LlTABCffvqpTrkBAwYImUwmrl+/rtlmY2MjwsPDCx0zMzOz0Lbjx48LAOKHH37QbDt8+LAAIA4fPlxiPc+cOSMAiIMHDwohhFAqlaJevXpi/PjxOuVmz54tAIjt27cXOoZSqRRCCLFq1SoBQCxatKjIMkXV7datWwKAWL16tWZbeHi4ACCmTZtW6Hj62mLBggVCJpOJO3fuaLZ16tRJ2NnZ6WzTro8QQkyfPl3I5XKRnJys2RYfHy/MzMzEnDlzCp1H2/Tp04W5ublISkrSbMvJyRGOjo5i+PDhmm0ODg5i7NixxR6rJFXhNfX06VNRp04dERQUpLN9+fLlAoDYv3+/EEKI7OxsoVAodMrcunVLyOVy8Z///EdnW8HXxZw5c3TaITo6WgAQY8aM0TneO++8IwDo/BuW9vlu2bKlyOfbuXNn0blzZ83vixcvFgDE+vXrNdtyc3NFUFCQsLW1FampqTrPpXbt2jqvl59++kkAELt37y50roLi4uKEmZmZWLFihWZb+/btRZ8+fXTKlea9eOjQIQFAjBs3rsgy+tpfrWDbqv9dQkJCCpXV1+4bN24UAMTvv/+u2RYWFiZMTEzE6dOni6zTd999JwCIS5cuafbl5uYKZ2dnva9xMgyHaaq5vXv3wtTUFOPGjdPZ/uGHH0IIgV9++aXEY1hZWWnu5+XlITExEQ0bNoSjo2OZu/sjIyPh5uaGrl27AlB1vQ4aNAibNm2CQqHQlNu2bRsCAgIK9R6oH6Mu4+zsjH/9619FlimL0aNHF9qm3RYZGRlISEhA+/btIYTA+fPnAQCPHz/G77//juHDh6N+/fpF1icsLAw5OTnYunWrZtvmzZvx9OnTEudnDBo0CHl5edi+fbtm24EDB5CcnIxBgwZptjk6OuLkyZN48OBBKZ91yZ7H15SpqSkGDx6M48eP6wx9bNiwAW5ubujWrRsAQC6Xw8RE9WdPoVAgMTERtra2aNSokcHn3bt3LwAUaocJEyYUKlsZ76G9e/fC3d0dISEhmm3m5uYYN24c0tPT8dtvv+mUHzRoEJycnDS/d+zYEQBw8+bNEs+1adMmmJiYoH///pptISEh+OWXX/DkyRPNttK8F7dt2waZTKZ3flh53q8ffPBBoW3a7Z6dnY2EhAS89NJLAKBpd6VSiZ07dyI4OFhvr4y6Tm+//TYsLS11hpP379+PhISE53Y+VVXCMFLN3blzBx4eHrCzs9PZru76vXPnTonHyMrKwuzZszXzA5ydneHi4oLk5GSkpKQYXCeFQoFNmzaha9euuHXrFq5fv47r16+jXbt2iIuLQ1RUlKbsjRs30KxZs2KPd+PGDTRq1KhCJxeamZmhXr16hbbHxsZi6NChqFWrFmxtbeHi4oLOnTsDgKYt1H/cS6p348aN0bZtW50/bpGRkXjppZdKXFUUEBCAxo0bY/PmzZptmzdvhrOzM1555RXNti+++AIXL16Ep6cnAgMDMXfu3FJ9+BTneXxNAdDM69mwYQMA4N69e/jjjz8wePBgmJqaAlB98Hz11Vfw8/PTOe9ff/1l8Hnv3LkDExOTQsOAjRo1KlS2Mp7vnTt34OfnpwlXakX9OxQMxupgoh0mirJ+/XoEBgYiMTFR835t2bIlcnNzdYYnS/NevHHjBjw8PFCrVq0Sz2sIHx+fQtuSkpIwfvx4uLm5wcrKCi4uLppy6nZ//PgxUlNTS3y/Ojo6Ijg4WPP6AlTv17p16+q856hsOGeESvSvf/0Lq1evxoQJExAUFAQHBwfIZDIMHjy4TNcaOHToEB4+fIhNmzZh06ZNhfZHRkbitddeq4iqaxT1Py7tXhht2v+D1i776quvIikpCVOnTkXjxo1hY2OD+/fvY+jQoWVqi7CwMIwfPx737t1DTk4OTpw4gf/973+leuygQYMwb948JCQkwM7ODrt27UJISIjOB8Hbb7+Njh07YseOHThw4AC+/PJLfP7559i+fTt69eplcH0rSkW/pgCgdevWaNy4MTZu3IiPPvoIGzduhBBCZxXN/PnzMWvWLAwfPhyffPIJatWqBRMTE0yYMKFSr5tRGc/XUOpAVpDQmnSsz7Vr1zQTXf38/Artj4yM1MwJqiiGvl8B3V4QtbfffhvHjh3D5MmT0aJFC9ja2kKpVKJnz55lfr9u2bIFx44dg7+/P3bt2oUxY8YU+ltBhmMYqea8vLzw66+/Ii0tTed/spcvX9bsVyvqD8DWrVsRHh6OhQsXarZlZ2cjOTm5THWKjIyEq6srli1bVmjf9u3bsWPHDixfvhxWVlbw9fXFxYsXiz2er68vTp48iby8vCIn4qn/F1iwzqX5X7za33//jatXr2Lt2rU6S0gPHjyoU65BgwYAUGK9AWDw4MGYNGkSNm7ciKysLJibm+sMsxRn0KBB+Pjjj7Ft2za4ubkhNTUVgwcPLlSuTp06GDNmDMaMGYP4+Hi0atUK8+bNK3MYeR5fU2qhoaGYNWsW/vrrL2zYsAF+fn46E6K3bt2Krl27YuXKlTqPS05OhrOzs0Hn8vLyglKp1PQGqF25cqVQ2dI+X0OGKby8vPDXX39BqVTqfBjq+3coj8jISJibm2PdunWFAs3Ro0exZMkSxMbGon79+qV6L/r6+mL//v1ISkoqsnekIt6vT548QVRUFD7++GPMnj1bs/3atWs65VxcXGBvb1+q92vPnj3h4uKCyMhItGvXDpmZmRgyZEip60RFY5yr5nr37g2FQlHof9tfffUVZDKZzgeSjY2N3g8DU1PTQv97Wrp0abH/SylKVlYWtm/fjjfeeAMDBgwodIuIiEBaWhp27doFAOjfvz8uXLigdwmsuk79+/dHQkKC3h4FdRkvLy+Ympri999/19n/zTfflLru6j/E2m0hhMDXX3+tU87FxQWdOnXCqlWrEBsbq7c+as7OzujVqxfWr1+PyMhI9OzZs9Qfik2aNIG/vz82b96MzZs3o06dOujUqZNmv0KhKDQE4OrqCg8PD+Tk5JTqHPo8b68pbepekNmzZyM6OrrQtUX0nXfLli24f/++wedSP88lS5bobF+8eHGhsqV9vuprY5QmlPXu3RuPHj3SGap7+vQpli5dCltbW83wYXlFRkaiY8eOGDRoUKH36+TJkwFAs6y1NO/F/v37QwiBjz/+uMgy9vb2cHZ2rvD3K1D438fExARvvfUWdu/erVlarK9OgGr4NiQkBD/++CPWrFkDf39/NG/evNR1oqKxZ6SaCw4ORteuXTFjxgzcvn0bAQEBOHDgAH766SdMmDBBZ7y7devW+PXXX7Fo0SJ4eHjAx8cH7dq1wxtvvIF169bBwcEBTZs2xfHjx/Hrr7+W6WqWu3btQlpaGt588029+1966SXN/zwGDRqEyZMnY+vWrRg4cCCGDx+O1q1bIykpCbt27cLy5csREBCAsLAw/PDDD5g0aRJOnTqFjh07IiMjA7/++ivGjBmDPn36wMHBAQMHDsTSpUshk8ng6+uLn3/+We91KYrSuHFj+Pr64t///jfu378Pe3t7bNu2Te+Y+5IlS/Dyyy+jVatWGDVqFHx8fHD79m3s2bMH0dHROmXDwsIwYMAAAMAnn3xS+saEqndk9uzZsLS0xIgRI3T+h5yWloZ69ephwIABCAgIgK2tLX799VecPn1a53/ohnreXlPafHx80L59e/z0008AUCiMvPHGG/jPf/6DYcOGoX379vj7778RGRmp6c0yRIsWLRASEoJvvvkGKSkpaN++PaKionD9+vVCZUv7fFu0aAFTU1N8/vnnSElJgVwuxyuvvAJXV9dCxxw1ahS+++47DB06FGfPnoW3tze2bt2KP//8E4sXLy40p6csTp48qVk6rE/dunXRqlUrREZGYurUqaV6L3bt2hVDhgzBkiVLcO3aNc2QyR9//IGuXbtqzjVy5Eh89tlnGDlyJNq0aYPff/8dV69eLXXd7e3t0alTJ3zxxRfIy8tD3bp1ceDAAdy6datQ2fnz5+PAgQPo3LkzRo0ahSZNmuDhw4fYsmULjh49CkdHR03ZsLAwLFmyBIcPH8bnn39uWINS0Yy8eocqWcFlmEIIkZaWJiZOnCg8PDyEubm58PPzE19++aXOMlMhhLh8+bLo1KmTsLKyEgA0y9WePHkihg0bJpydnYWtra3o0aOHuHz5svDy8tJZ0laaZZjBwcHC0tJSZGRkFFlm6NChwtzcXCQkJAghhEhMTBQRERGibt26wsLCQtSrV0+Eh4dr9guhWsI3Y8YM4ePjI8zNzYW7u7sYMGCAuHHjhqbM48ePRf/+/YW1tbVwcnIS77//vrh48aLepb02NjZ66xYTEyO6d+8ubG1thbOzs3jvvffEhQsX9C5DvHjxoujbt69wdHQUlpaWolGjRmLWrFmFjpmTkyOcnJyEg4ODyMrKKrJd9Ll27ZoAIACIo0ePFjru5MmTRUBAgLCzsxM2NjYiICBAfPPNNwad43l/TRW0bNkyAUAEBgYW2pednS0+/PBDUadOHWFlZSU6dOggjh8/XmjZbGmW9gohRFZWlhg3bpyoXbu2sLGxEcHBweLu3buFlp+W9vkKIcSKFStEgwYNhKmpqc5zL1hHIVRLbtXHtbCwEP7+/oVeh+rn8uWXXxZqj4L1LOhf//qXAKDzPipo7ty5AoC4cOGCEKJ078WnT5+KL7/8UjRu3FhYWFgIFxcX0atXL3H27FlNmczMTDFixAjh4OAg7OzsxNtvvy3i4+OLXNr7+PHjQnW7d++e5j3o4OAgBg4cKB48eKD3ed+5c0eEhYUJFxcXIZfLRYMGDcTYsWNFTk5OoeO++OKLwsTERNy7d6/IdiHDyIQoYfYSEVWqp0+fwsPDA8HBwYXmMhDR86dly5aoVauWzso/Kh/OGSGS2M6dO/H48WO936tCRM+XM2fOIDo6mu/XCsaeESKJnDx5En/99Rc++eQTODs7l/v7Yoio8ly8eBFnz57FwoULkZCQgJs3b8LS0lLqalUb7Bkhksi3336L0aNHw9XVFT/88IPU1SGiYmzduhXDhg1DXl4eNm7cyCBSwdgzQkRERJJizwgRERFJimGEiIiIJFUlLnqmVCrx4MED2NnZletbHYmIiMh4hBBIS0uDh4dHsd/hUyXCyIMHD+Dp6Sl1NYiIiKgM7t69q/eb0NWqRBhRX9b47t27sLe3l7g2REREVBqpqanw9PQs8esJqkQYUQ/N2NvbM4wQERFVMSVNseAEViIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERScrgMPL7778jODgYHh4ekMlk2LlzZ4mPOXLkCFq1agW5XI6GDRtizZo1ZagqERERVUcGh5GMjAwEBARg2bJlpSp/69YtvP766+jatSuio6MxYcIEjBw5Evv37ze4skRERFT9GPxFeb169UKvXr1KXX758uXw8fHBwoULAQBNmjTB0aNH8dVXX6FHjx56H5OTk4OcnBzN76mpqYZWs/o4fRrYuBFQKg1/bLduQHBwqYtnZADffAN06AC0b1+6xwgB7N4NHD6sug8AMqFE5/OL4ZQWa3idiYhIEr5LJ6Dey97SnFyUAwCxY8eOYst07NhRjB8/XmfbqlWrhL29fZGPmTNnjgBQ6JaSklKe6lY92dlC1KsnhOpz3vCbmZkQd+6U+nSTJz97aK9eQpw5U3RZpVKIffuEaNOm8GmHYG3Z68wbb7zxxpskt79XHK+ADy5dKSkpojSf3wb3jBjq0aNHcHNz09nm5uaG1NRUZGVlwcrKqtBjpk+fjkmTJml+T01NhaenZ2VX9fmzZg1w7x7g7g4MH67ZnJICWFoBcouiH5q3cw/MYy4gbtLnuD1ZNaRmZQX4+wP6vsk5Lw9Yu/bZ77/8orr17QtERAA2Ns/2PX4MfP45cPSo6ncbGyAsDHByAmRKBcZ/Pw9IAmJeeAvxzk3L0QBERGQsfi96SHbuSg8jZSGXyyGXy6WuhrTy8oAFC1T3p08Hxo1DTAwwZw6wdSvg6AhMngyMGwfY2j572O3bwCefALcvv4oodIXjtv9Dv20f4QHqAgAWLgS0cp7Gzz8D8fGAmxtw5Agwbx4QGQns2KG66SOXA2PHAlOnAq6u+Rs3bQGSrgK1aqHpmR/Q1M6ughqEiIiqq0pf2uvu7o64uDidbXFxcbC3t9fbK0L51q0D7twB3Nxw45X3MGQI0KyZKogAQHIyMGMG0KABsGgRcOOGKhi88AKwahVwSNkZp+QvQ45cfGr/JerVUz1uwQLV3JCCVq5U/Rw6FGjcWHX6ixeBQYMAHx/dm68vMGaM6pwLF2oFEaUS+PRT1f0JEwAGESIiKo3yjAUBJc8ZmTJlimjWrJnOtpCQENGjR49Sn6e0Y05V3c2bQrRtK4SfT564beYrBCDm1/pSmJo+G9br10+ICxeEiIwUomFD/UN/3bsLcfy4EGL/ftUGS0uRd++R8FUdUixapHvee/eEMDFR7btypRxPYOtW1UHs7YV48qQcByIiouqgtJ/fBveMpKenIzo6GtHR0QBUS3ejo6MRG6taOTF9+nSEhYVpyn/wwQe4efMmpkyZgsuXL+Obb77Bjz/+iIkTJ1ZAlKo+hFBNCzl9Ggi8tQleT28gAbUxL+kDKBRA797AmTPAtm1A8+bAO+8Aly6pejTq11cdo0MH1aqWgweBl14C8OqrQGAgkJ0Ns68XYvp0VbkvvwSys5+de80aVadGx46qnpUyPwF1r8i4capxJCIiotIwNOUcPnxYAIVXuoSHhwshhAgPDxedO3cu9JgWLVoICwsL0aBBA7F69WqDzlkTeka+/17VqWBj+VSkeTYWAhB3Ppgvjh8X4urV4h+bkyPE5cuqFS6F/Pxz/oFtRM79x8LTU/XrsmWq3QqFEA0aqLatWVOOJ7Brl+ogtrZCJCSU40BERFRdlPbzWyaEEBJmoVJJTU2Fg4MDUlJSYG9vL3V1Ktz9+0DTpkBqKrB7yI94Y90g1dKU27eB8j5fIYA2bYBz54AZM7CszqeIiFD1ply7ploR062b6jQPHuiumjHoHO3aqbp1pk4FPvusfHUmIqJqobSf38/laprnXnw8YG6uCgxFefwY+OefEg8lBPDtLKBlKtCkMfD6+U9UO8aPL38QAVTreGfOBPr1A5YswcgNnRHlZI6kWODXmaqM0hnAm50Bm9NlPEdMjCqIWFnpX6pDRERUDPaMGCopSTWxwtlZ9SFsomfazdOngLe3qsujLOzsVCtpigs7hlAqgYAA1fKYyjRxomppDxEREdgzUnmOHAESE1W3ixdVs0kLOndOFUTMzQE/vyIP9VQBXL8OKBSAiwvg6gLA1FT1oV5RQQRQBab//U/Va5GdDYVSNUSjUKh2W8qBBr6AnmuhlZ67OzQzZImIiAzAMGKo33/Xva8vjKjL9OwJ7NpV5KFGDgXWXgGaNAHOnwdQmdd569wZOHsWAGAKYNs81egNAHz9hWoBDBERkRQq/aJn1c5vv+m/r69M585FHubAAdXl12Uy1fJcY19wNiJCdbVVJycgNNS45yYiItLGnhFDJCcDFy48+/3331UzULW/7EWhAP74Q3W/Uye9h0lPB0aNUt2PiACCgiqnusVxcFA9FYUCqF3b+OcnIiJSY8+IIY4eVYUPb29VV0Z8PHDlim6Zv/9WfZOdrS3QsqXew8ycqZqf6uUFzJ9f+dUuipsb4CHd9yIREREBYBgxjHr4pXv3/EucQncOiXaZDh0As8IdT8ePA0uWqO5/953ul9wRERHVRAwjhlAHj86dn80HKThvRLtMATk5wMiRqs6VsDCgR49KrCsREVEVwTkjpZWWplmNgk6dgDp1VPd/++3ZvBEhnoURPfNFFixQXZrExYWX4yAiIlJjGCmt48dVsz29vVXXUnd2Vg3D3L8P3LoFNGigShoJCaorkbZtq/PwmJhn80P+9z9OGiUiIlLjME1pqYdj1D0e1tbPAoe6N0T9MygIsLDQefj//R+Ql6f69t2BA41QXyIioiqCYaS09F07pOC8kYKBRcuBA6qfYWG6K4GJiIhqOoaR0sjKAk6dUt3XDhrqMKK+3kgRk1fv3VN9Z55MplqIQ0RERM8wjJTGiROqMRYPD8DX99n29u1V3/ty86bqO2sePlQNz7Rrp/Nwda9I27acK0JERFQQw0hpaPd4aI+x2NsDrVqp7n/yiepnYKBqAquW/ftVP7mUl4iIqDCGkdIoZi6IZtvhw3rLKBTAwYOq+wwjREREhTGMlCQnR7WsF9D/xXcFtxX4/cwZ4MkT1XfBFBi9ISIiIjCMlOzMGSA7W3WlssaNC+/v2PHZ0I2pqWoeiRb1EE23bnqvDk9ERFTjMYyURHuIRt+aXCcnKJv5AwBEq9aFvmyG80WIiIiKxzBSkuho1c+goCKLHLNVJY2f817T2Z6cDJw8qbrPMEJERKQfBw5KkpGh+lmrVpFFPsqZg/pojm3R/fFzlGpIBgAOHVJNYG3UCPDyMkJdiYiIqiD2jJQkM1P109pa7+60NODYBRtE4l1kwwrvvfcsv3CIhoiIqGQMIyUpIYyovz+vbl3A01P1nXmzZ6suyMowQkREVDKGkZJkZal+FriQmZr6emjdugHLl6vuL14MrF8P3LmjuiCrvhXBREREpMIwUpISekbUYaRTJ9U38oaGAkolMHy4anvHjoCNjRHqSUREVEUxjJREHUb09IxkZz9bLaO+8OrixYCzM/D0qep3DtEQEREVj2GkJOphGj09I6dOAbm5gLs70LChapuzM7BkybMyDCNERETF49LekhQzTKM9RKN9PbTBg4ErV1RBxd/fCHUkIiKqwhhGiqNQqBIFoHeYRjuMaJPJgLlzK7dqRERE1QWHaYqjHqIBCvWM5OUBx46p7nO1DBERUdkxjBRHPUQDAJaWOrvOn1dd3KxWLaBpUyPXi4iIqBphGCmOumfE0hIw0W0q9RBNx46FdhEREZEB+DFanFJOXiUiIqKyYxgpThHXGFEqgT/+UN1nGCEiIiofhpHiFHGNkYsXgeRkwNYWaNHC6LUiIiKqVhhGilPEMI16iKZDB8CMi6OJiIjKhWGkOEUM03C+CBERUcVhGCmOnmEaIRhGiIiIKhLDSHH0DNPcuwfExQHm5kDbthLVi4iIqBphGCmOnmGahw9VP+vUAeRyCepERERUzTCMFEfPMM2jR6qfbm4S1IeIiKgaYhgpjp5hGnUYcXeXoD5ERETVEMNIcdQ9I1rDNHFxqp/sGSEiIqoYDCPFYc8IERFRpWMYKY6eCazqnhGGESIioorBMFIcTmAlIiKqdAwjxeEwDRERUaVjGCkOh2mIiIgqHcNIcQoM06Snq24Ah2mIiIgqCsNIcQoM06h7RaytAVtbiepERERUzTCMFKfAdUa0rzEik0lUJyIiomqGYaQ4BXpGOHmViIio4jGMFKfABFaGESIioorHMFKcAhNYeSl4IiKiiscwUhQhOExDRERkBAwjRcnNBZRK1f0CwzTsGSEiIqo4DCNFUQ/RAIWGadgzQkREVHEYRoqiHqIxNQXMzQFwmIaIiKgyMIwURXsljUwGITiBlYiIqDIwjBSlwEqa1FQgO1u1iWGEiIio4jCMFKWIa4zY2+t8iS8RERGVE8NIUXiNESIiIqNgGCkKrzFCRERkFAwjRSlimIY9I0RERBWLYaQoRQzTsGeEiIioYpUpjCxbtgze3t6wtLREu3btcOrUqSLL5uXl4T//+Q98fX1haWmJgIAA7Nu3r8wVNhoO0xARERmFwWFk8+bNmDRpEubMmYNz584hICAAPXr0QHx8vN7yM2fOxHfffYelS5ciJiYGH3zwAfr27Yvz58+Xu/KVisM0RERERmFwGFm0aBHee+89DBs2DE2bNsXy5cthbW2NVatW6S2/bt06fPTRR+jduzcaNGiA0aNHo3fv3li4cGG5K1+pOExDRERkFAaFkdzcXJw9exbdu3d/dgATE3Tv3h3Hjx/X+5icnBxYWlrqbLOyssLRo0eLPE9OTg5SU1N1bkbHnhEiIiKjMCiMJCQkQKFQwK3AJ7KbmxseqT+tC+jRowcWLVqEa9euQalU4uDBg9i+fTsePnxY5HkWLFgABwcHzc3T09OQalYMrTkjSiWgHoVizwgREVHFqvTVNF9//TX8/PzQuHFjWFhYICIiAsOGDYOJSdGnnj59OlJSUjS3u3fvVnY1C9MapnnyBMjLU/3q6mr8qhAREVVnBoURZ2dnmJqaIk49gSJfXFwc3IvoMnBxccHOnTuRkZGBO3fu4PLly7C1tUWDBg2KPI9cLoe9vb3Ozei0hmnUnT5OToBcbvyqEBERVWcGhRELCwu0bt0aUVFRmm1KpRJRUVEICgoq9rGWlpaoW7cunj59im3btqFPnz5lq7GxaPWMcPIqERFR5TEz9AGTJk1CeHg42rRpg8DAQCxevBgZGRkYNmwYACAsLAx169bFggULAAAnT57E/fv30aJFC9y/fx9z586FUqnElClTKvaZVDStOSO8xggREVHlMTiMDBo0CI8fP8bs2bPx6NEjtGjRAvv27dNMao2NjdWZD5KdnY2ZM2fi5s2bsLW1Re/evbFu3To4OjpW2JOoFNrDNPlzbbmShoiIqOIZHEYAICIiAhEREXr3HTlyROf3zp07IyYmpiynkRaHaYiIiIyC301TFD0TWNkzQkREVPEYRorCOSNERERGwTBSFA7TEBERGQXDSFE4TENERGQUDCNFye8ZUcit8fixahN7RoiIiCoew4g+SiWQnQ0ASMxSfTeNTAa4uEhcLyIiomqIYUQf9XwRAHGpqm/tdXYGzMq0EJqIiIiKwzCij1YYeZisCiMcoiEiIqocDCP6qCevWljg0WNTAJy8SkREVFkYRvThNUaIiIiMhmFEH15jhIiIyGgYRvThNUaIiIiMhmFEH61hmpQU1V0nJ+mqQ0REVJ0xjOijNUyTkaG6a2MjXXWIiIiqM4YRfbSGadLTVXdtbaWrDhERUXXGMKKPVs8IwwgREVHlYhjRhz0jRERERsMwoo/WBFaGESIiosrFMKKPngmsDCNERESVg2FEn/yeEYWFFfLyVJu4moaIiKhyMIzokx9Gcs2sNZsYRoiIiCoHw4g++cM0OaaqMGJhoboRERFRxWMY0Se/ZyRbZgWA80WIiIgqE8OIPuowYqLqGWEYISIiqjwMI/rkD9NkQdUzwvkiRERElYdhRJ/8npEMwZ4RIiKiysYwok9+zwjDCBERUeVjGNEnv2ckXcEJrERERJWNYUSf/DCS+pQ9I0RERJWNYUSf/GGaNAXDCBERUWVjGNEnv2ckJZeraYiIiCobw4g++WEkOZc9I0RERJWNYaSgvDxAoQAAPMlhGCEiIqpsDCMF5feKAMCTbK6mISIiqmwMIwWpw4hMhuQsOQCGESIiosrEMFJQ/koaWFkhPUMGgGGEiIioMjGMFKTuGbG2Rnq66i5X0xAREVUehpGC1D0jWmGEPSNERESVh2GkIHXPiJUVwwgREZERMIwUpDVMk5GhusswQkREVHkYRgrKH6YRHKYhIiIyCoaRgvJ7RpQWVhBCtYkTWImIiCoPw0hB+WHkqYW1ZpO1dVGFiYiIqLwYRgrKH6bJM1NdfdXaGjA1lbJCRERE1RvDSEH5PSO5ZvxeGiIiImNgGCkov2eEYYSIiMg4GEYKyu8ZyZbxS/KIiIiMgWGkoPwwkmWi6hnhShoiIqLKxTBSUP4wTRY4TENERGQMDCMF5feMZAoO0xARERkDw0hB+WEkQ7BnhIiIyBgYRgrKH6ZJV7BnhIiIyBgYRgrK7xlJU3ACKxERkTEwjBSUH0ZSn3KYhoiIyBgYRgrKH6ZJyeUwDRERkTEwjBSU3zOSkseeESIiImNgGCkov2fkSQ7DCBERkTEwjBSU3zPyJJvDNERERMbAMKJNCE3PSFI2V9MQEREZA8OItuxszd3ETPaMEBERGQPDiLb8IRoASMhgGCEiIjIGhhFt6jBibo6UTHMADCNERESVjWFEW/58EWFlpb7LMEJERFTJGEa05feMCCtrzSZOYCUiIqpcDCPa0tIAAEorVQIxMQEsLaWsEBERUfXHMKItNhYAkOtaD4BqiEYmk7JCRERE1V+ZwsiyZcvg7e0NS0tLtGvXDqdOnSq2/OLFi9GoUSNYWVnB09MTEydORLbWMtrnxp07AIAsVy8AnC9CRERkDAaHkc2bN2PSpEmYM2cOzp07h4CAAPTo0QPx8fF6y2/YsAHTpk3DnDlzcOnSJaxcuRKbN2/GRx99VO7KV7j8MJLu7A2AYYSIiMgYDA4jixYtwnvvvYdhw4ahadOmWL58OaytrbFq1Sq95Y8dO4YOHTrgnXfegbe3N1577TWEhISU2Jsiidu3AQCpjuwZISIiMhaDwkhubi7Onj2L7t27PzuAiQm6d++O48eP631M+/btcfbsWU34uHnzJvbu3YvevXsXeZ6cnBykpqbq3Iwiv2ckyU4VRriShoiIqPKZGVI4ISEBCoUCbm5uOtvd3Nxw+fJlvY955513kJCQgJdffhlCCDx9+hQffPBBscM0CxYswMcff2xI1cpPCE0YeWzjDYA9I0RERMZQ6atpjhw5gvnz5+Obb77BuXPnsH37duzZsweffPJJkY+ZPn06UlJSNLe7d+9WdjWB+HjVd9PIZIiXewJgGCEiIjIGg3pGnJ2dYWpqiri4OJ3tcXFxcHd31/uYWbNmYciQIRg5ciQAwN/fHxkZGRg1ahRmzJgBE5PCeUgul0MulxtStfLL7xVBnTpIzbYAwDBCRERkDAb1jFhYWKB169aIiorSbFMqlYiKikJQUJDex2RmZhYKHKampgAAIYSh9a086jDi5YX0dNVdhhEiIqLKZ1DPCABMmjQJ4eHhaNOmDQIDA7F48WJkZGRg2LBhAICwsDDUrVsXCxYsAAAEBwdj0aJFaNmyJdq1a4fr169j1qxZCA4O1oSS50L+Shp4e2vCCCewEhERVT6Dw8igQYPw+PFjzJ49G48ePUKLFi2wb98+zaTW2NhYnZ6QmTNnQiaTYebMmbh//z5cXFwQHByMefPmVdyzqAjaPSOPVXfZM0JERFT5ZOK5GivRLzU1FQ4ODkhJSYG9vX3lnCQ4GPj5Z+DbbzH4yAfYvBlYvBgYP75yTkdERFTdlfbzm99No6buGfH2RkaG6i57RoiIiCofwwigusaIes4IJ7ASEREZFcMIACQnA2lpqvv16zOMEBERGRHDCPBsiMbFBbCx4WoaIiIiI2IYAXSGaACwZ4SIiMiIGEYAnWW9ADiBlYiIyIgYRgCdlTQAe0aIiIiMiWEE0OkZyc0F8vJUvzKMEBERVT6GEUDvsl6AE1iJiIiMgWEE0PsleRYWgLm5dFUiIiKqKRhG0tOBxETVfS8vTl4lIiIyMoYRda+IgwPg6MjJq0REREbGMFJgWS/DCBERkXExjHBZLxERkaQYRoq4+ipX0hARERkHwwivvkpERCQphhEO0xAREUmKYYQTWImIiCRVs8NIdjbw8KHqPsMIERGRJGp2GLl7V/XTygpwdgbACaxERETGVrPDiPZ8EZkMAHtGiIiIjK1mh5ECy3oBrqYhIiIytpodRgpMXgXYM0JERGRsDCOAZlkvwDBCRERkbDU7jOgZpmEYISIiMi4zqSsgKT8/ICkJ8PXVbOJqGiIiIuOq2WFk5cpCmziBlYiIyLhq9jCNHhymISIiMi6GES1CMIwQEREZG8OIlqwsVSABGEaIiIiMhWFEi7pXBACsraWrBxERUU3CMKJFPXnV2howYcsQEREZBT9ytXC+CBERkfExjGjhNUaIiIiMj2FES3a26qeVlbT1ICIiqkkYRrRkZal+MowQEREZD8OIFnXPiKWltPUgIiKqSRhGtDCMEBERGR/DiBaGESIiIuNjGNHCOSNERETGxzCihT0jRERExscwooVhhIiIyPgYRrTwOiNERETGxzCiRT1nhD0jRERExsMwooXDNERERMbHMKKFYYSIiMj4GEa0cGkvERGR8TGMaGHPCBERkfExjGhhGCEiIjI+hhEtDCNERETGxzCihXNGiIiIjI9hRAt7RoiIiIyPYUQLwwgREZHxMYxo4eXgiYiIjI9hRAsvB09ERGR8DCNaOExDRERkfAwjWhhGiIiIjI9hJJ8QnDNCREQkBYaRfDk5z+6zZ4SIiMh4GEbyqXtFAIYRIiIiY2IYyacOIzIZYG4ubV2IiIhqEoaRfNqXgpfJpK0LERFRTcIwko8raYiIiKTBMJKPYYSIiEgaDCP5uKyXiIhIGgwj+XgpeCIiImkwjOTjMA0REZE0yhRGli1bBm9vb1haWqJdu3Y4depUkWW7dOkCmUxW6Pb666+XudKVgWGEiIhIGgaHkc2bN2PSpEmYM2cOzp07h4CAAPTo0QPx8fF6y2/fvh0PHz7U3C5evAhTU1MMHDiw3JWvSNpLe4mIiMh4DA4jixYtwnvvvYdhw4ahadOmWL58OaytrbFq1Sq95WvVqgV3d3fN7eDBg7C2ti42jOTk5CA1NVXnVtnYM0JERCQNg8JIbm4uzp49i+7duz87gIkJunfvjuPHj5fqGCtXrsTgwYNhY2NTZJkFCxbAwcFBc/P09DSkmmXCMEJERCQNg8JIQkICFAoF3NzcdLa7ubnh0aNHJT7+1KlTuHjxIkaOHFlsuenTpyMlJUVzu3v3riHVLBOGESIiImmYGfNkK1euhL+/PwIDA4stJ5fLIZfLjVQrFc4ZISIikoZBPSPOzs4wNTVFXFyczva4uDi4u7sX+9iMjAxs2rQJI0aMMLyWRsCeESIiImkYFEYsLCzQunVrREVFabYplUpERUUhKCio2Mdu2bIFOTk5ePfdd8tW00rGMEJERCQNg4dpJk2ahPDwcLRp0waBgYFYvHgxMjIyMGzYMABAWFgY6tatiwULFug8buXKlXjrrbdQu3btiql5BePl4ImIiKRhcBgZNGgQHj9+jNmzZ+PRo0do0aIF9u3bp5nUGhsbCxMT3Q6XK1eu4OjRozhw4EDF1LoS8HLwRERE0ijTBNaIiAhERETo3XfkyJFC2xo1agQhRFlOZTQcpiEiIpIGv5smH8MIERGRNBhG8nFpLxERkTQYRvKxZ4SIiEgaDCP5GEaIiIikwTCSj2GEiIhIGgwj+ThnhIiISBoMI/nYM0JERCQNhpF8DCNERETSYBjJx8vBExERSYNhJB8vB09ERCQNhhEAQgA5Oar7DCNERETGxTCCZ0EEYBghIiIyNoYRPBuiAThnhIiIyNgYRvBs8qqJCWBWpu8xJiIiorJiGIHusl6ZTNq6EBER1TQMI+A1RoiIiKTEMAJeCp6IiEhKDCNgzwgREZGUGEbAMEJERCQlhhHwUvBERERSYhgBLwVPREQkJYYRcJiGiIhISgwjYBghIiKSEsMIuLSXiIhISgwjYM8IERGRlBhGwDBCREQkJYYRMIwQERFJiWEEnDNCREQkJYYRsGeEiIhISgwjYBghIiKSEsMIeDl4IiIiKTGMgJeDJyIikhLDCDhMQ0REJCWGETCMEBERSYlhBFzaS0REJCWGEbBnhIiISEoMI2AYISIikhLDCLi0l4iISEoMI+DSXiIiIikxjIDDNERERFJiGAHDCBERkZRqfBgRAsjJUd3nnBEiIiLjq/FhRN0rArBnhIiISAoMIwwjREREkmIYyQ8jJiaAmZm0dSEiIqqJanwY0b4UvEwmbV2IiIhqohofRriShoiISFoMIwwjREREkmIY4aXgiYiIJFXjwwgvBU9ERCStGh9GOExDREQkLYYRhhEiIiJJMYxwzggREZGkanwY4ZwRIiIiadX4MMJhGiIiImkxjDCMEBERSarGhxHty8ETERGR8dX4MMKeESIiImkxjDCMEBERScpM6gpIjUt7iYj0UygUyMvLk7oa9BwzNzeHqalpuY9T48MIl/YSEekSQuDRo0dITk6WuipUBTg6OsLd3R0ymazMx6jxYYTDNEREutRBxNXVFdbW1uX6kKHqSwiBzMxMxMfHAwDq1KlT5mMxjDCMEBFpKBQKTRCpXbu21NWh55xV/hyH+Ph4uLq6lnnIhhNYOWeEiEhDPUfE2tpa4ppQVaF+rZRnflGNDyOcM0JEVBiHZqi0KuK1UuPDCIdpiIiIpFWmMLJs2TJ4e3vD0tIS7dq1w6lTp4otn5ycjLFjx6JOnTqQy+V44YUXsHfv3jJVuKIxjBAREUnL4AmsmzdvxqRJk7B8+XK0a9cOixcvRo8ePXDlyhW4uroWKp+bm4tXX30Vrq6u2Lp1K+rWrYs7d+7A0dGxIupfbrwcPBERkbQMDiOLFi3Ce++9h2HDhgEAli9fjj179mDVqlWYNm1aofKrVq1CUlISjh07BnNzcwCAt7d3+WpdgdgzQkRElSEvL0/zuUfFM2iYJjc3F2fPnkX37t2fHcDEBN27d8fx48f1PmbXrl0ICgrC2LFj4ebmhmbNmmH+/PlQKBRFnicnJwepqak6t8rCMEJEVD3s27cPL7/8MhwdHVG7dm288cYbuHHjhmb/vXv3EBISglq1asHGxgZt2rTByZMnNft3796Ntm3bwtLSEs7Ozujbt69mn0wmw86dO3XO5+joiDVr1gAAbt++DZlMhs2bN6Nz586wtLREZGQkEhMTERISgrp168La2hr+/v7YuHGjznGUSiW++OILNGzYEHK5HPXr18e8efMAAK+88goiIiJ0yj9+/BgWFhaIioqqiGZ7LhjUM5KQkACFQgE3Nzed7W5ubrh8+bLex9y8eROHDh1CaGgo9u7di+vXr2PMmDHIy8vDnDlz9D5mwYIF+Pjjjw2pWplxaS8RUfGEADIzjX9ea2vAkIUaGRkZmDRpEpo3b4709HTMnj0bffv2RXR0NDIzM9G5c2fUrVsXu3btgru7O86dOwelUgkA2LNnD/r27YsZM2bghx9+QG5ubpnmNk6bNg0LFy5Ey5YtYWlpiezsbLRu3RpTp06Fvb099uzZgyFDhsDX1xeBgYEAgOnTp2PFihX46quv8PLLL+Phw4eaz9SRI0ciIiICCxcuhFwuBwCsX78edevWxSuvvGJw/Z5bwgD3798XAMSxY8d0tk+ePFkEBgbqfYyfn5/w9PQUT58+1WxbuHChcHd3L/I82dnZIiUlRXO7e/euACBSUlIMqW6pWFgIAQgRG1vhhyYiqnKysrJETEyMyMrK0mxLT1f9nTT2LT29fM/l8ePHAoD4+++/xXfffSfs7OxEYmKi3rJBQUEiNDS0yGMBEDt27NDZ5uDgIFavXi2EEOLWrVsCgFi8eHGJ9Xr99dfFhx9+KIQQIjU1VcjlcrFixQq9ZbOysoSTk5PYvHmzZlvz5s3F3LlzSzyPseh7zailpKSU6vPboGEaZ2dnmJqaIi4uTmd7XFwc3N3d9T6mTp06eOGFF3SuytakSRM8evQIubm5eh8jl8thb2+vc6sMSiWgrgKHaYiIqrZr164hJCQEDRo0gL29vWZ+YmxsLKKjo9GyZUvUqlVL72Ojo6PRrVu3ctehTZs2Or8rFAp88skn8Pf3R61atWBra4v9+/cjNjYWAHDp0iXk5OQUeW5LS0sMGTIEq1atAgCcO3cOFy9exNChQ8td1+eJQcM0FhYWaN26NaKiovDWW28BUI11RUVFFRrTUuvQoQM2bNgApVIJExNV9rl69Srq1KkDCwuL8tW+nHJynt1nGCEi0s/aGkhPl+a8hggODoaXlxdWrFgBDw8PKJVKNGvWDLm5uZrLlhelpP0ymQxCCJ1t+q44amNjo/P7l19+ia+//hqLFy+Gv78/bGxsMGHCBM1/xks6L6AaqmnRogXu3buH1atX45VXXoGXl1eJj6tKDL7OyKRJk7BixQqsXbsWly5dwujRo5GRkaFZXRMWFobp06dryo8ePRpJSUkYP348rl69ij179mD+/PkYO3ZsxT2LMlLPFwE4Z4SIqCgyGWBjY/ybIfNFEhMTceXKFcycORPdunVDkyZN8OTJE83+5s2bIzo6GklJSXof37x582InhLq4uODhw4ea369du4bMUkyk+fPPP9GnTx+8++67CAgIQIMGDXD16lXNfj8/P1hZWRV7bn9/f7Rp0wYrVqzAhg0bMHz48BLPW9UYvLR30KBBePz4MWbPno1Hjx6hRYsW2Ldvn2ZSa2xsrKYHBAA8PT2xf/9+TJw4Ec2bN0fdunUxfvx4TJ06teKeRRmprzFiagqY1fivDCQiqrqcnJxQu3ZtfP/996hTpw5iY2N1LjcREhKC+fPn46233sKCBQtQp04dnD9/Hh4eHggKCsKcOXPQrVs3+Pr6YvDgwXj69Cn27t2r+ax65ZVX8L///Q9BQUFQKBSYOnVqqZbt+vn5YevWrTh27BicnJywaNEixMXFoWnTpgBUwzBTp07FlClTYGFhgQ4dOuDx48f4559/MGLECM1x1BNZbWxsdFb5VBuVNJ+lQpV2AoyhbtxQTZKysanQwxIRVVnFTUZ83h08eFA0adJEyOVy0bx5c3HkyBGdiae3b98W/fv3F/b29sLa2lq0adNGnDx5UvP4bdu2iRYtWggLCwvh7Ows+vXrp9l3//598dprrwkbGxvh5+cn9u7dq3cC6/nz53XqlJiYKPr06SNsbW2Fq6urmDlzpggLCxN9+vTRlFEoFOLTTz8VXl5ewtzcXNSvX1/Mnz9f5zhpaWnC2tpajBkzpkLbrCJUxARWmRAFBsGeQ6mpqXBwcEBKSkqFTmaNiQFefBGoXRtISKiwwxIRVVnZ2dm4desWfHx8YMnJdM+N27dvw9fXF6dPn0arVq2kro6O4l4zpf38rtGDE7wUPBERPc/y8vKQmJiImTNn4qWXXnrugkhFqdHf2surrxIR0fPszz//RJ06dXD69GksX75c6upUmhrdM8IwQkREz7MuXboUWlJcHbFnBBymISIiklKNDiPqOSPsGSEiIpJOjQ4jHKYhIiKSHsMIGEaIiIikxDACzhkhIiKSUo0OI5wzQkREJL0aHUY4TENERGre3t5YvHix1NWokRhGwDBCREQkpRodRng5eCIiqg4UCgWUSqXU1SizGh1G2DNCRFQ9fP/99/Dw8Cj0gdynTx8MHz4cN27cQJ8+feDm5gZbW1u0bdsWv/76a5nPt2jRIvj7+8PGxgaenp4YM2YM0tPTdcr8+eef6NKlC6ytreHk5IQePXrgyZMnAAClUokvvvgCDRs2hFwuR/369TFv3jwAwJEjRyCTyZCcnKw5VnR0NGQyGW7fvg0AWLNmDRwdHbFr1y40bdoUcrkcsbGxOH36NF599VU4OzvDwcEBnTt3xrlz53TqlZycjPfffx9ubm6wtLREs2bN8PPPPyMjIwP29vbYunWrTvmdO3fCxsYGaWlpZW6vkjCMgGGEiKhYQgAZGca/GXAZ9IEDByIxMRGHDx/WbEtKSsK+ffsQGhqK9PR09O7dG1FRUTh//jx69uyJ4OBgxMbGlqlJTExMsGTJEvzzzz9Yu3YtDh06hClTpmj2R0dHo1u3bmjatCmOHz+Oo0ePIjg4GAqFAgAwffp0fPbZZ5g1axZiYmKwYcMGuLm5GVSHzMxMfP755/i///s//PPPP3B1dUVaWhrCw8Nx9OhRnDhxAn5+fujdu7cmSCiVSvTq1Qt//vkn1q9fj5iYGHz22WcwNTWFjY0NBg8ejNWrV+ucZ/Xq1RgwYADs7OzK1FalIqqAlJQUAUCkpKRU6HFDQoQAhFi8uEIPS0RUZWVlZYmYmBiRlZX1bGN6uuqPpbFv6ekG1b1Pnz5i+PDhmt+/++474eHhIRQKhd7yL774oli6dKnmdy8vL/HVV18ZdE61LVu2iNq1a2t+DwkJER06dNBbNjU1VcjlcrFixQq9+w8fPiwAiCdPnmi2nT9/XgAQt27dEkIIsXr1agFAREdHF1svhUIh7OzsxO7du4UQQuzfv1+YmJiIK1eu6C1/8uRJYWpqKh48eCCEECIuLk6YmZmJI0eOFHkOva+ZfKX9/K7RPSNc2ktEVH2EhoZi27ZtyMnJAQBERkZi8ODBMDExQXp6Ov7973+jSZMmcHR0hK2tLS5dulTmnpFff/0V3bp1Q926dWFnZ4chQ4YgMTERmZmZAJ71jOhz6dIl5OTkFLm/tCwsLNC8eXOdbXFxcXjvvffg5+cHBwcH2NvbIz09XfM8o6OjUa9ePbzwwgt6jxkYGIgXX3wRa9euBQCsX78eXl5e6NSpU7nqWhJ+ay8YRoiIimVtDRSYD2G08xogODgYQgjs2bMHbdu2xR9//IGvvvoKAPDvf/8bBw8exH//+180bNgQVlZWGDBgAHJzcw2u1u3bt/HGG29g9OjRmDdvHmrVqoWjR49ixIgRyM3NhbW1NayKWRlR3D5ANQQEQOfbevPy8vQeRyaT6WwLDw9HYmIivv76a3h5eUEulyMoKEjzPEs6NwCMHDkSy5Ytw7Rp07B69WoMGzas0HkqGsMIGEaIiIolkwE2NlLXokSWlpbo168fIiMjcf36dTRq1AitWrUCoJpMOnToUPTt2xcAkJ6erpkMaqizZ89CqVRi4cKFmuDw448/6pRp3rw5oqKi8PHHHxd6vJ+fH6ysrBAVFYWRI0cW2u/i4gIAePjwIZycnACoejRK488//8Q333yD3r17AwDu3r2LhIQEnXrdu3cPV69eLbJ35N1338WUKVOwZMkSxMTEIDw8vFTnLo8aPUzDy8ETEVUvoaGh2LNnD1atWoXQ0FDNdj8/P2zfvh3R0dG4cOEC3nnnnTIvhW3YsCHy8vKwdOlS3Lx5E+vWrcPy5ct1ykyfPh2nT5/GmDFj8Ndff+Hy5cv49ttvkZCQAEtLS0ydOhVTpkzBDz/8gBs3buDEiRNYuXKl5vienp6YO3curl27hj179mDhwoWlqpufnx/WrVuHS5cu4eTJkwgNDdXpDencuTM6deqE/v374+DBg7h16xZ++eUX7Nu3T1PGyckJ/fr1w+TJk/Haa6+hXr16ZWonQ9ToMDJsGDB9OlBEOCQioirmlVdeQa1atXDlyhW88847mu2LFi2Ck5MT2rdvj+DgYPTo0UPTa2KogIAALFq0CJ9//jmaNWuGyMhILFiwQKfMCy+8gAMHDuDChQsIDAxEUFAQfvrpJ5iZqQYkZs2ahQ8//BCzZ89GkyZNMGjQIMTHxwMAzM3NsXHjRly+fBnNmzfH559/jk8//bRUdVu5ciWePHmCVq1aYciQIRg3bhxcXV11ymzbtg1t27ZFSEgImjZtiilTpmhW+aiph5yGDx9epjYylExoD0o9p1JTU+Hg4ICUlBTY29tLXR0iomorOzsbt27dgo+PDyw5hl1jrVu3DhMnTsSDBw9gYWFRbNniXjOl/fyu0XNGiIiI6JnMzEw8fPgQn332Gd5///0Sg0hFqdHDNERERAVFRkbC1tZW7+3FF1+UunqV6osvvkDjxo3h7u6O6dOnG+28HKYhIiINDtMAaWlpiIuL07vP3NwcXl5eRq7R843DNERERBXMzs6uci99ToVwmIaIiIgkxTBCRESFVOWvoyfjqojXCodpiIhIw8LCAiYmJnjw4AFcXFxgYWFR6ZcCp6pJCIHc3Fw8fvwYJiYm5Vp5wzBCREQaJiYm8PHxwcOHD/HgwQOpq0NVgLW1NerXr6+5NH5ZMIwQEZEOCwsL1K9fH0+fPi10ZU4ibaampjAzMyt37xnDCBERFSKTyWBubg5zc3Opq0I1ACewEhERkaQYRoiIiEhSDCNEREQkqSoxZ0R9xfrU1FSJa0JERESlpf7cLumbZ6pEGElLSwMAeHp6SlwTIiIiMlRaWhocHByK3F8lvihPqVTiwYMHsLOzq9CL76SmpsLT0xN3797lF/BVMra18bCtjYvtbTxsa+OpqLYWQiAtLQ0eHh7FXoekSvSMmJiYoF69epV2fHt7e76wjYRtbTxsa+NiexsP29p4KqKti+sRUeMEViIiIpIUwwgRERFJqkaHEblcjjlz5kAul0tdlWqPbW08bGvjYnsbD9vaeIzd1lViAisRERFVXzW6Z4SIiIikxzBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUjU6jCxbtgze3t6wtLREu3btcOrUKamrVOUtWLAAbdu2hZ2dHVxdXfHWW2/hypUrOmWys7MxduxY1K5dG7a2tujfvz/i4uIkqnH18Nlnn0Emk2HChAmabWzninX//n28++67qF27NqysrODv748zZ85o9gshMHv2bNSpUwdWVlbo3r07rl27JmGNqyaFQoFZs2bBx8cHVlZW8PX1xSeffKLzRWts67L5/fffERwcDA8PD8hkMuzcuVNnf2naNSkpCaGhobC3t4ejoyNGjBiB9PT08ldO1FCbNm0SFhYWYtWqVeKff/4R7733nnB0dBRxcXFSV61K69Gjh1i9erW4ePGiiI6OFr179xb169cX6enpmjIffPCB8PT0FFFRUeLMmTPipZdeEu3bt5ew1lXbqVOnhLe3t2jevLkYP368ZjvbueIkJSUJLy8vMXToUHHy5Elx8+ZNsX//fnH9+nVNmc8++0w4ODiInTt3igsXLog333xT+Pj4iKysLAlrXvXMmzdP1K5dW/z888/i1q1bYsuWLcLW1lZ8/fXXmjJs67LZu3evmDFjhti+fbsAIHbs2KGzvzTt2rNnTxEQECBOnDgh/vjjD9GwYUMREhJS7rrV2DASGBgoxo4dq/ldoVAIDw8PsWDBAglrVf3Ex8cLAOK3334TQgiRnJwszM3NxZYtWzRlLl26JACI48ePS1XNKistLU34+fmJgwcPis6dO2vCCNu5Yk2dOlW8/PLLRe5XKpXC3d1dfPnll5ptycnJQi6Xi40bNxqjitXG66+/LoYPH66zrV+/fiI0NFQIwbauKAXDSGnaNSYmRgAQp0+f1pT55ZdfhEwmE/fv3y9XfWrkME1ubi7Onj2L7t27a7aZmJige/fuOH78uIQ1q35SUlIAALVq1QIAnD17Fnl5eTpt37hxY9SvX59tXwZjx47F66+/rtOeANu5ou3atQtt2rTBwIED4erqipYtW2LFihWa/bdu3cKjR4902tvBwQHt2rVjexuoffv2iIqKwtWrVwEAFy5cwNGjR9GrVy8AbOvKUpp2PX78OBwdHdGmTRtNme7du8PExAQnT54s1/mrxLf2VrSEhAQoFAq4ubnpbHdzc8Ply5clqlX1o1QqMWHCBHTo0AHNmjUDADx69AgWFhZwdHTUKevm5oZHjx5JUMuqa9OmTTh37hxOnz5daB/buWLdvHkT3377LSZNmoSPPvoIp0+fxrhx42BhYYHw8HBNm+r7m8L2Nsy0adOQmpqKxo0bw9TUFAqFAvPmzUNoaCgAsK0rSWna9dGjR3B1ddXZb2Zmhlq1apW77WtkGCHjGDt2LC5evIijR49KXZVq5+7duxg/fjwOHjwIS0tLqatT7SmVSrRp0wbz588HALRs2RIXL17E8uXLER4eLnHtqpcff/wRkZGR2LBhA1588UVER0djwoQJ8PDwYFtXYzVymMbZ2RmmpqaFVhbExcXB3d1dolpVLxEREfj5559x+PBh1KtXT7Pd3d0dubm5SE5O1inPtjfM2bNnER8fj1atWsHMzAxmZmb47bffsGTJEpiZmcHNzY3tXIHq1KmDpk2b6mxr0qQJYmNjAUDTpvybUn6TJ0/GtGnTMHjwYPj7+2PIkCGYOHEiFixYAIBtXVlK067u7u6Ij4/X2f/06VMkJSWVu+1rZBixsLBA69atERUVpdmmVCoRFRWFoKAgCWtW9QkhEBERgR07duDQoUPw8fHR2d+6dWuYm5vrtP2VK1cQGxvLtjdAt27d8PfffyM6Olpza9OmDUJDQzX32c4Vp0OHDoWWqF+9ehVeXl4AAB8fH7i7u+u0d2pqKk6ePMn2NlBmZiZMTHQ/mkxNTaFUKgGwrStLado1KCgIycnJOHv2rKbMoUOHoFQq0a5du/JVoFzTX6uwTZs2CblcLtasWSNiYmLEqFGjhKOjo3j06JHUVavSRo8eLRwcHMSRI0fEw4cPNbfMzExNmQ8++EDUr19fHDp0SJw5c0YEBQWJoKAgCWtdPWivphGC7VyRTp06JczMzMS8efPEtWvXRGRkpLC2thbr16/XlPnss8+Eo6Oj+Omnn8Rff/0l+vTpw+WmZRAeHi7q1q2rWdq7fft24ezsLKZMmaIpw7Yum7S0NHH+/Hlx/vx5AUAsWrRInD9/Xty5c0cIUbp27dmzp2jZsqU4efKkOHr0qPDz8+PS3vJaunSpqF+/vrCwsBCBgYHixIkTUlepygOg97Z69WpNmaysLDFmzBjh5OQkrK2tRd++fcXDhw+lq3Q1UTCMsJ0r1u7du0WzZs2EXC4XjRs3Ft9//73OfqVSKWbNmiXc3NyEXC4X3bp1E1euXJGotlVXamqqGD9+vKhfv76wtLQUDRo0EDNmzBA5OTmaMmzrsjl8+LDev8/h4eFCiNK1a2JioggJCRG2trbC3t5eDBs2TKSlpZW7bjIhtC5rR0RERGRkNXLOCBERET0/GEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCSp/wdZhuzwMq6wBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9deef-e07c-486b-86b1-ba3e8f1124b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1c225-6070-4719-a440-3804bf2069d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7679e01-65a0-4e65-9752-3e07a5644de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e0fed-d033-4bc1-b123-7b7ba1ab0c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc950c7-e9b5-4a47-8f51-fcc3dec0e350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81879f5c-cb19-4be1-bebb-776859eae031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a093cf6-9133-486a-9052-f83cf2800011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62594a8d-640c-4e38-82ae-516522137f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894cfcb-d034-4c97-a4db-7f4f74779a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016f105-c131-49f8-8f7d-4590472b37a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182ae4c-c033-4475-b39d-e4408f440a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7181d-172e-41fc-8b22-7d217135ed30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d13c1b-3795-4c8c-98ac-6eb0b0b42292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccfc07-5b38-4922-9c71-c67a80e0118c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08245b91-c4bf-4d47-bf13-a4c610bcd48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002e0ce-833b-4d84-89fc-62e3f15db34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
